1

JAKE ARCHIBALD: Good
morning, everyone.

Welcome to the offline
part of the day.

So my involvement with all the
offline stuff started a year

and a half ago when
I joined Lanyard.

And when I joined Lanyard--


so can everyone hear me?

Right, OK.

I'll stay at this level.

So a year and a half ago,
I started at Lanyard.

When I started, they were
building an iPhone app.

And they were doing this mainly
just to get a presence

in the App Store, but also
because it gave them the

opportunity to make data
available offline.

And offline is important to
conference delegates because

you're quite often on a plane
on the way there, so you've

mostly got no connection
there.

Or when you arrive in a foreign
country, you might be

data roaming.

So we don't want you to have to
pay a lot of money just to

find out where the conference
is or what the sessions are.

And even when you're at the
conference, obviously

conferences have Wi-Fi.

But it's a special brand of
Wi-Fi known as conference

Wi-Fi, which is like Wi-Fi,
but it doesn't work.

So you can't rely on
the connection.

But obviously not everyone
has an iPhone.

People have lots of different
kinds of devices.

And we wanted Lanyard to
work on there as well.

But most of these, quite a few
of these don't have an app

platform, and we didn't have the
resource to go and build

apps for all of then either.

So we wanted to make a web
version of the app, and that

was what I was there to do.

And when I was given this task,
I was like, well, I

really want to work offline
work in the

web version as well.

And I had this recollection of
this thing called AppCache.

And I went and did some
preliminary research into it.

And it looked really good.

I could just add a
reference to a

manifest on the HTML elements.

And I could just list
all the stuff that I

want to work offline.

And it works.

And I could also capture a set
of URLs, like everything that

begins with avatars-- images,
avatars-- and then say, well,

if you're offline, I want you
to serve that instead.

And I was like, wow,
this sounds like

a really good solution.

It seemed like the API was this
big, cuddly teddy bear.

And I kind of ran up and I
hugged the teddy bear and

thought, together, we're going
to get through this.

We can make the web
work offline.

Of course it soon became obvious
that the lovely teddy

bear that I was cuddling
was filled with

razor blades and bees.

And I got stung many,
many times.

And the razor blades
dug into my skin.

And I got the whole alphabet
of hepatitis.

And it was a really
nasty experience.

So you hear the word "gotcha"
a lot with AppCache.

And the spec does seem
to do the unexpected.

MALE SPEAKER: I think
your mic is on.

JAKE ARCHIBALD: Ah, yeah.

That would help.

OK.

Oh, that's nicer.

OK, so when something is cached,
it will always come

from the cache.

If the AppCache has something to
give you, it will serve it

straight from the cache.

And so even if you're online,
you're going to get those

cached assets.

And the cache is only updated
if the manifest file itself

changes, just a character
changes, even if that

character is inside a comment.

And the cache only updates if
all of the things you listed

downloads successfully.

If one of them 404s or 500s,
then the whole thing fails.

I started drawing this diagram
to try and make sense of what

AppCache was actually doing,
what the flow of information

was, how it worked.

And I did some talks based on
this, and I'm showing this

diagram, going, look--

look how terrible
that cache is.

Look how complicated it is.

But if you think about some code
you've written recently--

even something fairly simple,
like, I don't know, form

validation--

if you drew it as
a flow chart, it

would look like this.

It would look this complicated,
probably more

complicated.

And that doesn't
make it wrong.

And that doesn't make it
difficult to read.

And that doesn't make
it hard to maintain.

A lot of the gotchas that
AppCache has are actually

quite sensible.

So the cache is used even if
you're online, and that

happens because it's really,
really fast.

The exception is in fallback.

So if it tries to request an
avatar, it's going to go to

the network.

And it's only going to
serve this if the

network request fails.

And that's really quick, in this
case, because you can go

and get the avatar from the
network, and that's going to

be really fast.

It's even faster in this case
because it's going to fail

really, really quickly.

And you'll get the fallback
avatar instead.

The problem case is this,
which I like to

call the real world.

And when your phone's in this
kind of state, it's like a

one-legged dog.

It thinks it can still play
fetch, but it can't.

And you have to watch it drag
itself along the floor with

its one leg.

And it's heartbreaking.

And with your phone it's really,
really irritating.

Because you know that on the
device, on there is the data

that is good enough
for you right now.

But it won't give you it.

It has to wait for minutes
before it decides it really

can't make this connection.

The spec doesn't really mention
offline very much.

It only talks about connections
that succeeded or

failed, all past tense.

It doesn't try and predict
the state of the network.

So cached data at first is good,
because it doesn't have

any expectation of the network,
and that's great.

And that's how apps behave.

If you open Twitter on
your phone, you've

got old data there.

And then it goes and fetches new
data if it can, if there's

a network connection.

So complexity isn't
the problem here.

What is the problem?

Well, what is the AppCache
made of?

There's a request cache.

And we can add, remove, and
update items from this.

And those updates are
transactional.

It's all atomic.

And it's pretty sensible.

There's also a router.

The router takes a network
connection and decides what it

should do with it.

So it can just serve stuff
straight from the cache

without going to network, or
it can go to network, give

that a go, and serve something
from the cache if that fails.

And that's all quite
sensible as well.

But what's our API into this?

Our API is the manifest.

So if I do this, I add
an empty manifest--

well, just with the words
cache manifest--

what this will do is it'll take
index.html and it will

put that into the cache.

And it will set up a routing
rule that says if that page is

requested, serve it straight
from the cache.

Really?

Did I just tell it to
do all that, just

with this empty file?

Here I'm adding a lot more
static routes, and here I'm

saying, hey, with this one line,
take fallback PNG, make

that a cache entry, put
that into the cache.

And if any of these URLs are
requested, set up a routing

rule, try and fetch it from the
network first, and if that

fails, then use this instead,
fallback PNG.

And a failure means any HTTP
status code that starts with

4, 404, anything that starts
with 5, or if there's a

redirect to another domain.

Did I really tell it to do
that with this one line?

That's a lot of assumptions
to make.

And if I, say, have on my HTML
page a link, an image to a

picture of your cat from
Flickr-- do you have a cat?

Who has a cat?

Your cat-- good, Bruce's cat.

What happens to the
image of that cat?

OK, so an index.html file
is a get request.

That's fine.

Is it associated with manifest?

Yes it is.

We're going to use that.

Is the URL AppCached?

Yes it is.

So it comes straight
from the cache.

That's fine.

Is it HTML?

Yes it is.

So for each get request on
the page, we're going

to go back up here.

And that's going to include
the picture of your cat.

So is the URL AppCached?

No.

Is the URL in the network
section of the manifest?

No.

Does the URL match a
fallback prefix?

No.

We've got one for avatars
but not one for

Bruce's cat, so no.

Is there a star in the
network section?

No.

So the image will fail.

And the picture of Bruce's
cat will not appear.

It will appear as if there
was no network.

Even if you're online, the
picture of that cat will fail

to download.

There is nothing here to me that
suggests that picture of

Bruce's cat should not load.

I don't know what the AppCache
has against Bruce's cat, but

even online it's not
going to work.

This is a downfall API.

And by downfall, I don't mean
the shouty Hitler thing.

I'm not suggesting AppCache
is like Hitler--

although it is a bit.

No, I mean the old board game.

I don't know how people have
played this, but this is what

I feel like when I'm dealing
with AppCache.

I know what I'm trying to do.

I'm trying to get my pieces
to the bottom.

And I have a very limited set
of controls for that.

But when I'm doing this, all
kinds of shit's happening in

the background.

And I don't know what's going
on until bits start falling

out of the bottom that
I didn't expect.

And I don't know which of my
actions actually contributed

to that happening.

I know the last one that
happens, but I don't

everything that happened
before that.

The manifest is simple in terms
of the character count,

but there's too much implicit
going on here.

A better API may involve more
typing but might set out

exactly what's supposed
to happen.

What if in your HTML you could
say, I want to register a

JavaScript controller.

This controllers going to take
care of all URLs on the

origin, just slash-star.

And here's my JavaScript file.

And that was going to run
in some kind of worker.

And here I could just say, so
for all these files, when the

cache is supposed to update
itself, I want you to define a

cache called static, and I want
you to cache all of those

static URLs and do
it atomically.

And then when there's a request,
I want you to have a

look and see in the static cache
if there's something

that matches the incoming URL.

And if there is a resource,
prevent default.

Don't do the default
browser action.

Respond with that resource
from the cache.

This is a lot more typing than
the equivalent that you did in

the manifest, but it's
really explicit.

You're setting up exactly
what you want to happen.

There's no magic here.

You can define your own magic.

This is a bring your
own unicorn API.

You do all that stuff
yourself.

What if I could say, OK, I'm
going to set up a route for

get requests.

Anything that starts with
avatars, prevent the default.

I want you to try and get
it from the network.

But on an error, I want you to
see if we've got something,

the fallback PNG in
the resource.

And if there is, I'm
going to serve it.

So that's the equivalent of
your fallback, but you're

telling it exactly what to do.

What if I could listen to
messages from the web page

that's happening?

So imagine something like DFT,
where there's issues.

And the user might have said,
I want to cache this issue.

So he posted a message saying,
cache the issue.

And [INAUDIBLE]

receives that, caches define
issue, and then the issue

number, and the URLs
to cache for that.

And then when those requests
come in, anything that's URL

issue and a number, we're
going to deal with that.

We're going to say get me the
cache for that issue.

If we have that cached and we
have a URL inside that cache

that matches what's being
requested, serve it.

Otherwise, if the request type
is a navigate, as in, someone

is changing page, it's going to
be a full reload, prevent

the default.

Respond--

try and fetch it from the
network as normal.

And if that fails, and the
status code was zero, which

suggests a lack of network
connection, then serve a thing

from the cache saying, no, I'm
afraid you don't have that

issue cached, here's why.

And that's something we can't
do with AppCache now.

Maybe you could do stuff like
get stuff from local storage

and then use Mustache to
render it, or whatever

templating language
you included.

We could just completely build
an app up from this experience

and completely define how
it should behave.

So even someone who is
unfamiliar with the API would

have a good idea of
what it's doing.

They wouldn't have to read a
whole spec to understand

what's going on.

What if we could do that?

And I think that's what we're
going to discuss, or

things around it.

I don't how this transition--
you have to clap.

[APPLAUSE]

JAKE ARCHIBALD: Watch
out, watch out.

I think that's Andrew's
seat, isn't it?


ANDREW BETTIS: Right.

So I realized when Jake started
that I completely

forgot to big up all
the people on the

panel before we started.

So we have Jake, who's obviously
just given his talk.

He's now developed relations
for Google,

formerly from Lanyard.

Mark Christian from Twitter,
who also created one of the

first informative sites about
AppCache, appcachefacts.info.

Alex Russell, also from Google,
who is co-author of

the proposal that Jake was just
talking about, with the

navigation controller.

And Jonas Sicking from Mozilla,
who has very kindly

signed up at the very last
minute to replace [INAUDIBLE]

Tobie Langel, who's
unfortunately unable to make

it because he's ill.

So let's get started.


So we have loads of questions
in moderator about offline.

And I think the most burning
one for me, and I think the

one that's most relevant to
DFT is why is there such a

constraint on what we
can do offline?

Why do we have such tiny limits
on what we can store?

And is this a problem that we
need to solve at the spec

level, or do we need an entire
new technology to solve it?

Jake, why don't you start?

JAKE ARCHIBALD: OK, so if you're
building something,

it's going to be running
on multiple devices.

So you can't make too many
expectations of the amount of

data that you would be able to
store on a particular device.

That said, one of the things
we were looking at is the

ability to request a
permanent cache.

Because one of the problems
we've got with the current

cache is the browser may
object at any point.

Has my microphone
gone off again?

Oh, whatever.

So the browser can just get
rid of it at any point.

Oh, hello.


So what AppCache gives you is
it says, one of these assets

is not going to be ejected
from the cache.

If anything's going to be
ejected, they're all going to

be ejected together.

And the spec doesn't say that
this stuff's going to be

around forever.

So the idea is if we could
make it where you would

request a permanent cache, maybe
of a particular size,

then you could do
that and that.

And because a user would agree
to give you that, they are

also now in control of
uninstalling something.

So if there is a lack of space,
like they run out of

space on their phone, then it's
down to them to decide

what to keep and what to lose.

So they might go and say, well,
this small FT app is

very important to me, whereas
these big game apps are not.

And it's their decision
of what to do?

ANDREW BETTIS: So what's the
limit on what's reasonable?

What's reasonable for an app
to acclaim for its own

exclusive use?

ALE RUSSELL: How is
that a question

for the app to answer?

It's usually a question for
the user to answer.

This is about the user agent
mediating the conversation

between the app developer and
the user, who is the owner of

the device.

And so you're trying to enable
that conversation to happen in

an informed way.

And usually that doesn't
mean, can I

have some bit of storage.

It's usually did I mean
to install this thing?

Did I mean to turn this into
a real thing that's not an

ephemeral page that I happen
to load and unload.

The question is, have my
expectations been violated by

navigating naked
to a web page.

Did that imply that
100 megabytes was

taken on disk per page?

If I'm going to Facebook every
day, maybe it does.

Maybe that's a reasonable
thing to do.

If I go to Twitter and I like
to see all my history, maybe

that's the most reasonable
thing I

could possibly imagine.

But that's a decision that
I as a user should be

at least part of.

And so today we don't have
that way to mediate it.

And so I [INAUDIBLE]

there was an additional proposal
yesterday that Jonas

and others at Mozilla were
working on to layer on top of

this API that we have shown a
little bit of, the idea of a

more declarative manifest that
has more to say about what the

thing is that you would
take an action on.

JONAS SICKING: There's
a few things here.

First of all, you shouldn't
think of the web as being

different from native
applications.

Native applications, once you
install a native application,

it can write as much
as it wants.

Why should the web not be able
to do that, assuming the

user's fine with it.

So we need to have some way of
communicating between the

application and the user that
the user thinks this website

is important and then wants to
enable it to store data on the

local device.

So that is really something
we would need to enable.

Google actually has some
interesting ideas here in the

[INAUDIBLE]

API, where they have this
concept of temporary storage

and permanent storage.

That concept is something we
are working on expanding so

you can use that storage area to
store essentially anything

that you can store locally, you
can choose to [INAUDIBLE]

store permanently
or temporary.

And the user can then
be involved.

And we can also use heuristics
in the browser.

Like, if we know that the user
is using a website a lot, we

can grant that website more
implicit storage, and we can

be more careful about when
we eject that data.

Or we can also enable the
website to say, I want to

really lock this down.

And then once the user's OK with
that, we can guarantee

that certain data is
available offline.

So the goal should really be
that anything that native

applications can do when it
comes to sorting data locally,

the web should be able to do.

And that shouldn't be
hard to accomplish.

ANDREW BETTIS: Is it currently
a problem that a user giving

explicit consent to store
something as an explicit

intention to store, but
then the browser can

implicitly purge it?

Is that a bug, do you think,
currently in implementation?

Should it be the case that
anything that's explicitly

given permission to be stored
should be explicitly removed

by the user?

JONAS SICKING: I think we need
to enable the scenario where

you're guaranteed that
something is wrong.

The only way to guarantee that
something is wrong is to take

up storage on the user's device,
which means taking

resource away from the user.

And so the user needs to be
involved in that decision.

But in many cases, you don't
need that level of guarantee.

And you could probably build
pretty good heuristics so that

things mostly work without
the user being involved.

But I also think that we need
to enable websites to say,

hey, I really want to be able to
guarantee this to the user,

in which case we can
have interaction.

We can have a security
dialogue.

But as long as we make that
flow nice and don't ask--

like Firefox currently does,
asks you three times before it

grants you that permission.

It should be within the control
of the website when to

ask the user.

And it should only
be one question.

The user should just say, yeah,
I'm OK with giving this

website a little bit
more information.

And we shouldn't need to ask
about individual [INAUDIBLE].

ANDREW BETTIS: So can
I just a quick poll?

Who here has run out of space
when they were building an

offline app?

So we have a few
people who've--

OK, interesting.

ALEX RUSSELL: I think it's
also a UX issue.

There's the what is it
that I'm doing here?

Are we going to ask users
honestly to go reason about

their storage independently of
what the application is?

I don't think that people,
generally speaking-- certainly

not the app platform models
that we have today--

I don't think people reason
about them independently.

You have an application, and
that means that you have its

data as well.

And we don't really have a
reified idea of what an

application is.

That's the thing that we don't
have, as a unit of something

that we can communicate
to end users today.

And Mozilla's building an app
platform, and we're building

an app platform.

And they helped unify
that concept.

And it feels to me like
helping to make that

transition from I've got a page
to look, it's also an

application--

I think that's really the big
transition for everyone who's

building apps, both conceptually
as you're

building them and for users
who are consuming them.

I'd like to talk more at some
point about what it means to

transition as a builder thinking
about an app--

ANDREW BETTIS: Well, your
microphone's not working.

So next time you want to speak,
just let me know.

And you can speak into mine.

MALE SPEAKER: His
mic works fine.

But he can't talk over his
shoulder to Andrew.

He's got to talk directly
[INAUDIBLE].

ALEX RUSSELL: Sorry
about that.

MARK CHRISTIAN: So I think that
part of the problem with

the situation right now is that
web applications feel a

little bit different than
websites, but they're all

running in the same universe.

And when you're building an
application, you want to have

quite a bit of control over
how you're storing your

resources and managing the
user data, whereas

historically, web APIs have been
more like suggestions to

the user agent.

It's up to the user agent to
interpret what's going on and

deal with it appropriately.

AppCache demonstrates that
there's a lot of assumptions

built into that that don't
always work, and it makes it

difficult to have a consistent
experience.

So I think part of the problem
is actually philosophical.

As we go forward and build a new
API, how much control do

we want to let these
applications have?

And it's a trust
issue as well.

Going to a random website, how
much trust does that actually

imply that user has?

JAKE ARCHIBALD: I think we could
spend the whole of today

trying to work out what the
difference between a website

and a web app is.

And I think at the end of it,
we'd say, well, does it

actually matter?

Once we've made that decision,
what would we do differently?

So I think this API we're making
now would work fine for

sites and work fine for apps.

What do you see as the
difference between the two?

MARK CHRISTIAN: Probably
persistence of storage and

amount of storage.

Those are the characteristics.

Do you want a random website to
be able to dump a gigabyte

of data onto your hard drive?

JAKE ARCHIBALD: Well, I might
if it's Wikipedia.

I might want to download
Wikipedia as a site.

MARK CHRISTIAN: Yeah,
I might too.

But there's no good model for
letting a user illustrate that

that's actually what
they really wanted.


JONAS SICKING: I think one
problem we have is that

historically websites have been
these things where, as a

browser, we treat them as--
we have no idea if this is

something that the user
actually likes.

It might be just some random
website that the user found

through a link in
a spam email.

And so we have this very
distrusting relationship of

the website.

And as we're trying to expand
the web into being able to do

more things, we have to enable
the user to indicate, I

actually trust this website.

I actually enjoy this website.

I want this website to be able
to do things that [INAUDIBLE]

shouldn't be able to do.

So we need some way, some
UX to enable the user to

communicate to the browser that,
hey, it's OK for this

website to get some extra
capabilities.

So one way of doing this is
app platforms that both

Firefox and Chrome OS is having,
which enables the

users to go through this install
flow, at which point,

you indicated that yeah, I trust
this website enough that

I have installed it.

We should enable those
capabilities not just through

install flow but also through
other means where it's still a

website, UX-wise, but you've
indicated some other way that

it's OK for this guy to
use more resources.

The two things in Firefox OS
that we're giving a website

once it's installed is ability
to use resources and ability

to annoy the user.

So on the web, we built
pop-up blockers.

We tried to disable this ability
of disabling the

context menu.

And a lot of the things that
it's really nice if the good

guys can do but we don't want
the bad guys to do.

And so if we can have some way
to use UX to indicate that

this website should be able to
do things, then we can enable

much more [INAUDIBLE].

ANDREW BETTIS: Do you think that
using app runtimes as a

solution to offline problems
is good enough?

Or do you think that we ought
to be able to solve these

problems without using
app runtime?

JONAS SICKING: I think app
runtimes is a good way for us

to experiment, but
it's an easy out.

We have this traditional sense
of what an application is.

And traditional users know what
it means to install an

application, as far as I know
that this enables this

application to do more things.

I shouldn't install
it if I hate it.

So it gives us an easy
out, but it's

definitely not good enough.

There needs to be a fluid
transition from being a

potentially evil spam website
that the user has navigated to

being a fully-trusted
installed app.

It's a smooth transition.

And the user, as you're slowly
getting more and more familiar

with the website, it shouldn't
be a hard path.

It should be, you trust it more
and more, and it gets

more and more capabilities as
the user gives it more and

more trust.

App runtimes is definitely
not enough of an answer.

JAKE ARCHIBALD: Yeah, we've been
through that same problem

before with Flash.

I mean, we went for so long with
not adding these APIs to

HTML, saying, oh, if you want
those kind of capabilities, do

it in a plug-in.

And we're seeing the same again
with, oh, if you want

those kind of things, just
do it in an app.

We shouldn't let that stop us
making the platform better.

ANDREW BETTIS: Jake and Alex,
you're proposing actually a

controller that gives the
developer a lot of flexibility

over how they respond to
offline situations.


There's a great question in
Moderator which is, how would

you propose to use that
to handle the

one-legged dog scenario?

ALEX RUSSELL: So I think
the answer to this is--

it's a little bit circuitous,
so stick with me.

The way AppCache works,
generally speaking, when it

works, is to help you take the
shell of an application, the

thing that will load content
and then display it to you

while your offline, package that
up, and make it available

to you at all points.

What Jake showed you was a great
way for you to package

up the shell of a content
application using AppCache.

There's a related question,
which is inflated by the API

of AppCache, unfortunately,
which is, how do I then deal

with the content that I'm
loading inside this shell?

Because every app you
load in native

environment has this duality.

I've got shell, and I've got a
library of content that I'm

navigating.

And if you think about the way
you're building things on the

server, you do exactly
the same thing.

You've got this node graph of
content that you're allowing

users to transition through,
and they're

all mapped to URLs.

But you usually take the little
bit of content that's

unique to that URL, and you
smash a gigantic template

thing around it, and you spit
it all out as a string, and

then you rehydrate it
on the client side.

But that isn't what the URL
is really addressing.

The URL addresses that little
bit of content, that unique

bit of indivisible content
that you're

serving at that URL.

And it may be multiple nodes all
joined into one particular

serialization.

But that's sort of the idea.

So the question is, how do
we enable people to build

application architectures
offline, which easily give you

that shell and the ability to
cache resources which you will

load inside that shell, so that
you can discover them, so

you can load them, you can
provide the fallback

experience if you
don't have them.

Today, AppCache rolls them
all into one manifest.

Because today, if you actually
take the AppCache to its

logical conclusion, what you
realize at the end of this

long, painful journey-- which
Jake took, and which the Gmail

team took, and which a lot of
people who have been building

offline apps have taken
independently--

is that AppCache is the
thing that you use

to cache the shell.

And for all other content, which
you would have liked to

have given a nice URL, what you
do is you build an ad hoc

synchronization protocol, you
put it in Web SQL Database or

IndexDB or local storage.

And then every time someone
navigates to that URL, you try

to override what the browser
was going to do to navigate

you, go get it out of the local
storage if you have it,

and then perform your
own synchronization

on that data model.

So you have a data model which
is not represented at those

URLs anymore.

So the default model is
effectively URL hostile.

And the only thing that's helped
by having it at a URL

is loading the initial shell,
which is the least meaningful

thing in terms of URL space.

So what you'd really like to
do in all this is to help

application owners understand
through the API that your

caching two separate
sets of things.

There's a shell, which is your
browser for your content.

There's the browser that
you browse to different

sites and apps with.

But there's the browser that you
build for the content that

you're surfacing inside
your app.

And then there's the
content of the app.

You need to treat them
independently, but you'd like

them both to be cacheable
as HTTP resources.

So the way to get there is
to change expectations.

There's no app that you're
going to build that's

meaningful that's not
offline by default.

AppCache gets you part of the
way there, because it makes

the resources for your app
shell offline by default.

But it doesn't necessarily do
anything particular for the

resources that you would like
to load inside that shell.

So we have to make this
transition in thinking about

building apps in this world,
which is, we're not building a

series of HTML pages that you're
going to serialize at a

URL fully formed from the server
side as strings that

you're going to put back
into the cache.

It's nonsensical.

It doesn't work.

Instead what you're going to do
is you're going to assume

that there's a shell that's
booted, and you're moving

between the cached resources,
and if you can get to them,

the uncached ones.

And that means that you're
always working from this local

store of your shell and your
content in order to do

everything.

And that's the big transition
that has been conflated with

the use of AppCache over time.

And everyone discovers that
that's what AppCache implies,

but it's not clear.

And it's not clear that that's
how you have to build your

application to be successful.

JAKE ARCHIBALD: So I would see
the model working if you

imagine an app--

I think I'm all right.

If you imagine an app--
no, I'm not.

If you imagine an app where it's
a series of messages from

people you're subscribed to--

basically Twitter--

if you visit the page and you
don't have a controller

installed, and you don't have
JavaScript, the server is

going to construct all
of this stuff.

You'll have to wait for a
network who responds, and

you'll get it how internet
should work today.

If you have a controller
installed, it's going to

respond with an empty content
shell of the UI, it's going to

kick off an XHR or request on
your page, but it's going to

have a header or query
strings saying, I'm

OK with cached data.

The controller is going to
see that and return the

last data you saw.

You're going to build
up the page.

And that's going to
happen instantly.

But then it will set off another
XHR, something in a

query string, saying, I want
this data to come from online.

And that connection will either
succeed, in which case

you'll replace the content on
the screen with the new stuff,

or it will fail, and you'll
fail silently.

And that's your offline
experience.

ANDREW BETTIS: Can I pick up--

you were talking about the
failure scenario of trying to

load content and then it failing
and falling back to

content from cache.

So the biggest problem we have
with AppCache with the

fallback is that you can't
control that timeout.

You can't determine how long
that's going to be, and it's

usually longer than a user
is prepared to wait.

So in the scenario of using a
navigation controller, in

which you'd be able to configure
what that timeout

is, how long are you
prepared to wait?


ALEX RUSSELL: You have explicit
control under the

controller scenario over
the loading process.

So you are able to make
a decision when you're

dispatching the request in the
first place, do I know that

I'm offline?

The only thing that we can
actually tell you from the

browser's perspective about
your online versus offline

state is that you are
definitively not connected to

any network.

We can't tell you whether or not
you can hit your server.

We can't tell you anything about
what's reasonable in

terms of expectation for
hitting your server.

We can tell you if you're behind
a hostile proxy or

inside of a captive portal
from some Wi-Fi thing.

We can't tell you any of that.

That's going to be up to
your application to

have to figure out.

And the way you do that is by
making one these requests and

then watching what happens.

So yes, you'll be able to cancel
the request and respond

with I have no idea
what's going on.

And it's going to be explicitly
under your control,

which is to say that you'll
explicitly have to provide

that functionality.

But that's a damn sight better
than trying to have to figure

out a way to make AppCache
do it right now.

ANDREW BETTIS: And here's
another quick

question from Moderator.

Is there scope for a standard
way of synchronizing content

from server to client
and vice versa?

JONAS SICKING: So

synchronization is really hard.

Once you get into two-way
synchronization, which is what

you often get into, there's
no standard way of

synchronizing data.

It's very, very application
specific, how you deal with

merged conflicts.


So one answer is simply no,
we can't solve this.

There are some interesting
approaches that may work.

So Couch, for example, does this
thing where it allows you

to synchronize data, but
it doesn't actually

deal with the merging.

So you can pull down data, and
the local data that you end up

with explicitly contains
the conflict.

And then after the fact, once
you run code, then you can

deal with that conflict.

And so potentially we can build

something around that model.

But I think dealing with
synchronization is really,

really hard.

I think in the beginning
we need to just.

ANDREW BETTIS: Are we just
asking for trouble here?

I mean, are we just asking
to build something that

developers will say, that
doesn't quite work the way I

want it to, so I'm going
to build my own?

ALEX RUSSELL: I think the thing
that will get you in

trouble is making assumptions
about the developers' data

model, which were not
collaborative.

So if we provide developers a
data model which we constrain

tightly, like, if we provide
a straight transition chart

system that you can then speak
in high-level terms about the

changes between the states of
your applications, and then we

can watch those in a way that,
say, a SQL database watches

the SQL queries that come in and
the transactions and the

commits and you can then make a
binary log of them, then you

can start to do something about
the synchronization of

the high-level application
semantics.

But as much as people would like
to pretend that HTML is

semantic, it ain't.

HTML today, in most of its use
cases, ain't semantic.

You're not saying anything more
meaningful than div, div,

div, div, div.

And your mutations of HTML are
no more meaningful that show

or hide this particular
piece of UI.

They don't relate specifically,
in most cases,

except in a tangential way, to
I'm changing this particular

piece of state in my data model,
which is what you're

trying to synchronize.

And so we don't have a local
idea of a data model.

Therefore we can't really cons
up the idea of a local

synchronization store.

I think that the next iteration
of the library wars

will be about data models
locally and synchronization.

My guess is that people are
going to start doing

operational transform libraries
out of the woodwork.

It's going to be amazing.

We're starting to see this a
little bit with Meteor and

some other libraries that are
starting to apply some good

computer science to the
question of how do I

differentiate what's happening
when I change it?

How do I prevent merge conflicts
in the first place,

by dealing in high-level
operations, and not in, oh

look, some field was
added or removed?

And we're starting to add good
support for being able to

build these libraries into both
the language and the DOM.

There's something called
object.observe and mutation

observers, which are way of
observing those changes as

they happen and responding to
high-level events and not the

low-level primitives changing
out from underneath you.

But we've got a very long way
collectively to go to get to

an agreement whereby we as
browser vendors would feel, I

think, reasonably comfortable
in blessing one particulars

strategy for describing your
data and then another strategy

for synchronizing it.

ANDREW BETTIS: So has anyone
here implemented any kind of

offline sync, any kind
of ability to

synchronize data to browser?

MALE SPEAKER: Yeah.

ANDREW BETTIS: OK, so what's
your use case?


MALE SPEAKER: It's exactly how
you just described it.

The AppCache hosts the shell,
and everything else comes from

local storage.

So local storage is the user
data, AppCache is the shell.

And it assumes from the
beginning that the user is

going to have no data and then
tries to fetch over an AJAX

request and feeds into
local storage.


MARK CHRISTIAN: I think most
of the problems with

synchronization are less data
model than we would think.

I feel like it's actually
a feasible problem.

If you look at stuff like
iCloud, you can offer a couple

of pretty basic data
strategies.

Like, I've got a key value
store, or I've

got a record store.

You don't need to build up
particularly complex models in

the browser to actually
be able to support--

there's this thing, it has a
GUID, and you can say whatever

the most recent changed
version is works.

ALEX RUSSELL: So you're positing
that one default

strategy across multi-tenant
synchronization will work,

that there's only a single user,
and that user's last

change is going to be
synchronized and timed

correctly across multiple
systems.

And you're saying that there's
a closed form over the

operations that I can take.

You do need the closed form, but
you need the ability for

applications to specify the
operations that they will

allow on their data and what it
means for them to change a

piece of data.

Yes, you can bring users down to
one model of mutating data

and what that semantic
is for mutation.

And you can constrain the set of
things that they will then

reasonably be able to do in
the app without hitting

synchronization issues
based on this policy.

You could do that, but I don't
feel like it's our job as a

platform right now to make that
kind of a call in quite

such a closed way.

Because I don't think that we've
got the experience in

our community for that's
the right thing to do.

I can tell you right now that
that would not work for Gmail.

It honestly would not
work for Gmail.

It wouldn't work for Sync.

It wouldn't have worked
for Wave.

It doesn't work for Plus.

It won't fly.

ANDREW BETTIS: Mark, can you
tell us why Twitter doesn't

currently use offline?

MARK CHRISTIAN: Well, Twitter's
web platform is in a

bit of flux.

We're moving towards
a server as the

ultimate source of truth.

So we actually don't do any
client side rendering at all.

So any navigation event, even
though it's happening AJAXly,

is actually just injecting a
response from the server.

So you can't really cache that
nearly as efficiently as you

could a series of JSON
responses, for example,

because they're full-page
responses.

So not every AJAX model is going
to work as well with

that sort of a strategy.

Whether that changes
in the future, TBD.

But basically, two competing
styles of how you want to have

a fast responsive app, you have
something that lives on

the server, something that lives
entirely on the client.

And having something that can
react to both is actually a

messy, terrible proposition
right now.


JAKE ARCHIBALD: The way we did
that at Lanyard was we were

rendering on the server with
Mustache and some data.

And then when we were doing the
same on the client with

offline, we were using the same
Mustache templates, and

we were caching the same data
model in local storage, the

same as you were.

And obviously we'd rather be
doing that in AppCache.

So yeah, you can still do the
progressive enhancement thing

and have a client-based
app, and you're not

duplicating too much data.

And did anyone see the "B&B"
article recently where they

were talking about, hey, we've
decided to try this new,

exciting idea.

And what we're going to do is
we're going to render content

on the server, and we're
going to send out an

HTML string of content.

And it's amazingly fast.

You guys should all
be doing this.


Yeah, we've been calling that
progressive enhancement.

MARK CHRISTIAN: Well, that's
sort of our model too.

Twitter's famously, remember,
the hashbang website a couple

of years ago.

It was actually pretty speedy
if you were on a MacBook Pro

with the latest version
of Chrome.

But if you were using IE7 in
Bangalore, it was actually an

atrocious experience.

And so the server side model
ends up working a lot better

on the low end.

And the problem with having two
rendering stacks, even if

they're sharing templates, is
that you've got quirks between

your view implementation.

And that is a great way to kill
yourself with 1,000 paper

cuts, especially if you're on
a large dev team with a few

dozen developers trying to
keep it all in sync.

JAKE ARCHIBALD: No, I completely
agree with that.

Because we were using Mustache,
and we ended up

pretty much owning, or making
massive contributions to about

four different implementations
of Mustache the Python one,

the Java one, the IOS one,
and the JavaScript one.

MARK CHRISTIAN: There's one
developer at Twitter who's

single-handedly written
two from scratch--

Hogan and Eckersley--

just because most of the
implementations had

some sort of issue.

ANDREW BETTIS: So are you
saying, then, that the only

real use case for offline
technologies is when you

actually want to build an
offline app rather than to

improve the performance
of your app?

MARK CHRISTIAN: Well,
application versus website--

it's the same thing I
mentioned earlier.

I feel like the offline
technologies are really good

for building an app, like
the Lanyard thing.

But they don't really map very
well towards a Twitter or even

a Wikipedia kind of example.

They just don't feel like a very
good fit for something

where you're always pulling
in new data, and it's an

unbounded amount of content
that you might

want to pull in.

JAKE ARCHIBALD: If you're
just looking to improve

performance, that's what
the HTTP cache is for.

The application cache is for
caching applications--

it's for making it
work offline.

If you can get a performance
benefit out of using it, then

fair enough.

But you are buying into making
an offline-first experience.

ALEX RUSSELL: To be clear,
though, the new proposal would

be a reasonable accelerator.

If you don't ever handle any
navigation events but only

resources, you could certainly
build a local high performance

cache system to improve website
performance without

biting off any offline
capability at all.

ANDREW BETTIS: In what situation
would you want to do

that versus using
the HTTP cache?

ALEX RUSSELL: We've had good
input from the folks at

Facebook that this is their core
use case for AppCache, is

actually making things--

or not a core.

One of their most important use
cases was making things

available faster.

And at Google, I know that our
global teams have had similar

needs, and AppCache
hasn't met them.

So hopefully this new API
will meet those two.

JONAS SICKING: Yeah, I think the
mental model that I've had

recently is that it would be
great if we can make it work

so that the online case
is very similar

to the offline case.

It's more a difference between
are you seeing controller

slash app cache or you're not.

So if we can make it so that
when you are using these new

features for enabling offline
but you happen to be online,

you can still download the data
and just download the

data part and not the template
and the static content and use

that cached version of that
increase performance.

I'm definitely hoping that that
is a model we can get to,

to basically make the online
application experience be more

competitive with native--
where on native you're

downloading your shell once.

And then as you're using it,
you're just downloading the

incremental data.

We should be able to make the
same thing possible on the web

to increase performance.


JAKE ARCHIBALD: So the HTTP
cache is like this really busy

room, and everyone's in there.

And the browser's having to be
the bouncer at the door.

And when other people want into
the room, the bouncer's

going, look, you've had
too much to drink.

You should get out.

And then what Facebook have done
is gone, ah, but there's

this quieter bar around
the corner.

We're going to go there.

But the thing is, if everyone
starts doing that, then that

bar is going to have to hire a
bouncer, and they're going to

start kicking people
out as well.

It seems like a nice performance
enhancement now.

But I think if everyone started
using it, we're going

to get the same issues where if
everyone's stuffing fonts

and images into local storage,
there's going to have to be a

bouncer there that kicks
people out-- unless the

website asked for a
permanent cache.

But I don't think we want a
web where you just visit

Facebook because you want to
look at a thing, and it's

saying, Facebook wants to
install 5 megabytes worth of

stuff just so you can see it.

It's not for an offline
experience, it's just to look

at the site.

MARK CHRISTIAN: The interesting
characteristic

about using AppCache for storing
the outer shell is

that it lets you have a cache
where it's totally happy to

start rendering the page with
the old version, without even

going to see if there's
a new one.

And that's something that HTTP
caching could theoretically be

modified to have but doesn't.

And it's an interesting
characteristic all its own.

HTTP caching in general is best
described as bewildering.

There's just so many options,
and it never quite does what

you expect.

And with all of AppCache's
problems, one thing that we

can say is at least we can
expect that the data will be

there when we ask
for it again.


JONAS SICKING: I don't think the
bar around the corner is

necessarily going to get
as packed as the

initial HTTP cache bar.

Because if we are good enough
at building the heuristics

where maybe we don't download
AppCache the first time you

visit a website.

But if we see that you visit a
website every day, then we'll

download the AppCache and we'll
keep it more tightly.

So I think if we're more clever
than we are with HTTP

cache, then I think we
can keep the good

people in that bar.

ANDREW BETTIS: Why do we need
another bar at all?

Just hypothetically, why do we
not just have an extra cache

control directive that gives
enhanced persistence within

the HTTP cache?

ALEX RUSSELL: I try to rephrase
this as, why is there

no priority system?

Why is their no user expressible
and collaborative

priority system?

So many of the cases where we
wind up fighting the browser

as developers are cases where if
we could express our intent

more clearly to the browser, the
browser could collaborate

with the user to have
a better experience

provided in many cases.

We could then use the browser
to help express to the user,

hey, this is what we're
trying to do here.

And if you say to the browser,
listen, these resources are

really dear to me, these are
slightly less dear, and these

are totally ephemeral, I don't
really need them--

the work that the folks are
doing on Quota API for the

file system points in this
direction, where you're

getting to a point where you can
start to collaborate with

the system and say listen, these
are really important to

me, these are less important.

And I don't think we need to
back ourselves into hard

guarantees, as long as we're
able to say that, by default,

you're in the less privileged
group until you ask for a

privilege, in which case you
take on responsibility to

collaborate.

You might be evicted.

You might get events about
whether or not eviction is

about to happen, and maybe you
should offer up some other

thing to remove or try to remove
stuff for yourself.

This is a well-worn path in
a lot of other operating

systems, where you'll say,
hey, dear plug-in or dear

application, we're running
low on storage.

Can you please clean
some stuff up?

Or where the OS tries to clean
things up for you if it winds

up under pressure.

At that point, you have to
have a conversation.

And today we have no way to
have that conversation.

So it's not that we necessarily
need a different

bar or a different bouncer, but
I think those are just one

way of saying we need multiple
levels of collaboration and

cooperation, and we don't have
any of that right now.

MARK CHRISTIAN: This goes to the
philosophical web idea of

the user agent knows best.

Even when we talk about some
of the new ideas, there's

these heuristics on caching.

And we've never really decided
to empower the app developer

to have much of a say in this.

ALEX RUSSELL: Well,
let's be clear.

The user agent is in control.

It may not know best, but it's
certainly in control, because

we're putting users in control
of their system and their

experience.

So the imperative for the user
agent to have the last say is

all about giving users
the last say.

And so that's an inviolable
principle of a safe web.

The answer was, well, shouldn't
we just count on

everyone being nice?

And the answer is,
no, advertisers.

Duh.

MARK CHRISTIAN: It's still a
very different model than

native apps, though.

And I'm not saying it's a
bad model, but it's just

interesting that native apps
don't have the same set of

constraints on them.

Once they're on the app, then
they can do all of these

things within the sandbox.

And in general, the sandbox that
you'll get on a native

platform is very much wider than
the sandbox that you'll

get as a random website.

JONAS SICKING: Yeah, but there's
still a very big

difference from a random website
and a native app.

Within a native app, the user
has made a decision that I

care about this app, at the very
least enough to bother

with download time.

But it's even more to the point
that the user has said,

I trust this website to
do a lot of things.

Most native apps can take
over your system.

So the user has clearly
indicated that there's some

amount of trust.

And so we can't really ever give
the random website that

the user's visiting the first
time the same amount of trust

as a native app has.

But this is where I think this
smooth transition from going

from untrusted to trusted
needs to happen.

ANDREW BETTIS: Is it ever
reasonable that you could

visit a random website and it
could prompt you saying, this

website wants to completely take
over your computer, do

you want to allow this?

ALEX RUSSELL: Sure, we
have that today.

JONAS SICKING: I don't think we
should have the question to

the user, click the yes button
if you want your system

entirely taken over, click
the no button if not.

Because some people will click
the yes button not knowing

what their doing.

So we need to be more
careful than that.

ALEX RUSSELL: I like to think
about this as what are you

getting back for friction?

So in native apps, there's
much more friction to

discovery and use.

I have to know that I want it
or be told that I want it or

be advertised to as something I
should want and then go buy

it off the friction of
finding this thing.

Whereas the web has this amazing
model where there's a

zero friction to navigate
and use a new thing.

Identity is a problem.

We've got a lot of other things
which add incidental

friction over time, but
generally speaking, we have

paid application developers back
1,000 fold for putting

something on the web by reducing
the friction to using

to almost nothing.

And native app models induce
this friction.

And I think that Jonas is
entirely correct that that

smooth transition needs to get
you to a point where in order

to get the same capabilities
that you would give to a

native app, you have to have
the same level of friction.

Because the constraints that you
impose at those points are

reasonable, and both sets of
system authors have made

choices about which constraints
are going to

impose at each level of friction
under all the same

considerations.

They're saying, if you browse to
an ephemeral web page, then

you get whatever level
of effort you put

into browsing there.

And if you install something,
you get maybe more privilege

and more process available
to you.

And I think that's
the right model.

And so yeah, I think that's
going to be the endpoint, is

well, it will have that
much friction.

And having that much friction
will get you that much.

MARK CHRISTIAN: The smooth
gradient's a really

interesting model.

But I just think that as we're
designing new APIs, we should

make sure that we actually try
to figure out, what does that

smooth gradient look like?

And how can we make the APIs
flexible enough to have a

difference between it's either
working completely or it

doesn't work at all?

ANDREW BETTIS: I think we should
probably move on and

talk about what we can do today
rather than what we

should be doing tomorrow.

So one of the most popular
questions we have is--

a lot of people are stuffing
fonts, images, and JavaScript

in local storage for
fasting loading.

Should we be discouraging
this, which is something

[INAUDIBLE]

was saying at [INAUDIBLE]

and us as well.

So what would you say
to that, Alex?

ALEX RUSSELL: Is it
working for you?

If so, go for it.

I mean, I come from a dirty
JavaScript hacker background.

Man, if it works, run.

Run with it as far as it goes.

But measure.

Measure, measure, measure.

If it's actually faster,
heck yes.

Make the web faster.

Go, do it.

ANDREW BETTIS: So do we need
to be aware of what pain

that's storing up for
us in the future?

And how much pain is that
storing up for us in future?

ALEX RUSSELL: A lot.

So let me tell you
all about it.

So you'll notice if you're
stuffing a lot of stuff into

local storage that you'll see
some really strange behavioral

differences between IE9 and 10,
and Firefox and Chrome,

with regards to potentially
getting out of sync across

tabs or across Windows with
regards to try to communicate

over a local storage.

Well, why is that?

Local storage is a
synchronous API.

This is generally speaking in
terms of web API design a

terrible, terrible thing.

This is a bad thing.

It's the reason that IndexDB
is coming along--

which is available, I think, in
IE10 and it's available in

Chrome and it's coming along
in other places, too.

JAKE ARCHIBALD: Another
terrible, terrible thing.

ALEX RUSSELL: I know.

It's harder to use, right?

So that was the pain.

So that pain generated this new
system which isn't widely

enough deployed yet.

And so folks find out that
there's an implicit cross tab

synchronization issue with local
storage because the API

is synchronous for all the tabs
that can see the same

local store.

This isn't great.

This is actually relatively
terrible.

So we need an asynchronous
version of local storage.

So one of these you're biting
off is a huge performance

issue because you'll start
loading your web page, you'll

ask local storage early in the
document load to go grab you

some resource, and you
think it's fast.

Except we're brand
new to this.

We might have put this in a
SQLite database on a per local

store or per origin basis.

We have to go do synchronize IO
to go load that database,

block that web page, by the way,
while we're doing this,

block the main thread, go do a
bunch of IO, and then give you

the answer.

This is terrible for
performance.

ANDREW BETTIS: OK, so I get it.

I get it.

It's painful.

So should we just not do it
and wait for this amazing

navigation controller
to appear?

ALEX RUSSELL: No, you
should measure.

You should measure,
measure, measure.

And once you've measured, you'll
have an answer about

whether or not it's
better or worse.

But you won't until
you measure.


JONAS SICKING: So I
think there's two

separate questions here.

Taking resources and storing
them locally on the client

side, I think, it's a good
workaround to do until we get

things like this controller
thing, until we fix AppCache,

until we get other mechanisms in
place that actually make it

a pleasurable experience to
develop these solutions.


So the local storage issue of
being asynchronous API--

please to measure it, but it's
actually really, really hard

to measure.

The problem is that what a lot
of asynchronous IO, which A,

is very, very dependent
on a device.

You can't measure it locally.

You need to measure it on
your users' devices.

The other problem is that it's
not a performance hit that

happens every time you
use local storage.

It happens probably the
first time you see it.

And even just like calling--

we've had some benchmarks that
the first thing it does, it

calls localStorage.clear
and then it

starts using local storage.

But at the time you called the
localStorage.clear, that's

actually when the performance
hit happens.

Local storage, I would say,
is hard enough to measure

performance of that
you probably

will not get it right.

What we're doing in Firefox at
22, 21 or something is we're

actually going to pre-load local
storage before we're

even running scripts.

So that performance hit
is not something

you can't even measure.

And the reason we're doing that
is because hopefully in

those cases, we can do this
IO before we're even

attempting to use it.

It does have the effect that
we're going to do more IO for

each and every page on your
website as soon as you use

local storage.

But that's to avoid halting
the thread and having your

site look up while you're
doing this IO.

So local storage's performance
is really, really tricky.

So IndexDB has issues.

Those are, in big
part, my fault.

I'm one of the editors
for that spec.

We do need something like
asynchronous local storage,

which is as simple as local
storage but doesn't have the

synchronous problem.

So that hopefully
will come soon.

ALEX RUSSELL: I'm hoping
for that, too.

ANDREW BETTIS: OK, so in the
meantime, do you think that

the fact that developers love
local storage and don't like

APIs like IndexDB is an
indication that we need to

simplify IndexDB and Web SQL
and those sort of APIs?

ALEX RUSSELL: Yes, absolutely.

So one of the things that I've
been working on over the last

couple of months is to add
a futures primitive.

So you might have promises
in your libraries.

We're just going to ignore the
fight over what it means to

have a promise.

We're going to call
it a future.

It's a different thing.

Same API.

.then, and then you can add
whatever callbacks you want to

success and failure,
accept or reject.

OK, cool.

So we're building a spec for
futures for DOM, so we can

start to reinterpret a lot of
these asynchronous things in a

more unified way.

Because events aren't really the
right model for something

that is a single request.

If I get one thing out of local
storage, I'm only asking

for one thing back.

I'm not asking for a potential
stream of things to happen

zero or more times in
the future, which

is the event model.

So I have hope that we'll be
able to build a saner version

of a lot of these APIs to stop
using events and stop using

implicit asynchronicity and end
of term behavior and make

it much more explicit in the
APIs, do an asynchronous local

storage on top of something like
this, and then Web Crypto

and IndexDB, I think all these
APIs can be retrofitted with

this model so that we get a
much more rational API.

I think a lot of this is down to
the APIs not really having

great idioms baked into them.

And it's one of these
traditional DOM versus the

rest of the JavaScript world
discussions, which I'm happy

to talk to you about over
beer endlessly.

ANDREW BETTIS: So how long
until we get navigation

controller?


JAKE ARCHIBALD: I'm not taking
responsibility for that.

JONAS SICKING: So the space of
fixing the AppCache where

navigation controller is a very
interesting proposal is

something that for some reason
we had a very, very hard time

actually getting to the point
of having proposals.

I would say we've been working
on this for well over a year

and a half, probably two years,
on just people ranting

about how much AppCache
sucks, but there has

not been any proposals.

There are now two proposals.

There's the controller thing.

Mozilla also has a proposal that
we're hopefully going to

present very soon.

And I think that's an enormously
good first step.

What we need to do once we have
these proposals is to get

feedback from everyone
that has been

complaining about AppCache.


The two proposals are actually
very complementary, so they

actually combine very well.

If you had these two
things, would

that solve your problems?

Or would this just be
a less sucky way?

So we have a very
good first step.

It will take a little bit to
get this stuff implemented,

but I think it'll take a lot
less than the well over a year

that we've been complaining
about AppCache.

JAKE ARCHIBALD: So on the
simple APIs, do we build

something really low level and
maybe a bit more complicated

to deal with, or do
we just try and go

as simple as possible?

We want something as simple
as possible, but look what

happened to AppCache.

They made something that was
really, really simple, but

they didn't know what people
really wanted to do with it,

so they made some things
simple and useless.


Whereas with local storage, that
was the simple and easy

to use but had massive
performance problems.

So I like the world where you
might have something like

IndexDB, where it's what you can
do with it-- there's loads

you can do with it--

but then have a look at what
the use cases are.

See what code you see people
repeating over and over.

What are people using libraries
for, and how can we

get that into the problem?

You see that happening
with the DOM now.

querySelectorAll was one
of those things.

We see jQuery doing it.

We can make jQuery faster by
having that on the platform,

and people maybe wouldn't
have to use jQuery

if that's the case.

So that's what I see going
with the navigation

controller.

Some of the code that I showed
on there was stuff I made up.

There was a routing function,
which is something that

probably won't be there in the
initial spec, but it's

something you can create
yourself or something a

library can give you.

And we'll be able to see what
people are doing and if

there's common patterns or a lot
of repeated code, then we

can put that in the platform and
make it quicker and make

it less typing.

MARK CHRISTIAN: Yeah, we can
trust that libraries will come

into existence.

It's something that we can
rely on on the web.

So we should build for
flexibility instead of stupid

simplicity.

ANDREW BETTIS: Well,
we're out of time.

So thanks, everyone.

And that's the end
of the panel.

[APPLAUSE]



IVAN ZUZAK: Hey, everyone.

So I noticed on Moderator that
someone said, why do we have

testing and tooling
in the same panel?

So we will try to cover
both topics equally.

And with that, please join me
in welcoming Simon Stewart.

He works at Facebook, and he is
known for creating Selenium

and WebDriver.

Next to him is Remy Sharp, who
is the creator of JS Bin, JS

Console, and he curates the
Full Frontal conference.

David Blooman from BBC
News, who is the

testing superhero there.

And next to him is Paul Irish,
who is our opener.

He is a guru on the Chrome
Developer Relations team.

And he's also known for many,
many developer tools, such as

Modernizr, Yeoman, et
cetera, et cetera.

So I will invite Paul to give
an excellent introduction.

[APPLAUSE]

PAUL IRISH: All right.

I'm going to go fast on this.

And I apologize, because I'm
speaking with an accent, for

probably most of you.

But we're going to go quick.

First, I'm going to give
a lay of the land

of the tooling ecosystem.

And then I'm going to give a few
demos showcasing some of

the cool stuff that's emerging
or things you might have not

seen in this area.

So first, it's hard to
conceptualize as far as all

the things that are captured
by tooling.

This is one approach--

Addy Osmani and I
worked on this--

kind of laying out a bunch of
the tools as far as the life

cycle of a project, from
boilerplate to abstractions,

the application stack, and then
into workflow performance

and builds.

But then we in the group here
were thinking about something

along these lines, too--

this is very much in
the tooling vein--

the package and dependency
management of my application

source code.

What my editing experience is
like, what the tools that the

browser actually provides is.

When it comes to testing, both
unit testing, integration

testing, CSS testing.

I'm going to show a demo
of some of that.

Then build and deployment, how
I'm automating browsers.

I'm probably going to be doing
that inside Continuous

Integration.

And then there's a lot
inside mobile.

So handling mobile devices,
whether they're local or in

the cloud, there's a lot.

So I want to dive into
a few things.

So CSS testing, this is a
fantastic slide deck and site

put together by Simon Madine.

This is focused on
four styles.

How can we better have
a feel for if we're

screwing up or not?

One of the projects that's
listed here--

a number of these are pretty
young projects, but this one,

called Fighting Layout Bugs,
has been around for about

three years.

And it's actually offered
in Java, mostly

for use with Maven.

And it does things like
these five tests here.

One of them is DetectTextNearOr

OverlappingVerticalEdge.


But what you'll end up
is this sort of test.

So it can actually detect when
you have text that's running

up against something
like an image or

even overflowing here.

And this is completely
automated, so on every commit,

Finding Layout Bugs is going to
make sure that you do not

have one of these problems
in your target browsers.

Pretty cool.

So you might be running this
inside Continuous Integration,

and I've seen a lot of movement
here recently.

Travis has kind of opened up
everyone's eyes in the open

source world, as far as
what can be done here.

This here is Travis running
the new Dojo 2 tests.

And so actually, Travis pulled
down the latest Dojo 2 source,

built out what it needed, and
then it connected up to Sauce

Labs, and opened up a bunch of
desktop and mobile browsers,

and ran the test suite of
Dojo 2 on all of them.

Reported back, and now for every
single commit and every

single pull request, we know
if we are looking good and

green or not.


Telemetry was mentioned
a little bit before.

And I just wanted to give a
better idea of what it does

and how it works.

Unfortunately, it requires a
check out of the Chromium code

base, which is about five gigs,
and I didn't want to

pull that down on the Wi-Fi.

So let me just talk it out.

Telemetry would take something
like this page.

Now, it's going to do something
like scroll the page

down, and it's going
to pop back up and

scroll it down again.

While it did those two things,
it's going to be extracting a

bunch of metrics from
the browser.

Like what was the paint rate?

How many million pixels per
second are being painted?

What was the FPS?

And now it's going to take all
these metrics and provide them

to me in a nice way.

And then I can take this and
plot it out against time or

against all my commits and
see, are my performance

thresholds being met
as the project is

growing and as it's living?

Or are me and my teammate adding
things to it that kill

the visual performance?

So there's a lot
of power here.

Another project from
the Chromium

team is called Endure.

This is something where you
can write a test like, OK,

open up Gmail, start
composing.

Now discard.

Start composing again.

Discard.

Repeat this for six hours.

Now tell me what's up.

So Endure will take this and
just handle the browser

automation for you.

And then it will give you back
some really fantastic insight

on the memory consumption of
this application over time

across a number of
different axes.

So you're able to understand
if you're increasing in an

uncontrollable way in your
memory situation.

All right.

Now, we've seen a lot of new
advancements when it comes to

mobile and cross-device
testing.

This was a project I bet a
number of you have seen called

Remote Preview, where I can
navigate to a URL here on my

machine, and all the browsers
follow my navigation.

Adobe Edge Inspect also has
a similar functionality.

And so it's cool.

I got all these phones right
here, and they're just

following me around.

It's pretty fantastic.

Mixture is another project.

Does some fantastic things.

It also does the same
thing, but on top of

this, it will add--

let's say there's a button.

I click it.

It pops up a dialogue, and
I close that dialogue.

Mixture will do the same stuff
but actually repeat those same

actions on all of these
devices as well.

So not just navigation but
actual click events so you can

see and verify that things are
occurring the way that you

would expect.

Now, I think it's cool to have
all this on devices that are

next to you.

But not everyone can afford all
the devices that you need

to actually support.

So we've been seeing things like
cloud browser testing.

BrowserStack is one I think most
people are familiar with.

And for mobile, they use
emulators, which is cool.

DeviceAnywhere actually features
real devices, which

is pretty cool.

It's a paid service, though.

They did just recently offer
this free service.

So I'm opening up
an iPhone 4S.

So this is actually a real
device, and I'm able to kind

of play around with it--

[INAUDIBLE]

Google News--

and click around.

I can also do--

let's see, I can mimic
a swipe and see that.

And you can see that the
performance here is actually

pretty good.

It's telling me that
my latency is OK.

And so this could actually even
get quite a bit better.

But it's pretty fantastic to
connect to an actual device

and get a better idea of
what my performance

situation is on that.

This is a project that is
totally alpha and has never

really been shown at all.

So I just want to FYI.

It's got some rough edges,
but it's pretty cool.

It's a project from some
engineers at Google.

It's called Tracing Framework.

And it's a bunch of analyses
for smoothness

inside of the browser.

And so the cool thing about it
is the instrumentation is

written completely in
JavaScript, which means it

runs in Chrome, Firefox,
IE, mobile

browsers, and web views.

So if you ever feel like you're
in a situation where

you do not have the browser
tooling to give you enough

insight in any of these
situations,

check out Tracing Framework.

Still, it's rough in alpha,
but it's worth a look.

Now, this conversation wouldn't
be complete without

talking about the dev tools
that are in the browser.

And I wanted to show
a few things.

The first up is Canvas
Inspection.

And the cool thing is we've
never showed this before.

And it's coming out.

It's still kind of
an experiment.

But I'm excited to show it.

So I brought up here this
WebGL Aquarium.

It's pretty cool.

Now, when we're in Profiles, we
see Capture Canvas Frame.

But I actually need to have the
dev tools open while this

canvas is created.

Now I'm going to capture
that frame.

And up here, it looks like we
captured it at 4,300 calls to

the context.

And these are all the calls that
were made that changed

the context.

And I can step through
all of them.

And what it's going to do is
it's going to replay all the

calls up to this point.

And I can set through
all the draw calls.

Let's see.

Give me some fishes.


Fishes!


Fish, fish.


Yeah, good.

Great.

Fishes.

So we're able to see
step-by-step as this frame is

being constructed and correlate
that back to my

actual code of what
was happening.

So I can click over there and
see this, in fact, was making

these draw calls.

Now, I don't know if you guys
noticed this, but when I

actually clicked from Profiles
over into the Sources panel,

there was a little
bit of a delay.

Now, let's say I actually want
to figure out why there's such

a delay there.

So first, I'm going to undock
this move over that guy, and I

think you see what's happening
here is that I'm using the dev

tools on the dev tools.

I'm going to start a new
timeline, and I'm going to

repeat this action.

And there we go, capture that.

So inside the timeline, we're
getting some good information

on how long things like
paints, recalc

styles are all taking.

And over here on the left-hand
side, we can see this yellow.

And this is my click event.

And we can see that it
was pretty long.

In this case, it
took almost 400

milliseconds to complete that.

Now why was that?

Eesh.

So you look over here, and you
see this is what happened

inside that time.

We got a lot of Recalculate
Style and Layout, and Recalc

Style, Layout.

And this is what we were talking
about before when we

were talking about excess
reflows, layout thrashing.

Layout and reflow are the same
thing across browsers.

But this is a bad situation.

This is a pattern you
want to avoid.

And the cool thing here
is the dev tools are

actually telling you this.

There's a little indicator that
says you might have a

problem. "Forced synchronous
layer is a possible

performance bottleneck." And
the fact that we're seeing

this nonstop back and forth
means there's probably an

ability to optimize.

So Pavel, you should
probably optimize

this in the dev tools.

Sounds good.

All right.

So a lot of times, there is
a problem with paint.

Paint is consuming a lot of
time, and it's a little hard

to get a feel for
what's going on.

So earlier in some talks, they
brought up continuous page

repainting, and I want to show
what that looks like.

Let's try this guy.

Yeah, cool.

All right, bringing back the dev
tools, I'm going to dock

them again.

And over here in the settings,
I'm going to turn on

continuous page repainting.

So up here, we get an idea of
how long it's taking to paint

this page right here.

So let's say right now it's
taking about 15 milliseconds.

But first, I'm going to go over
here, and I'm going to

turn off some of the styles.

So on each of these little
Chrome logos, I got a box

shadow and a border radius.

I'm going to clear those off.

And my paint time jumps
down, which is good.

It's much cheaper to
paint this page.

Now, the interesting thing here
is that because I have

this live feedback and kind of
play around, I can see what is

contributing to long paints.

So if I add on border radius,
you can see it jumped up from

about twos and threes up
to the fours and fives.

Cool.

Take that off and put on box
shadow, which is normally kind

of expensive, you hear.

But my paint time is actually
pretty reasonable.

But check this out.

I add both of them--


ooh--

and my paint time just
went up to about 20

milliseconds per frame.

And so I get great feedback
here on what is actually

contributing.

It turns out that by themselves,
these styles,

they're pretty cheap.

But in combination, the browser
takes a little bit of

time on it.

Now, painting can be expensive,
and there's a lot

that could be done.

And I wanted to show one thing
that has been done recently.

So--

cool.

This right here is Chrome
for Android stable.

And so we have an article
on HTML5 Rocks.

And now what I'm going to do
is just scroll the page.

Scroll.

There we go.

Cool.

And you see I'm scrolling down,
and the browser kind of

catches up.

But for a little while,
the page is blank.

And then it comes in.

So it's probably not optimal.

We just added a new thing to
Chrome on Android called

multi-threaded painting.

And so here--

so this is Chrome for
Android beta.

You can get this from
Google Play.

Now if I scroll, I think you
see that there's no white.

That's cool.

Another thing--

you might be able to see it--
is the text actually gets a

little blurry when this
is going too fast.

And we have low-res tiles that
are in place just in case

you're moving really, really
fast, that it will resolve to

the crisp picture that
you're looking for.

So this actual painting is
happening on a separate

thread, which is pretty cool,
one, for the performance

benefit, but two, for speed.

Over here, this is
about tracing.

I think this has been mentioned
before as well.

Here, we get kind of--

I mean, this looks
intimidating.

And it is, but there's good
ways to read these things.

So right now, I'm zooming in
on the RendererMain thread.

This is the UI thread.

This is the "don't block
this thread" thread.

There's a lot of other parts
in the browser, like the

compositor up here, but I'm
going to jump in to this guy

and zoom in.

And down here, we've
got a few things.

V8.callFunction.

This is JavaScript.

JavaScript is running
right now.

And then, all of a sudden,
we hit Picture Record.

So this is a capture from Chrome
Canary on desktop doing

multi-threaded painting.

And this Picture Record is
actually recording all the

draw calls that are coming
into Chrome.

And Chrome is like, OK, I've
got all these draws.

Here they are.

I'm going to pass it up
to the compositor.

The compositors are like, cool,
I'm going to spawn off a

new thread that's
CompositorWorker, and he's

going to take care
of this for you.

So CompositorWorker right here,
he's doing the paint.

This paint raster right here
is the actual paints.

And what this means is because
this is on a separate thread,

I can now be executing
JavaScript at the same time.

So here we are in v8, executing
JavaScript at the

same time as I'm doing paints.

We haven't been able to do
this before, but now it's

finally happening.

I'm really excited about that.

All right, the last thing I just
want to mention is I'm

not going to demo Remote
Debugging, but everything that

I showed is available, just
the same thing, just

connecting on here.

Really fantastic, because the
performance characteristics on

a device with hardware that is
so different as a laptop is

something that you really want
to be very mindful of as

you're developing all
these experiences.

Lastly, a few trends I think
I've been witnessing and will

continue in 2013.

We're seeing a rise of people
leveraging Continuous

Integration, not just for
running things like unit tests

but also making sure that
there's no performance

regressions as the project
is built out.

Things like people are focusing
on a better mobile

debugging workflow and making
sure that for throwing tests

on there, getting tests out of
it, and seeing their work,

that everything is working
very nicely.

A bigger adoption of using
dependency management, not

just for third-party libraries
but also for your own

application code, and people
being very mindful of

performance from the beginning
of the project so that a

project can sail nicely from
these devices to these

devices, and all your
users are happy.

That's it for this little
opener, and let's

get into the panel.

[APPLAUSE]

IVAN ZUZAK: That's awesome.


[INAUDIBLE].

PAUL IRISH: I do.

IVAN ZUZAK: OK, that's
all we have as intro.


So there is, like, 30 questions
on Moderator--

33.

And let's just try to
get as much through.


So the first question that
[INAUDIBLE], also from Google

Chrome Developer Relations put
on Moderator was, mobile is a

big focus for developers
this year.

So what do you see as being the
biggest pain points in the

mobile test--

mobile tooling landscape?

And I think everyone can just
chip in what they think.

So let's start from Remy.


REMY SHARP: The other browsers
is the big pain point for me

at the moment.

The fact that I've got Dev Tools
on Android is amazing.

But then I have to use Safari,
and that's horrible for me.

And that has kind of
set me up to--

I've started a project
in my company--

very, very early days-- where
I'm trying to get the point,

ultimately, to just use Dev
Tools to debug every single

mobile platform--

Safari, Firefox, Opera, Chrome,
Windows, all of them--

using the debugger protocol.

And it's not so much of an
automation tool, and it's

having the hardware there but
using just Dev Tools to go in

and do that micro debugging, but
have one familiar tool and

just debug the other tools.

I hate working with Safari's
remote debugger.

It's great that we've got it,
but I really, really struggle

with the tool.

So the pain point, for me, is
it just kind of exposes how

bad the other dev tools are.

IE 10 mobile, that's
a great browser.

But where are the dev tools?


SIMON STEWART: OK.

So the desktop world was
surprisingly simple, entirely

by accident.

But it was surprisingly
simple.

We only had web apps running
in a browser,

and that was fine.

The mobile world, because the
devices are underpowered, and

they're a little bit puny, and
Moore's Law is helping, but

they are improving.

The apps we get when we need
to test aren't just

running in a browser.

They're running in web views
contained within the native

application.

And you need to be able to test
the communication between

the native part of the app in
the web part of the app, and

the web part in the
native part.

And who knows, right?

It's a complete nightmare.

So not only do we have a more
complex testing environment to

begin with, the tooling
just isn't there.

It's still early days.

There are very few tools out
there that can actually be

used to test a hybrid
application successfully and

in a way that won't cause your
developers to scream at you in

just pure rage and
frustration.

We'll get there one day, but
that's the main pain point,

just that the tooling
isn't there.

DAVID BLOOMAN: Yeah, similar
to Remy, but [INAUDIBLE].


I don't like Safari at all,
so I don't use it.

But the generic Web Inspector
Remote has been quite

successful, quite
useful for me.

But that's only for
WebKit browsers.

But what about everything
else?

And things like BlackBerrys,
which are still very high

usage and something like News
is very difficult to do

anything with.

And then automations, iOS and
Android are pretty much the

only two platforms.

So you're stuck with them.

Even the new platforms, like
BlackBerry, how do you even

approach them with no tools?

You can't do much with them.

So there's a lot lacking.

And hopefully, some nice people
will come along and

build something new, and
the tools will mature.

But there are still the legacy
browsers and operating systems

that we're going to have to
deal with for a long time.

So tooling is going to get
better, but it's also going to

stay bad at the same time.


PAUL IRISH: I would say one part
of this is that I think a

lot of developers' workflow for
their mobile testing is

extremely manual.

It is a matter of putting up the
newest version on stage,

hitting Refresh, seeing,
exploring, then going to the

next device that has the
viewport that they care about,

and hitting Refresh,
testing that.

And I think it's just
really slow.

And there's a lot of existing
solutions that can totally

improve that.

And I think that's worth
looking into.

The other part that I think is
important-- and I mentioned

this in the opening, which is
that I don't think every

developer can afford all the
devices that they need to be

testing on.

I mean, the Remote Debugging
capability that we're seeing

is very important when you
have the device there.

But I do think that
having access to--

being able to run your
application in these mobile

devices that you don't actually

own is really important.

So I'm looking forward to seeing
how we can solve that.

Yeah.

IVAN ZUZAK: Great OK,
so let's continue.

The question is, what are
currently the best tools and

workflows for testing and
debugging mobile devices?

And I think David
can start this.

DAVID BLOOMAN: Yeah,
so I've tried to--

in my role at the BBC, tried to
just use as many tools as I

can, really, to get the best
out of all our devices.

But as you said, it's a
very manual process

a lot of the time.

But we've implemented, recently,
the CSS Regression

Testing, which internally we
call a "snappy snaps." So it

will capture two images
of two domains.

So we use a stage and a live
environment, every

[? resolution ?] we really want,
and then various asset

types, so front page and story
pages, and then compare them

using ImageMagick to output a
[? DIF ?] image, which you can

then review.

So you can test a massive amount
of pages of different

resolutions very quickly and
identify the differences and

then collaboratively decide
how you want to

move on from there.

So there are tools like that
that really just cut down the

amount of manual testing you can
do, because you can just

automate a lot of it.

ImageMagick is a very powerful
tool, so you can use

percentage differences,
as well.

So it's just a series of numbers
that come out, and you

know whether you've got
huge CSS regressions.

And again, tools like Web
Inspector Remote and Remote

Debugging on Android, especially
of picking up

networking things, like are we
making sure that stats are

being recorded over the Chrome
Dev Tools is so important.

And using those tools has been
really beneficial for us.

There are other tools, like
Remote Preview and Adobe

Shadow, which you can use.

But the things is that Adobe
Shadow or Edge Inspect is a

costly one.

And I think that's where the
cost element is quite

difficult in mobile
[? responsive ?]

because you need all the devices
in a lot of cases, and

financially, it's impossible to
have for an independent or

small company.

BrowserStack is a good option.

And I haven't really looked into
TestPlant, but it's an

option as well.

But there are some good tools.

I think if you're interested,
there's a great amount of

tools on RGA Online, a site
which will point you in the

right direction.

IVAN ZUZAK: Great.

Simon, what can you tell
us about WebDriver?

SIMON STEWART: Yeah,
WebDriver.

So tools for doing testing
on mobile.

The first thing I was going to
suggest was it isn't that

different from being on
the desktop, right?

So you could use all the
JavaScript frameworks that are

already out there, things like
Jasmine, for example, if

you're a BDD fan, still work
in a mobile browser.

And a mobile browser nowadays
runs on a device that has the

same power as the old G5 Macs
that people used to do their

development on.

We think of them as underpowered
devices.

They're enormously
capable, and they

keep on getting faster.

So you could keep
on doing that.

I obviously have a
vested interest.

I am the lead of the
Selenium project.

I invented WebDriver.

We're standardizing
that with the W3C.

Hopefully, the best way to test
mobile browsers will be

to use the WebDriver APIs, which
will enable you to do

all sorts of fun things,
particularly from the point of

view of automating a browser
from a user's perspective.

Go to this page, click on this
link, execute this piece of

JavaScript.

Now let me see what the text is
on the page as a user would

see it, which is an enormously
powerful thing to do.

And I've been on projects
where we've had those

end-to-end tests, smaller
integration tests, unit tests,

realize that we've made some
fundamental failures in the

architecture of the application,
thrown away every

test apart from the WebDriver
tests, and rebuilt everything

just using those.

So if you write them well,
they can work.

If I was going to name
frameworks, obviously Selenium

is probably one that I
would rush out and

download right now.

I'm biased, though,
so that's OK.

For mobile, it might be worth
having a look at a thing

called iOS Driver, which is
written by Francois Reynaud,

who is working at eBay.

And Sauce Labs recently put a
lot of weight behind a project

called Appium.

So if you go to saucelabs.com
and take a look for Appium on

their site, you'll be
able to find it.

Both of those are for iOS.

And they allow you to test
native apps, hybrid apps, and

just plain web apps, as well.

So that's pretty cool.

On the Android platform, I think
it's still fair game.

There will be something that
uses UI automation.

And there's going to be a period
of about a year, two

years, while people
go, what about the

older versions of Android?

They're still really popular.

And then people will realize
that it's a pain in the

backside to test those things.

And time will be on our side,
and hopefully, we'll only have

ICS and above in about 50 years
of something, in the way

that Android is updating.

But it'll happen eventually,
and that will

be extremely cool.

IVAN ZUZAK: Want to add
something, Remy?

REMY SHARP: Yeah, I'm
more in the kind of

debugging end of things.

So actually, for a project that
we are releasing for a

client literally Friday, we're
trying to get the last style

changes in.

And we've got this iPad Mini,
and what I ended up doing was

using Dev Tools in Chrome,
having it save as I was making

changes to the local disk, and
then I had LiveReload just

sitting on there.

And the UX guy was sat next
to me with the iPad.

And he was like, OK, just
tweak this color.

I'd tweak it on my desktop.

And in the inspector, I'm
changing the color and

releasing, and it's immediately
on the iPad Mini.

Which for me, getting away
from coding, saving,

switching, hitting Refresh,
going to the device, hitting

Refresh, that's where I
live at the moment.

And the closer I get to actually
using the browser as

my development--

an IDE by IDE--

the happier I get.

And I'm really impatient.

I want that feedback.

I want to know now.

And I want it all reloading
live, and my workflow is

getting really, really
close to that.

And I see some of my guys
working, using--

in JS Bin, we've got a remote
rendering feature in it so you

can code away, and it will just
automatically update on

the device.

And I see them actually using
that as well, which is really

cool for me.

But yeah, basically, immediacy,
that's what

[INAUDIBLE].

IVAN ZUZAK: So there's this
question from Addy again.

And he says, seeing browser
developer tools flourish into

fully blown editors
is very exciting.

And at what point should we stop
pushing the envelope and

suggest developers use
their own tools?

So do you think that will
happen, or will we push the

envelope far and beyond and
use browser dev tools for

everything?

REMY SHARP: For me, personally,
I'm much more

towards the end of using the
browser as close as--

I want to get the output, the
rendered page, and what I'm

typing as close as possible.

I'm typing, I want to see
the output immediately.

If it lives inside of the
IDE itself, then fine.

But at the moment.

Dev Tools is kind of ticking
that box for me.

IVAN ZUZAK: So are there any
key parts that are missing

from dev tools currently for
any browser for you?

REMY SHARP: The testing,
for me.


Event proxying--

that's something I mentioned.

SIMON STEWART: That's
in WebDriver.

REMY SHARP: What's that?

SIMON STEWART: WebDriver's
got that.

REMY SHARP: I haven't
seen WebDriver.

SIMON STEWART: It's being
standardized.

REMY SHARP: So one thing that's
missing for me is I

don't want to type in a lat-long
to be able to emulate

geolocation.

I want my phone to
give it to me.

The accelerometer, I
want that to feed

straight into the desktop.

I know Paul and Addy
have hinted at, or

might mention something.

PAUL IRISH: There's likely going
to be some more stuff

that would make Remy happy, as
far as developing in the

browser more.


And actually, to add on to a
little bit of the mobile tools

and workflows, we talked a lot
about what are the ways to

work with these devices.

But the other thing is that a
lot of times, you can end up

doing a lot of development just
on desktop, straight up.

Firefox has a fantastic,
responsive design tool built

into their dev tools now.

Inside Chrome, there's
device metrics.

And there's, like, 50
different sites and

bookmarklets to get various
different iframes so they can

test your viewport
for any site.

But things like emulating touch
events, emulating and

spoofing geolocation,
these are all in the

browser now, too.

So there's a good amount that
you can get away with on

desktop before you go to the
device to make sure that your

performance goals are
being met, too.

So I'd add that in.

SIMON STEWART: Right.

So I think one of the things
we're missing here are the

audiences for testing, right?

Your workflow sounds very
developer-centric, like you

want to make sure that the CSS
and the UX is perfect.

The people that tend to use
WebDriver tend to be more

interested in the end-to-end
testing and the functionality

of the application, particularly
as a workflow or

a walkthrough goes.

So I probably wouldn't recommend
end-to-end testers

use dev tools, because it's
not the right hammer to be

hitting this particular
nail with.

And it's got to be like take
a look at what people are

actually attempting to do and
their relative skill levels

and try and figure out what
the best approach is.

For a handful of people, being
in the dev tools and being

highly technical and getting
all the metrics out of the

browser is entirely the
right thing to do.

And that's a fantastic option
for those people.

But for hundreds of people, for
a majority of developers,

actually, it's enough to be
able to throw something

together with a bit of Python
or a small amount of

JavaScript and use that to
verify that the application is

doing what it's meant
to be doing.

So yeah, think about the
audience of who's going to be

using this and how they're going
to be using it and how

they're going to be integrating
with the team.

And it may turn out that
actually, not being in the

browser is a better way
of going about it.

And sometimes, it's
going to be better

to do things manually.

"Does this feel right" is a
really hard question for

machine to answer but a
really easy question

for a person to answer.

REMY SHARP: Can I just tack
on to the end of that?

I can't remember who the
conversations were with, but

I've got a feeling it might
be Paul, like a year ago.

Web developers don't jump on
to the command line as

frequently as a Python developer
or a Ruby developer.

I'm comfortable with
the command line.

But out of the web developers
here, you probably do

server-side coding, anyway.

But hands up who's pretty
comfortable using the command

line or coding up--

actually, this is a bit
of a [INAUDIBLE]

[LAUGHTER]

REMY SHARP: It's a technical
audience in the first place.

Loaded question, bias,
so on and so forth.

But there's that question
as well.

IVAN ZUZAK: So it seems like
having a huge number of mobile

devices is the only way to
reliably test on Android and

BlackBerry.

Is there any hope of having
accurate, reliable emulators

for platforms other than iOS?

REMY SHARP: I would add iOS
to that list as well.

IVAN ZUZAK: Yeah?

Anyone?

So is there any hope for having

really reliable emulators?

SIMON STEWART: No.

IVAN ZUZAK: Excellent.

REMY SHARP: Just to
give Opera props,

isn't the Opera emulator--

isn't it supposed to
be exactly the

same as Opera Mobile?

AUDIENCE: [INAUDIBLE]

backed up.

But it obviously doesn't have
the same [INAUDIBLE]

device.

AUDIENCE: WebOS is
pretty good.

IVAN ZUZAK: Hmm?

AUDIENCE: WebOS is
pretty good.

PAUL IRISH: WebOS.

Yeah, I think you could say
that there is hope that

they'll get better.

I would expect those
vendors to put

support into those tools.

So yeah.

SIMON STEWART: Great.

More optimistically than
just a flat no.

I think the Pareto principle
is going to kick in here--

the 80-20 rule.

Testing on a simulator and
emulator is going to be fairly

close, and in the common case,
actually enough for our

testing needs.

But there's always going to
be some weird quirk in the

hardware that we're going
to need the devices for.

So are the emulators going to
get enough where it'll move

away from the 80-20
to 90-10 or 95-5?

I don't know.

But having seen the progress of
the Android emulator, which

has gone from being quite
painful to use to actually

being good enough to do a
majority of my testing on,

particularly with the Intel
version that's available now,

yeah, I'm actually relatively
hopeful about hitting the

90-10 point.

IVAN ZUZAK: Excellent.

REMY SHARP: There's a
question over back.

AUDIENCE: I just want to
give a shout out to

opendevicelab.com, which is
actually opening device labs

all over the world right now.

They've got 40 locations.

One of them is a
Mozilla office.

Google is thinking about it.

So if you've got hardware you
don't use, you can donate it

to one of them, and every
developer can go there and try

on real devices to play
with their things.

Because we can make emulators
as much as we want.

Most of the errors come through
touching and playing

with the thing on the
real hardware.

When I put Firefox OS on SIIs,
three devices, same device,

completely different results.

So it's not that easy.

But OpenDeviceLab is a really,
really good idea for people

that can't afford all these
phones to actually play with

them in an office that
is a sharing space.

And there's lots and lots
of them worldwide.

So just wanted to
mention that.

PAUL IRISH: They also have a lot
of information for people

that want to set up their own
device labs, too, and

community support for that.

DAVID BLOOMAN: I also, if I'm
passing a phone shop, I'll

just go in and have a play,
see what's going on.

And I recommend you do, too,
because the important thing to

know is what's in a shop
is what somebody could

potentially be using to
access your site.

So that's a great idea
of what exactly is

going on in the market.

And obviously, it's going to be
market specific, but you'd

be surprised at some of the
travesties that are in phone

shops nowadays.

So yeah.

AUDIENCE: Really quick, it's
worth pointing out that most

of the emulator execution is
somewhere else in the stack.

There's a great company
called [INAUDIBLE]

Incorporated, which has proven
that they can run ARM code on

x86 faster than ARM
executes on ARM.

So obviously, the problem isn't
with the ARM device or

the instruction set.

It's somewhere in the
stack to get these

emulators up and running.

Most of the time, it's a balance
between the teams

trying to get their products
out the door

versus actually caring--

or to put it in correct
terminology, since we're about

to have beers-- giving enough
shits about getting their

emulators up and running.

So if this is something that
matters to web dev as a whole,

you should definitely be putting
more pressure on these

manufacturers to get
their emulators up

to speed to do things.

IVAN ZUZAK: Excellent.

Great.

So let's switch gears a bit.

Here's one of my questions.

Will we get a solution for
package management and module

loading soon?

There have been several tools
that have shown that it could

be done, but there's
no real consensus.

And will ECMAScript 6
modules solve this?

And Addy corrected me.

So these are actually two
questions in one.

And package management
is somewhat

separate from module loading.

So this is a real problem
for a lot of developers.

And Paul, perhaps you
can start this.

PAUL IRISH: Sure.

So right now in client-side
package management, there's a

few possibilities.

A while ago, there was a project
called Ender, and the

people who made Ender decided
that it didn't really work

out, so that's mostly dead.

There's also volo, made by
James Burke, who created

Require.js, which
is pretty cool.

Bower, originally released by
Twitter, and there's also a

lot of folks using NPM, sending
it through Browserify,

and getting it to work there.

And these are all kind of
using different registry

approaches, different ideas on,
should we start an entire

new JavaScript library ecosystem
from scratch or use

one that's already available?

Do we just accept that we can
use node packages inside the

browser and make that work?


And it's kind of messy
right now.

I mean, I'm most excited about
what's happening with the

Bower project.

It has about 900 packages
in it, all working.

Dependency resolution
works fantastic.

You actually get updated inside
the UI when JavaScript

library ships a new version.

So it kind of keeps
you up to date.


But there's a lot of challenges,
because package

management for client side is
something where it's useful

when it hits a critical mass.

And I don't think
we're there yet.

So I'm looking forward to seeing
what we can do, either

inside this tool or another
tool, to kind of get there.

Because without package
management client side,

everyone's going to be afraid of
calling jQuery dependency.

And jQuery is already too big.

So it could have been smaller
had we had proper package

management.

And I think it would really open
up a lot of progress and

forward momentum in what we're
able to get away with on the

front end when we can actually
create reasonable

dependencies.

IVAN ZUZAK: So there's this
point where at one point,

standardization should
come in?


PAUL IRISH: Alex?


You want to talk about
ESX modules?

ALEX RUSSELL: Sure.

So I'm Alex Russell, Google, one
of our representatives on

TC39, the standards body
for JavaScript.

So there is a module system
coming in the next version of

JavaScript.

Will you be able to use it on
all the devices that are

deployed today?

Well, that depends on whether
or not you're

targeting new browsers.

So the answer is no.

At least no in the short term.

In the long term--

well, in the intermediary time,
you'll be able to use

tools like Tracer and
other transpilers--

JavaScript to JavaScript
compilers--

that will allow you to sort of
program in the source language

and then convert to the other
one, based on a standard

syntax, which sort of sets you
up for living in the wonderful

future that will eventually
arrive.

So that's a strategy that
you can use today.

There's a little bit of tension
right now in the

committee about what's going to
happen with the particulars

of the syntax and some
of the semantics.

And we're ironing
those out now.

But the goal for us is to have a
version of the language that

has this done, more or less
feature complete, by the end

of the year.

So wish us luck.

And I guess if you'd like to
start using what is likely to

become the module system for the
next version of ECMAScript

today, it's not a
package manager.

It's just a module system.

But you can check out Tracer
and a couple of other

transpilers that are starting
to support it.

IVAN ZUZAK: Good.

So while you have the
mic, I want to

ask you another question.

So what should be the role
of standardization in web

development during testing, and
what are some of the areas

that would benefit from
standardization right now?

ALEX RUSSELL: OK, so with my
non-Google hat on, with my W3C

TAG member hat on, let me answer
the question in terms

of, what's the role of
a standards body.

My view is that the role of a
standards body-- and this is

not the TAG's view, but it's my
personal view-- is that the

role of a standards body is to
hold the coats while everybody

gets yelled at to go have a
fight inside of a ring, right?

They set the rules, and they
hold the coats while people

duke it out inside some
preordained boxing ring.

And they aren't let out again
until users have one answer.

The goal here is to get users
to say, holy cow, you guys

have made this really hard.

You might all have some answer,
but we need one

standard answer.

And that usually only happens
when A, everybody understands

the problem.

So until everybody understands
the problem, if there's some

vocal minority that says,
look, there's this giant

problem, well, that's probably
not enough to get a standards

effort to a successful
conclusion.

So if everyone understands the
problem, and there are

competing answers, that's sort
of the predicate for a

successful standards scrum.

You can't really start the
game until those set of

conditions have been met.

So it's good for browser vendors
to innovate, to start

working together to
collaboratively look at what's

happening inside the world.

What are the libraries doing?

What are the compilers doing?

Where are we falling
down on the job?

Where are users yelling
at us most loudly?

And once that happens, go to
the standards body and say,

OK, well, this is the subset of
what we clearly understand

is a relatively good answer.

Let's standardize that.

And then to hopefully integrate
more of what is then

collectively understood to be
the right problem or the right

answer as time passes.

IVAN ZUZAK: OK, thanks.

Simon.

What's your experience from
being on W3C group for testing

and tooling?

SIMON STEWART: Yeah, so
WebDriver is in a really

interesting space in that it's a
de facto standard that we're

turning into a de
jure standard.

A lot of the tools that Paul
was talking about earlier,

anything that connects to
Sauce Labs is using the

WebDriver APIs.


Michael Tamm's Fighting Layout
Bugs, that uses WebDriver.

It keeps on cropping up in these
sort of unusual places.

The Appium stuff, that
uses the wire

protocol from WebDriver.

And so yeah, what we're
attempting to do right now is

go, what we need is--

that work is currently being
done by a relatively small

open source team.

And they're brilliant.

They are an amazing team.

But we're now at the point,
and we're past the point,

where in order to make the
things that people want to be

able to test work properly, we
need the aid and help of the

people writing the browsers.

We need to be baked
into the browsers.

Opera were the first people that
stepped up to the plate

and went, you know what?

We could actually do this.

And the Opera driver was a
fantastic step forward and was

incredibly fast and
incredibly stable.

Chrome followed relatively
swiftly after that.

And we went from having a fairly
buggy, painful to use

Chrome driver to something
that was amazing.

Mozilla, we talk about
M-Day on the project.

Mozilla have a project called
Marionette, which is their

implementation of the
WebDriver APIs.

So my experience has been
actually really, really

positive, like everybody sees
the need for these things.

Everyone is pulling together,
and we're all just trying to

figure out the nicest way of
standardizing these things.

REMY SHARP: Is Microsoft
on that list?

SIMON STEWART: So yes,
Microsoft, Apple.

There are now representatives
from Microsoft on the working

group mailing list, and I think
they're planning on

showing up to the next
face-to-face session.

There were Microsoft
representatives at TPAC last

year, in 2012, as well, who
attended a full day of

discussion.

So actually, Microsoft,
obviously they don't tell us

everything.

But they are taking
it seriously.

Apple are Apple, and nobody
knows quite what's going to

happen there.


But I think it's inevitable.

I really hope it's inevitable,
because everyone

else is doing it.

We're turning it into
a standard.

And there are people who
implement it because it's good

for the users.

And there are people who
implement it because they like

to be seen as conforming
to standards.

And the more pressure we apply
by allowing more of these

check boxes to be applied,
the better.

IVAN ZUZAK: So are there any
other tools that are going to

get standardized?

I saw the charter, and you
have Console API from

Developer Tools.

Is that going to happen soon?

PAUL IRISH: So there's
a Java spec for

standardizing Console API.

Mostly, it just needs
more work.

But right now, actually, Console
API is extremely

consistent across browsers.


There's a bunch of different
features in console.log that

most people don't know about
that are actually implemented

across browsers.

Just last summer, we changed the
definition of the dollar

sign symbol in the command
line API in the console.

And while it's not in any
standard, we just talked to

the guys who make Firebug, the
Firefox developer tools, the

Opera guys, and we all just
changed it at once.

So these things stay in sync
pretty well without the

standard being published.

Yeah.

SIMON STEWART: There is a
Browser Tools and Testing

Working Group.

If anyone's interested, they
should think about

joining at the W3C.

And I think there's some efforts
to actually kick start

that and give it some
shape and form.

You may know a bit more about
that, Paul, than I do.

Yeah, OK.

There's an effort, and I'm not
quite sure how far it's gone.

But it'll happen.

REMY SHARP: The debugger
protocol, is that part of the

standard, or is it just that
it's been written and looks

like a standard?


PAUL IRISH: The debugger
protocol--

IVAN ZUZAK: We're talking
about which protocol?

SIMON STEWART: Whose debugger
protocol is that?

Scope or the Firefox one
or the WebKit one?

REMY SHARP: The one that came
out of WebKit that--

like I said, it looked like
a standard Scope.

Looked like it came
from Opera.

The debugger protocol looked
like Chrome and Safari were

kind of adhering to it.

And--

[INTERPOSING VOICES]

PAUL IRISH: Yeah,
so both are--

REMY SHARP: [INAUDIBLE].

PAUL IRISH: Both are published
open specifications and both

designed for use in a
generalized fashion.

I think Firefox was the
last one to add

support for remote debugging.

And they didn't use either
of these two protocols.

So I don't expect to see
standardization along these

lines, which is a bummer,
but it's just how it is.

SIMON STEWART: Not yet.

PAUL IRISH: Not yet.

IVAN ZUZAK: So we have time
for a few questions.

Andrew?


So let's get one in.

What's the best way to test
against varying network

conditions in real life?

We have devices that are
constantly changing, network

switching between
speeds and such.

So how do you test this?

PAUL IRISH: There's two ways,
the two best ways I know.

There's Charles Proxy.

It runs on all platforms.

Can simulate a lot of different
network conditions,

including packet loss and
throttled bandwidth.

And anyone on Lion or better on
OSX, if they install Xcode,

they can get this thing called
Link Conditioner, which is

just in System Preferences.

And it has a few presets for
packet loss percentage and

bandwidth throughput.

But you can mimic a few
different common profiles,

which are pretty cool.

REMY SHARP: Can I also
add something there?

Something I've noticed is that
the iPhone behaves differently

when it has a Wi-Fi connection,
regardless of

whether or not it's on 3G, as
in tethered, to when it

doesn't have a Wi-Fi.

It does different things.


IOS 6 has the Network
Conditioner thing on the

actual device, as well, so you
can play around with that.

But seeing real network
traffic when

you're not on Wi-Fi--

the phone acts differently when
it's on Wi-Fi to when

it's not on Wi-Fi.

When it's on Wi-Fi, it
sends shitloads of

data over the wire.

And I found an article this
morning and tweeted the link

to show you how to sniff traffic
whilst it's on 3G,

connecting through a USB.

But it's something to be
wary of, basically.

IVAN ZUZAK: Great.

So can we get native support
for proxy events?

So--

oh, sorry.

AUDIENCE: Just one additional
question, then.

Testing things like app cache
and simulating offline whilst

remote debugging.

Is it possible?

We try blacklisting domains in
Charles, and that kind of half

simulates it but not totally.

PAUL IRISH: Not yet.

SIMON STEWART: Yeah, in
lots of the WebDriver

implementations, there's an
expectation there's a working

network stack.

And if you go offline,
that disappears.

D'oh.


AUDIENCE: Offline, we shut
down the server.

That's how we--

I mean, we're not
emulating it.

We're just killing the
server that it's

trying to connect to.

So it kind of fakes it.

IVAN ZUZAK: So here's
one for Remy.

Can we get native support for
proxy events in Dev Tools

injecting geolocation based
on Google Maps inputs?

REMY SHARP: We kind of touched
on that earlier, didn't we?

IVAN ZUZAK: OK.

REMY SHARP: I mean, you can
answer, Paul, if you want to.


IVAN ZUZAK: So here's
one for you, Remy.

You had a recent blog post
that touched upon CORS.

So the headers views to get
across the main [INAUDIBLE]

requests.

And there was a lengthy
discussion after that post.

And can you explain what the
discussion was about?

REMY SHARP: The discussion on
Google+ or the discussion on

the comments?

IVAN ZUZAK: The discussion that
touched upon that we're

not sure, actually, how to
use CORS headers on which

[INAUDIBLE].

REMY SHARP: Who asked
the question?

Because you might be able
to clarify it for me.

IVAN ZUZAK: So it was actually
my question.

REMY SHARP: That was
your question.

All right.

[LAUGHTER]

IVAN ZUZAK: Your
last blog post.

So it started quite a discussion
about when to use

CORS on images.

REMY SHARP: Oh yeah, I
basically said, just

turn that shit on.

And I linked to--

I'm going to butcher
his name--

Anne van Kesteren.


So he's got a blog post that
says turn CORS on for XHR, for

basically Ajax.

And I'm suggesting if you're
a Flickr or Instagram or

something with images, and I
think, actually, there's some

other asset types, you should
turn on CORS support for that.

So send, access origin, star.

There's a link at the bottom of
the blog post that opens a

discussion about the security
implications if

you add a star rule.

And there's a back and
forth between Anne

and Malte from Google.


I don't really know how it
ended, but I want to see

these, particularly image
services, giving us

cross-origin rules to allow us
to import that data into

things like Canvas and have full
access to that data so we

can remix the image data and
produce new content.

I can't remember-- there's
something else you can put it

on as well.

PAUL IRISH: If you're really
lazy, just add the Apache

config that's in HTML5
boilerplate, because it

enables this CORS for images
automatically.

IVAN ZUZAK: So do you think that
it's a place where tools

can improve to give you more
information on how you should

use a mechanism or an API?

Because there was a lot of
misunderstanding on, should

you be doing this?

Is it secure?

Is it not secure?

Are we doing [INAUDIBLE]
requests or not?

So like when you're writing
code, should you get a warning

from your IDE and say, hey look,
this is something you

probably are not an expert in.

Check these sections in the
standard, or check this--

PAUL IRISH: Yeah, I think
there's a lot of opportunity

for providing them a bit more
context of what you're seeing.

If you're looking at the
headers, and you're misusing

one of the new security headers,
the tool should be

able to let you know and tell
you where you can find more

documentation on how to
use it correctly.

Same situation on performance,
when you're getting back a lot

of information, it can give
you some guidance and some

resources to learn better
about what this means.

IVAN ZUZAK: Yeah.

OK, that's it.

Thanks, everyone.

[APPLAUSE]



STEVE THAIR: We started off
with the offline panel.

Now we're moving into a
networked world, where we are

connected to a network even
though obviously we discussed

a lot of network connected stuff
in the earlier session.

I'm going to introduce the
panel very quickly.

From the end, we have Ilya
Grigorik from Google.

If any of you have been to
Velocity have seen Ilya

present, he's going to give us
a little opening talk for 10

minutes just to set the scene.

So he shares an office with
Steve Souders, I think.

There you go.

Next to him, we have Andy
Davies, who's a local boy.

So we're from Bristol.

I don't know, where are you
from originally, Andy?

ANDY DAVIES: Wales.

I'm Welsh.


STEVE THAIR: [INAUDIBLE].


He's from Wales.

Occasionally, they win a rugby
game but not lately.

Next to him, we have John
Cleveley from the BBC.

He was responsible for migrating
BBC News to a

dynamic platform, been building
features mobile

first, using responsive design
all the way up to the desktop.

Yeah, I think Andrew wrote
that piece of thing.

And last but not least,
we have Jackson.

And Jackson's presented at our
London web performance user

group and Velocity, and
stuff like that.

He's described here as a
veteran troublemaker at

Facebook London.

I think it's supposed to be

troubleshooter at
Facebook London.

No?

Troublemaker?

OK.

Works on tools and mobile, help
build mobile Timeline and

App Center.

Saying you had anything
to do with Timeline

is extremely brave.

Cool.

So basically, we're just going
to kick off with Ilya giving

some opening remarks.


ILYA GRIGORIK: I'm not sure if
this microphone is working.

No?

Yes?

STEVE THAIR: That one's not.

Just use the [INAUDIBLE].

ILYA GRIGORIK: This one works.

That works.

Now what's the magic trick
to get this thing?

There.

STEVE THAIR: We wave
to the nice man.

ILYA GRIGORIK: OK.

Hello.


Waiting, waiting, waiting.


Warming up.

STEVE THAIR: Tell a joke.

ILYA GRIGORIK: All right.

Well, no jokes here.

It's all serious stuff.

It's all network performance.


JACKSON GABBARD: The
crowd looks lovely.

You look great today.

ILYA GRIGORIK: But seriously,
I'm not

going to take 10 minutes.

It's far more interesting to
talk about on the panel to

answer-- there's a lot
of questions in the

Moderator as well.

So I'm just going to kick
off with a couple of--

let me see, wrong screen.


That is weird.


Can you guys see that?


All right.

There we go.

So one thing that I've
discovered as I've been

working on network performance
stuff is, I've been becoming

grumpier and grumpier, in the
sense that people keep asking,

hey, we should put more
stuff on pages.

I want to put more images,
more video.

I'm like, no, no, don't do
that, because that hurts

performance.

Everything you do hurts
performance.

So the fewer things you put
on your page, the better.

So because of that, I've started
actually migrating my

HTML presentations to Bash just
to illustrate the point

that go as low level
as you can.

So this is actually running in
Chrome VSSH but in Bash.

So it's awesome.

Anyway, moving on.

So a lot of the network stuff
is not the sexy stuff.

We can talk about all the
awesome things that we're

building, all the new
CSS animations.

And then you start talking about
performance and it's

like, yeah, that TCP thing.

Ugh.

So a few things, I have like
four high-level things that I

want to seed the discussion
a little bit.

Cache primitives.

So we heard a lot about
caching and offline.

And I'm really excited for the
stuff that's happening in the

offline panel.

I think that's a big,
big improvement.

It'll obviously take some
time to get there.

The local storage stuff
is really interesting.

I'll just add maybe one more
comment to the earlier

discussion.

I don't think it's
a solved problem.

The fact that it's a sync or
async API I think, is maybe

slightly the wrong question to
ask, because for example, if

you look at local storage
performance on Windows, it's

actually really good.

Why is that?

Because they have SuperFetch,
which is a platform feature

within Windows which pre-loads
all the data

independent of the app.

So this is not an IE feature.

IE doesn't have these latency
delays that Chrome does.

In fact, Chrome is
like the worst

performer in local storage.

It's something that
we've got to fix.

So I don't think it's as
simple as we maybe

make it out to be.

Just having an async
API doesn't

necessarily solve the problems.

I think there's an 80% solution
even for something

like local storage.

The fact that this new
controller script is actually

interacting with the browser's
cache, I think is awesome.

Unlike the previous versions,
which it's

either all or nothing.

You don't have a fallback.

So I think this is
all great stuff.

But moving on, something that
I've been spending a lot of

time thinking about
and fighting with

is user-agent sniffing.

I think we can all agree that
this thing is just dead.

We all have to use it.

It's unfortunate.

It sucks.

You have to pay for
these databases.

You have to get a new
serving path.

It is a disaster, no matter
which way you look at it.

And not only that, but it
doesn't actually give you the

answers that you're looking
for, which is the best

combination of all
those things.

So I do have a proposal
out there.

We actually have a prototype
that's in progress in Chrome

for this thing called Client
Hints, which is the world's

dumbest idea, which is if you're
looking for a DPI, why

don't we just send it to you
in an HTTP request header?

That's really all it
boils down to.

So if you're curious,
take a look.

I'd love to get your feedback.

But I think this would actually
help quite a bit with

a lot of problems in the
responsive design world.

And speaking of responsive
design, if you talk about

network performance and web
pages, 60% of all the bytes

that we ship today are images,
which is huge.

So if nothing else, if there's
one area we can really focus

on and fix and improve, it seems
like images would be it.

And unfortunately, if you look
at what's happened in the

image space, nothing
has happened.

We have PNG, JPEG, and
GIF, and that's it.

And it's not obvious why we
don't have another 10 formats.

I don't know if 10 is needed,
but at least another couple.

We have WebP that we have
proposed at Google.

And WebP gives you a lot
of improvements.

But I don't think WebP
is the end all.

I'd hope to see more
image formats.

And it's not obvious why we're
just stuck with these three.

Then you look at products like
Opera Turbo, Silk, PageSpeed.

Opera Turbo is an incredibly
popular browser in a lot of

countries where bandwidth
is at a premium.

Like 90% of all of the
improvements that all these

proxies get is they
just re-encode all

the images with WebP.

That's literally all they do,
just blindly transcode

everything to WebP.

So that alone is like, why don't
we do that for the rest

of all the pages?

So we could decrease the size
of our pages by 50% by just

re-encoding all the images,
which seems like

a pretty nice thing.

And speaking of re-encoding
images, one

thing that I've realized--

I've done a lot of studies now
looking at WordPress sites and

a whole number of
other content--

it turns out we, as humans, suck
at picking image formats.

We are either lazy.

We are either too busy.

We pick the wrong formats.

So we save things as PNGs,
which should be JPEGs.

We save things as JPEGs,
which should be PNGs.

It's just a disaster.

And there's a lot of image
optimization solutions out

there that exist that you
actually can pay for, which

will say, hey, we'll optimize
your images.

If you give us a PNG,
we'll strip the

metadata and all the rest.

It's like, cool.

You're going to strip
100 bytes out of my

150 kilobyte image.

I'm like, that's still a win.

But the truth is, you should
have been saving that as a

JPEG, which would have
been a 15k file.

And we're not doing
that transcoding,

because it's much harder.

I think that's something
that we need to fix.

And this problem only gets much,
much harder when you

look at the responsive area,
where now you have different

break points.

You have different
device widths.

I recently ran a study looking
at how frequently do we

re-scale images on a client or
downscale images on a client.

And it turns out that about 20%
of all the large images

are getting downscaled
in the client.

So we're shipping extra bytes,
which was getting compressed.

This is just wasted bandwidth.

I think we need server help.

We need a client-side
solution, which

we don't have today.

There's a lot of room for better
server integration to

help us with this problem,
because it only gets worse.

You have five different
viewports.

You have high DPI, non-high DPI,
now you have 10 variants.

Add some art direction use
cases, and now you're like,

you started with an image tag,
which was beautiful, one line.

Then you look at your picture
tag, and it's like 40 lines.

And you're like, I am
not writing that.

I'm sorry.

At least that's for me.

Another crowd favorite--

net info API.

So let me just talk about
this one for a second.

So bandwidth estimation--

should we have bandwidth
estimation in a browser?

And the answer is no--


ever.

Yes.

Right.

So why is that?

It's worth actually
thinking about it.

And usually there's
a good counter

argument to that as well.

We have that.

We have that for video.

And the insight there is when we
do do server adaptation for

video, but the way that works
is we stream you a five

[? to ?] second chunk
of video.

Then we see how you
downloaded it.

And then we adjust.

So it's adaptive streaming,
not predictive streaming.

If you look at the actual
bandwidth throughput,

especially on mobile, your
mobile carrier can adjust your

bandwidth on one millisecond
granularity.

Me moving a phone from here on
my desk to here can double or

take my bandwidth by half.

There's such high amounts of
variability that we can

predict bandwidth, or we have
stable bandwidth on the order

of milliseconds--

maybe at most, second.

It's completely unpredictable,
anything beyond that.

So you sending a request for a
GIF file and then fetching

that and saying, ooh, one
megabyte per second.

And then making a decision
is completely useless.

So maybe if we switch all of our
internet back to circuit

switch networks, then we can
have this conversation.

But I don't think that's
going to happen.

And then the last one, which I
think is something that we

haven't actually talked about,
is radio and mobile.

So mobile is obviously a big,
big topic for networking.

And battery life is something
that I don't think we, as web

developers, have actually
thought about at all.

Battery life is actually, turns
out, very important for

native apps, because people
rank these apps.

You run this thing, and your
battery's dead, and you're

like, this app sucks.

For web pages, we haven't
thought about it.

But in reality, they
are just as costly.

I can point you to pages where
if you sit there reading your

news, for example, on some
sites which are using

real-time analytics, every
five seconds they send a

real-time beacon for a real-time
analytics app.

You're just draining
your battery.

It's killing your battery.

The radio is the second most
expensive thing you have in

your phone in terms of power.

The first one is the screen.

The second one is the radio.

And they're actually
about the same--

the same order of magnitude.

So turning off your radio
is incredibly important.

There is big, big anti-patterns,
stuff like

inefficiency of periodic
transfers.

And I think this one's really
illustrative, because even if

you look at the Android docs,
two years ago when we started

building these native apps, we
said, hey, fetch just the

stuff that you need.

And then as the user needs it,
fetch the rest of the content,

thinking that you don't
have enough bandwidth.

And you should get the best
experience up and then

progressively fill in.

If you look at the docs
now, they tell you

completely the opposite.

They tell you download
everything.

Burst everything you can
as fast as you can.

And then turn off the radio.

And please, please, please don't
turn it on ever again.

So I don't think that message
has reached the

web developer community.

And it's actually pretty
interesting to think, I don't

think we have an answer for
how exactly do we service

battery and network
performance?

What's that trade off?

We don't have an intuition in
the browser for what is the

cost of a page.

I'd love to see a metric that's
says, you've drained x

amount of your battery by
visiting this page.

That would be kind of cool.

And then the last one is
4G won't save you.

I see a lot of conversations
about this, which is like, I

heard LTE is going to
fix all things.

I'm just going to
wait for that.

Seems reasonable.

And it seems reasonable
when you're here.

You're in downtown London, then
you probably have really

good coverage.

The problem is when you actually
look at what the

carriers are saying, they're
saying, look, we've invested a

lot of money into 3G
and 2G networks.

We have a lot of users on older
hardware that can't

migrate to 4G overnight.

3G and 2G networks will continue
to exist for at least

another decade, at least
another decade.

And you'll have to build apps
that will transition between

4G, 3G, and 2G.

And that's just the
reality of it.

You can't design your apps
just targeting 4G.

So those are the high-level
points.

That's all I got.

I think we'll go
into the panel.


STEVE THAIR: I think
we're done here.

That's pretty good.

[APPLAUSE]


STEVE THAIR: I'm going to try
to come out from behind the

panel a bit so I can actually
see them instead

of talking to them.

Make sure you talk to them.

Don't talk to me.

Can everybody hear
me all right?

Yeah?

OK.

So the first question we
actually have-- the highest

ranked question on the list--
is, should we have continuous

live feedback access to the
user's network speed, similar

to [? navigate ?]

[? or battery? ?]

And the answer is?

ALL: No.

STEVE THAIR: You'd think
we rehearsed that.

Awesome.

There are actually a
few questions that

were about that topic.

Some people obviously
hadn't heard of net

API, some people had.

I don't even think it was worth
really asking any of

those other questions.

Just say no?

ILYA GRIGORIK: Can we take
a step back, though?

STEVE THAIR: OK.

ILYA GRIGORIK: We can't have
bandwidth estimation.

I can't tell you you have two
megabytes per second, three

megabytes per second.

It is useful to know which type
of network you are on,

which is the level of
granularity that you should be

working at.

Knowing that you're on Wi-Fi
tells you certain things

about, for example, the latency
characteristics of

your connection.

You're now going to have a weird
transition state where

you have to wait for two seconds
before you actually

get any packets on the wire.

If you're on 4G, you
have pretty tight

bounds on latency again.

Knowing on 3G-- so basically
it gives you goal posts.

Like, here's what the minimum,
here's what the maximum is.

And that's about the level
that we need to operate.

So the net info spec
actually had this--

the earlier versions.

It specifically said,
Wi-Fi 2G, 3G, 4G.

I think we need to revert to
spec, like, 15 iterations, go

back and implement that.

JOHN CLEVELEY: Also, when I'm
at home in Suffolk in the

middle of the country, my
Wi-Fi I get about a meg.

I come into London with my
phone and I get about the

same, even better sometimes.

So it's like you've got to use
the information quite wisely

in terms of not making
too many assumptions.

But the latency thing is
definitely going to help make

decisions between 3G
wireless and Wi-Fi.

JACKSON GABBARD: It's always the
one-legged dog [INAUDIBLE]

from the 4G, you get
intermittent one-bar

connection.

That's not as good as
the 3G connection.

But yeah, even then it's
still fraught.

[INAUDIBLE], it's not granular,

immediately useful data.

ANDY DAVIES: The original spec
got dumped for privacy

reasons, didn't it?

ILYA GRIGORIK: I think
the privacy reason

is completely bogus.

So let's just put
that to rest.

AUDIENCE: One other factor,
could it tell you that the

[INAUDIBLE] is roaming,
moving?

AUDIENCE: Use the mic, please.

STEVE THAIR: So the question
from Daryl was, could the spec

just at least tell you whether
the person is actually moving,

like if you're in a moving car
and a moving train, which has

an impact, certainly
on 3G, anyway.

ILYA GRIGORIK: I guess you could
enable GPS and look at

the coordinates if
they're changing.

But hold on, but I think there's
two different things--

roaming and moving are
two different things.

AUDIENCE: [INAUDIBLE]

STEVE THAIR: Yes.

He meant motion, as opposed
to paying 25 US dollars a

megabyte through Verizon in
Gibraltar type roaming.

ILYA GRIGORIK: Yeah.

STEVE THAIR: That would probably
also be useful.

ILYA GRIGORIK: So I don't
think that's a

concern of net info.

So if you are on the move, for
example, 4G performance is

much, much better than 3G
performance if you are moving.

I don't think that's something
that net info would service.

STEVE THAIR: So one question
from me is that if net info is

giving you an API that you
have to query in your

JavaScript, and then you send
that message back, why is the

browser not sending that message
to the server side in

a header or an unsolicited
cookie?

So from the point of view before
I've even served the

request, I've got an idea of
what the connection type is.

ANDY DAVIES: Well, that comes as
part of Ilya's Client Hints

spec, which is also growing into
the same privacy concerns

from some people.

So the idea that whenever
somebody makes a request of

your server, you expose their
screen size or how they

connected, starts to give
you ways of actually

fingerprinting browsers.

And we can do it pretty
well anyway.

So there are some privacy
concerns about it.

ILYA GRIGORIK: So, once
again, privacy stuff--

completely bogus.

Because you just
look at your--

no, no

STEVE THAIR: Who do you
work for again?

ILYA GRIGORIK: If you have the
IP address of your visitor,

you can do reverse map to say,
hey, you're on T-Mobile.

And you're coming from the
subnet, so you're probably on

3G network.

That is what the CDNs
are doing today.

This is all the information
that we're exposing.

So I think this actually
doesn't hold

much water, this argument.

AUDIENCE: I actually don't think
the privacy issue has

been the main killing issue
of these features.

That with the sending in
additional headers, the

problem is, there are billions
of requests happening every

day right now, right?

If you add even, like, 20
bytes of data into each

request, we're talking about
gigabytes and gigabytes of

data being sent for absolutely
no reason in 99.999% of cases.

So that's the main problem
about [INAUDIBLE].

AUDIENCE: Mic, please.

JACKSON GABBARD: I
agree with that.

I think the crux of the issue is
less the network connection

of [INAUDIBLE]

the information that you can
glean about the network or the

device that you're sending to.

That's the thing that-- when
you're trying to get the

biggest ones you can--
network request--

knowing what the device
can handle ahead of

time is pretty key.

And I think sending each
request is not

necessarily the right way.

But it goes back to what you
said before about user-agent

sniffing, like knowing
concretely on the server side

what to send.

It's also a really, really
hard problem.

But I feel like that's the
trick, like that's the magic

bullet in a lot of cases to
get good [INAUDIBLE].

These are the things I know
I don't need to send down.

And in the immediate [? query ?]
world, you send it

off with the layout, send it
off with the JavaScript.

In reality, you don't
need to do that.

Like a [INAUDIBLE] device, you
just don't need to send stuff.

And in some cases, you
don't even have

JavaScript on the devices.

You definitely don't need
JavaScript resources.

But there's no sure-fire way.

I'm curious, though about
user-agent sniffing.

Because I know what we do.

I'm curious what other
folks do for that.

ILYA GRIGORIK: Everybody
does it.

You have to.

STEVE THAIR: But you don't
like to talk about it.

AUDIENCE: I have one.

About--

AUDIENCE: Could you introduce
yourself quickly?

[INAUDIBLE].

AUDIENCE: Yes, thanks.

You introduced me,
but thank you.

Yes, I had a comment about the
spec and about the previous

version of the spec.

I think there was an argument
about privacy.

But another thing was that many
people were claiming that

the type of network is really
not enough information.

It's not telling you enough
about the type of connection.

You might be in a conference
like this on a Wi-Fi that is

complete cluttered, and you
don't get any throughput.

Or you might be actually on--

STEVE THAIR: Or in a
[INAUDIBLE] station

any day of the week.

You'll have five bars of signal,
and you're on a 3G

network, and it's completely
digested [INAUDIBLE].

AUDIENCE: And the problem that
we have with the net info is

that we're trying to find a way
to get this information

without defeating the purpose,
like the [INAUDIBLE]

problem, or measuring
bandwidth.

It changes so quickly, and you
have to measure so often that

you're going to be draining
the battery.

You're going to be defeating
the purpose entirely.

So that's a very hard
problem to solve.

I would be happy to go back
to the connection type.


There are many different use
cases, and we have to see

which ones are more important.

ILYA GRIGORIK: [INAUDIBLE]
some sort of notion of a

connection quality.

I don't know how to
define it exactly.

But it's kind of that losing
your Wi-Fi signal, you have

just enough to be connected
but not enough

to do anything else.

That is a good example.

Or you'd keep timing out.

But that needs to be
serviced by the

operating system somehow.

I don't think the browser should
be the one trying to

claim this one.

AUDIENCE: I work on a browser.

I work occasionally on
Chrome for Android.

And we've been talking a lot
about this particular issue

and this particular API.

And the thing we've come to
understand, as it relates to

the last session, is--

AUDIENCE: Step up to
the mic, guys.


AUDIENCE: The thing we've come
to understand here is that the

only meaningful data point is
the point at which you're

actually requesting
a resource.

That is the only time when you
can make any sort of a

decision that's worth a damn
about whether or not you've

got good quality, because
anything else is opening up a

window, which your expectations

might be violated in.

So if I go and I ping
occasionally to a server, now

I've got a window in which I'm
going to make assumptions

about the quality of
the connection.

And I'm likely to be
unfortunately shocked and

surprised by the terrible
things that

happened in the interim.

Tying this to an actual request,
I think, is the only

way to do it.

And we don't have any other API
right now that does that.

JACKSON GABBARD: I don't
even know if that's

really the crux of it.

I feel like the answer is
just to think about your

application from the standpoint
of minimizing your

risky network time and also
taking as many steps as you

can to harden your application
against it--

so not putting all your eggs in
one chunked HTTP request.

Bring it up over multiple HTTP
connections when necessary.

[INAUDIBLE] the steps to me,
arguing about whether or not

we should or shouldn't detect
network connectivity state is

like arguing about whether or
not the sky should be bright

colored blue.

We're not going to know.

It's not going to be good
enough information.

So what are the things that we
do that are reasonable to make

the application decent
in spite of that?

That's the part of this
discussion that I find

interesting.

STEVE THAIR: Can I actually--

I was going to say, John, you've
got a practical example

with the BBC apps.

What are you guys doing?

And do you care?

And how are you dealing
with that issue?

JOHN CLEVELEY: Yeah, we care a
lot about making sure that our

site works really well on low
bandwidth, because we have a

lot our users use the
World Service sites.

So we basically are always
really anal about file size,

looking at HTTP requests.

And going back to working out
what connection you're on, I'm

interested in what people
actually will use it for.

You can imagine users going to
the site on broadband and then

going on 4G on the phone and
getting completely different

user experience.

I'm interested in what
differences are we going to

actually be able to do if you've
been detected at a

higher bandwidth?

And [INAUDIBLE] you got video
and images of the big things.


We've kind of been really
efficient with

our file sizes, basically.

And as you said before, images
is the big thing.

So even though we haven't got
responsive images as any sort

of standard, basically, we're
using JavaScript to work out

what's the container size.

And then we've got a number
of recipes on the server

producing a number of different
image sizes.

And we grab an appropriate
image for

that particular device.

ILYA GRIGORIK: Do you do
that in real time?

How do you generate
the different

versions of the images?

JOHN CLEVELEY: Yeah, they're
generated the first time then

cached on server, and
then onto CDN.

JACKSON GABBARD: In the
generated case, I'm sure you

got multiple resolutions.

Do you require the people who
are publishing the stories to

upload to separate
resolutions?

Or do you--

JOHN CLEVELEY: No.

So they'll create one raw
image, because they're

journalists.

[INAUDIBLE] are actually
users with Facebook.

So that might be a little
bit different.

So we make sure the journalists
are uploading the

biggest size we can.

And then we've got 20, say,
different image sizes that we

would select from.

STEVE THAIR: So you transcode
all of that effectively server

side for the--

JOHN CLEVELEY: Exactly.

We resize it.

STEVE THAIR: Selected process
that's doing that re-scanning.

JOHN CLEVELEY: Exactly.

It's just a URL that we hit, and
it will do it on run time.

ANDY DAVIES: Do you do any of
the art direction stuff?

JOHN CLEVELEY: Sorry?

ANDY DAVIES: Do you do any
of the art direction

transformations on the image?

Or do you just crop them?

JOHN CLEVELEY: No, it's
literally just re-sized.

STEVE THAIR: We got a
question over here.

AUDIENCE: Somebody said that the
connection quality would

have to come from
the [? RS, ?]

but I think it can come
from the browser.

One thing we do when we're
monitoring a website is keep a

track on the time to first
byte for each host we're

talking to.

And if we see that go up, we
fire off a network test.

So the browser itself could
track and say, hey, this is my

average time to first byte
from Facebook.com.

And you can respond to that.

ILYA GRIGORIK: But your time
to first byte in mobile

networks will vary dramatically,
because you have

different radio state
transitions.

So for example, on 3G, you
can be anywhere from 200

milliseconds to two seconds.

Just because your rating--

AUDIENCE: You can ask it
to give you standard

deviation or min/max?

ILYA GRIGORIK: No, no.

But this is just your
first packet.

This is your first packet.

After that, you're
pretty good.

It's 100 milliseconds
or less--

50 milliseconds.

AUDIENCE: You keep
measuring it.

[INTERPOSING VOICES]

ILYA GRIGORIK: No, but the
point is then you wait.

Then you wait five seconds.

And then you will once again
incur two seconds.

I think the fundamental problem
that we have, is we

have this mental model of
Wi-Fi networks or mobile

networks being the same as
wired networks, which is

fundamentally wrong.

And because of that, we feel
like there's all this

variability, all of this
randomness, all this latency.

But once we actually understand
why these delays

are there and you design for
them, hey, I know I'm on 3G

network right now.

Every once in a while, I'm going
to dispatch a request

which will first block for
up to two seconds.

And this may not be a problem if
it's just like a background

update thing, because
who cares.

But if this is an interactive
user clicking on something and

you're on 3G, that's a UX
pattern that you should be

aware of, because you probably
need a different feedback loop

in your app to say, hey, this
could take a while.

JOHN CLEVELEY: So you're saying
you'd have a different

user experience depending
on what sort of

network you're on?

ILYA GRIGORIK: I'm just saying
you should design

with this in mind.

If you're on 3G, if you're on 4G
even, some actions, like if

my phone has been idle for a
while, the first network

interaction that you're going
to have will have a delay--

anywhere from 100 milliseconds
to two seconds--

before any packets
get dispatched.

JOHN CLEVELEY: So going from a
mobile first approach, do you

think we should use that
behavior as the standard for

everybody in terms
of making sure?

ILYA GRIGORIK: It's probably
a reasonable thing to do.

AUDIENCE: Just one comment,
[INAUDIBLE].


I'm basically my own firm.

Just one comment regarding the
measurement of time to first

byte, would resource timing,
especially if we could add

byte size into resource timing,
we could measure

continuously the end-to-end
bandwidth

throughout the download.

It's extremely complicated to
measure the bandwidth between

the various resources, but we
can have a fuller picture of

the download.

ILYA GRIGORIK: Great, we're
going to have a

fuller wrong picture.

STEVE THAIR: I'm going to move
on from this topic, because I

think we've done it to death.

You either believe that
measuring the bandwidth is

useful for you, or you may
believe that measuring the

bandwidth is a complete and
utter waste of time.

I think it really comes down to
if you're more for John's

point question really is, why do
you want to know, and what

are you going to do with
that information?

You're not going to be switching
between four

different viewport things of
this application or ways of

displaying this application
on a millisecond basis.

Who really cares?

One quick point?

AUDIENCE: Yeah, [INAUDIBLE],
Mozilla.

I heard this fallacy about if
the viewport is big enough,

then we [INAUDIBLE]
bigger picture.

That actually says that if
the screen is bigger, my

connection is faster, which
is not really true.

So [INAUDIBLE]

Retina displays and these kinds
of things, I can't be on

a slow connection with my
Retina display machine.

I still don't want the two-meg
background image.

So the question is, in Flash,
we had adaptive

streaming of videos.

And why don't we get this
in the HTML5 world?

What do you we need to do to get
this [INAUDIBLE], because

right now one can start using
Flash for that kind of stuff.

JACKSON GABBARD: [INAUDIBLE]

I guess for me--

AUDIENCE: Can you repeat
the essence of the

comment with mics?

JACKSON GABBARD: I don't
know if I can or not.

It's complicated.

So the essence was, device
screen size is no proxy for

network activity.

That's the measure that we take
against what [INAUDIBLE]

and what switches
we send across.

You mentioned the Flash
[INAUDIBLE]

where you can get
a [INAUDIBLE].

You need something along these
lines for the HTML

[INAUDIBLE].

Basically, you get the lower
quality image with low

bandwidth case naturally
by [INAUDIBLE]

that we don't have currently.

Is that the essence?

AUDIENCE: Yeah.

JACKSON GABBARD: I forgot what
I was going to say about it.

[LAUGHTER]

STEVE THAIR: And the
answer is, yes.

We need that.

Very good.

So I want to get on.

There are some other questions
on other topics that I want to

cover and get away
from net API.

So one of the questions which
you started to talk about with

you had different visions and
[? optimized ?] stuff, there's

a couple of questions in here
that are basically around

should I be compressing?

Should I be using
minification?

What things should I be
doing during my build

cycle in order to--

does minification really save
you all that much when it's

going to be gzip compressed
anyway?

JACKSON GABBARD: I have
a poll question here.

How many people here--

STEVE THAIR: How many
people here--

JACKSON GABBARD: How many
people here have a build

script for the they work on?

STEVE THAIR: Have a build
script for the

project they work on?

JACKSON GABBARD: Holy shit.

Wow.

STEVE THAIR: That's like
pretty much everybody.

Awesome.

JACKSON GABBARD: Nice.

I had no idea.

This is awesome.

STEVE THAIR: And how many of
those build scripts include

performance optimizations?

Now you're just showing off.

That was about everybody
again.


So who's doing minification?

Who's doing image optimization
and resize on the fly?

Oh, about a tenth of the
people who answered the

previous question.

What else would you
like to see?

JACKSON GABBARD: [INAUDIBLE].

STEVE THAIR: This is a question
for the panel.

What else can people do in their
build cycle that you

think is really going to help
their delivery, particular

over high latency, low
bandwidth networks?

JOHN CLEVELEY: I think the other
thing you can do is, for

JavaScript, you can't power
everything into an all.js.

You do get to the point where
it starts to get massive.

And so if there are other pages
where actually it's a

specific bit of [INAUDIBLE]

that you can have in a different
package, then

sometimes it's good to work
out what you can spit out.

So the majority of
pages, you're

still using this all.js.

But on these other ones that you
can get away with spitting

things out.

So we use AMD to do that
kind of stuff.

And there's probably all sorts
of different dependency type

things that you can use.

So it's not always about making
one massive file.

Sometimes you need to be a
little bit clever about how

you split stuff up,
bundle stuff.

JACKSON GABBARD: Thank
you for that.

So the approach that we take for
Facebook is that there's

two levels.

There's basically all
the important

interactions that matter--

clicking on links, loading
things by XHR.

And then there's all the rich
features, all the really

bulky, all that JS stuff.

And so in the header page,
before the body, with all the

[INAUDIBLE], we'll send out all
of the basics, the really

tight, "do not put bytes in
here, you're wasting human

lifetime" sort of stuff
in that [INAUDIBLE]

JavaScript.

And then the stuff you need
later, you'll get to it.

Eventually you'll get those
features, and then the

widgets, the flyouts, the
[? beepers on the site, ?]

the core interactions that are
JavaScript enhanced, they'll

be there immediately.

It's the exact same approach.

JOHN CLEVELEY: And it's just
downloading what the user's

actually going to use as well
and using feature detection.

So if you're doing video,
check that the user can

actually play video before you
download your HTML5 player and

things like that.

So just looking after the guys
with the bad phones, because

they're probably got bad
JavaScript as well and

probably are on slow
connections--

I'm making lots of
assumptions here.

But you generally
get the idea.

Basically it's just progressive
enhancement.

That's the most basic level.

ANDY DAVIES: But there also a
lot of people who are afraid

of-- particularly in the
design community-- of

server-side stuff.

If you look at media queries,
the showcase site for

responsive designs, and you look
at the configuration of

some of these guys' servers,
there's basic things like,

gzip compression missing,
keepalives missing, cache

directives missing.

There's a lot of basic stuff
that as a web industry, we're

really bad at doing.

ILYA GRIGORIK: It's actually
surprising.

Maybe not in this room.

I think in this room, most of us
here have the basics right.

Turns out most of the rest of
the industry still has the

basics wrong.

That's a big problem.

STEVE THAIR: I'm
an ops manager.

I'm going to disagree
with that.

Just because all the developers
in this room are

doing everything right sure as
heck doesn't mean the ops guys

who run the servers
are doing it.

ILYA GRIGORIK: All right.

Fair enough.

So we talked about JavaScript.

I'll come back to images.

60% of the bytes--

images.

You probably have your PNG
optim, jpegtran or something

built into your build script.

Chances are, you're still
missing the opportunity to

transcode it to a better
image format.

I'm guessing half of your PNGs
are bed encoded as JPEGs and

vice versa.

This is a much harder problem to
solve, because it's likely

that your PNG is hardcoded into
your app, which means you

need to rewrite your code.

But this is a huge, huge
opportunity that you should

look at today.

And you guys have a server-side
solution to do the

image resizing.

I think this is something that
more and more people need to

deploy, because we just stick
images into a markup and

resize them on a client.

And that's a big problem.

JACKSON GABBARD: The hard
problem, it's sort of an

exponential nature, because if
you want to serve every single

resolution, well, that's
a different image size.

If you want a full width image
for every single resolution,

that's a massive number
of resolutions.

And so the coping mechanism we
use is to basically put it in

four-ish categories.

I think we have roughly
four sizes--

very, very small, original
iPhone, high-end iPhone world,

and then gigantic, tablet-y,
very high-resolution Android

phone-y stuff.

And then use careful CSS to let
it crop on the client in a

way that's reasonable.

And that way, you never quite
get exactly the right thing in

all cases, but you end up having
to have not a mess, but

not a server side storage.



AUDIENCE: Yeah this is
[INAUDIBLE] from Mozilla.

One thing we saw when we were
looking into doing WebP was

that the reason it wasn't
commencing was we saw that

people could just use better
JPEG compressors.


When you're encoding to JPEG,
if you just use better

parameters to your JPEG
compressor, you can actually

win about the same order of
magnitude as this 30% that

WebP currently proposed.

It's quite possible that WebP
can do even better.

But the order, the wins that
people were shooting for could

be had in many cases with just
passing better parameters to

your compressor.

ILYA GRIGORIK: So I think
there's a couple

of threads in there.

You have quality level.

And most of the time today, we
save our JPEGs either as 100,

or if you're advanced, you'll
save it as an 85.

We can go way down into the
tail and actually get very

good visual performance at
a fraction of the cost.

WebP does have about 30%, on
average, better compression at

the same quality level, the
same perceptual level.

It is definitely the case that
you can take all your JPEGs,

save at a lower quality,
basically re-compress them,

and get much better bytes
on the [? wire. ?]

So that is definitely true.

And I think that's an
under-appreciated area

generally today.


JOHN CLEVELEY: One thing as well
is, if you want to work

it out from a UX perspective,
how many images you need to

show [INAUDIBLE].

You can fool around with
compression, but actually if

you get to the desktop
BBC News site, we've

got a lot of images.

And so that's something we're
looking at to work on.

In our mobile site,
we've only got 10.

And that's just a massive win.

And so it's working out just
trying to do less but do the

stuff you do do really well.

I think that that's the biggest

thing for network stuff.

STEVE THAIR: On the feature
phone, you drop the images

altogether on the news
page, don't you?

JOHN CLEVELEY: Yeah
that's right.

So if you hit our site on a
feature phone, like a Nokia,

you'd literally just get
the first image.

And that gets replaced out with
a better quality image if

you're on a wider screen.

And then we post-load all the
other images with JavaScript.

STEVE THAIR: We've got
a question from Colt.

AUDIENCE: Yeah, quick
question--

Colt McAnlis from Google.

So can we actually talk about
how the fact that the smaller

image compression formats we
have decreases our network hit

and actually increases
our runtime hit.

So all those JPEGs and PNGs have
to be decoded to a full

resolution 32-bit and then
transferred to the GPU, which

actually puts more pressure on
the GPU memory, causing more

invalidations and actually
hurts your runtime

performance.

What are our thoughts
on fixing this?

ILYA GRIGORIK: I don't think
there's a fix for it.

It's a trade-off.


How does WebP give you better
image compression?

Well, we have more advanced
algorithms that

take more CPU time.

And vice versa, you need
more time to decode it.

So this is an interesting
trade-off.

It will take more time to decode
a WebP image than it

does to decode a JPEG image.

And you need to look at, maybe
if you were building a game

and it's like you have a ton
of image [INAUDIBLE], maybe

your CPU, especially on
a ARM processor, is

your limiting factor.

Maybe be at that point, you
make a decision to use

something else.

We recently did some studies--

I don't think we've published
anything yet at this point,

but I think we will.

We looked at Image Search at
Google, where we moved

everything to WebP and just
looked at, what are the wins,

what are the losses?

We do take more time
in the CPU.

We take a lot less time
on the network.

Then that trade-off is we're
still better off using WebP in

that specific case.

And this is your Image Search
page, which has like 20 or 30

images at different
resolutions.

So this is, I think,
a great point.

It's something you need
to keep in mind.

STEVE THAIR: OK.

The I think we've done
images to death.

We've got about 10
minutes left.

I want to try to move on to two
semi-related topics that

are very network specific.

The first is some guy named Andy
Davies from Bristol asked

the question, with the adoption
of multiplexed

protocols like SPDY and HTTP2
and the prioritization of

resource downloads by the
browser based upon the type,

will data URIs become
an anti-pattern?

That's one question.

And then there was another
question that was basically

about web sockets and
stuff like that.

So I just want to move on
to talking about those.

So does anybody want
to answer Andy's

question other than Andy?

Or you can answer your own
question if you want to, Andy.

JACKSON GABBARD: I think it
echoes what you said earlier--

the idea that the best request
is no request.

So [INAUDIBLE]

is pretty sweet for that.

It's all there.

If you're [INAUDIBLE] mobile
app, you can put all your data

URLs into your CSS and you
have one CSS file.

That's a win.

I can't imagine a world where
going from no request to any

request isn't a better
trade-off.


ILYA GRIGORIK: Why do
we inline stuff?

It's because we have limitations
in HTTP 1.1, which

make small requests expense.

It's the same reason
we sprite images.

It's the same reason
we concatenate

files, all of this stuff.

With SPDY and HTTP2, that goes
away, because we can multiplex

all the stuff in parallel.

You can send all of your
requests at the same time.

We don't need multiple
parallel connections.

Yada, yada, yada.

Then coming back to inlining,
inlining is a

form of a server push.


Here's the idea.

In HTTP2, we have this proposal
to say, sometimes the

server actually knows what
you're going to request before

you request it.

Like I'm sending you
the damn page.

I know the resources on it.

So why don't I just send
you the resources?

Seems kind of obvious, right?

So that's the idea behind
server push.

And inlining is push, because
you're saying, look, I know

you're going to ask
for this icon.

So here, page 64 in the file.

Forget it.

Don't make the request.

That's a trade-off
of HTTP 1.1.

With 2, we can actually get away
from that and say, by the

way, here's the file.

And why is that a win?

So let's say you have to have a
small icon or a big icon or

whatnot, and you inline
into a page.

Now you're inlining that thing
into every single page.

It fits on multiple pages.

So you're just bloating
the size of each page.

Whereas with push, it can
actually be in your cache.

So I think it is mostly
an anti-pattern.

I'm sure there's one or two
use cases where there may

still-- like, if it's only
used on one page, it's

effectively the same.


STEVE THAIR: There's another
question here which is about

web sockets.

It seems that abstractions like
Socket.IO and Pusher are

the preferred way to
use web sockets.

Is this a failing in the
specification process?

Is it now the expectation that
new DOM APIs will be needed to

be wrapped by libraries
or frameworks?

So basically saying, does the
specification suck so bad

you've got to use another layer
on top to make it work?

AUDIENCE: [INAUDIBLE]?


[LAUGHTER]

STEVE THAIR: We'll take
that as a no.

So, apart from the guy from
Pusher in the audience, who's

using web sockets, and are they
using web sockets in a

mobile device?

Can I see a quick
show of hands?

So that's about four,
five people maybe.

Does anybody have any really bad
problems in a mobile world

that they think that causes?


AUDIENCE: [INAUDIBLE].

STEVE THAIR: One replay was,
the network provider is

blocking web sockets traffic.

AUDIENCE: Some of them.

Yeah.

STEVE THAIR: OK.

AUDIENCE: I haven't tested this,
but I've been told that

a web socket can just drop out
on a mobile connection.

I'm going to be listening
to the close events.

But I suppose the question is
simply to ask if that was

anything that anyone else
has come across.

ILYA GRIGORIK: So this is--

STEVE THAIR: Just repeat
the answer.

ILYA GRIGORIK: So the question
was, or the comment is that

sometimes website connections
just drop

out on mobile networks.

And this is a deployment
problem.

So I think there's
two problems.

First of all, web sockets did
go through a very elaborate

process of many revisions
and specifications.

Depending on which server you
use-- so I happen to have

worked on one--

it's the Ruby implementation,
the EM web socket.

If you actually look at the
implementation, we have, like,

15 implementations of
all the drafts.

It's a total nightmare in terms
of negotiating, oh, this

browser supports this
spec, et cetera.

That was problem number one.

So I think we did fail in the
specification process of that

specific standard.

The bigger problem today with
web sockets is you have to

deploy over SSL.

If you're deploying it on
mobile, you have to deploy it

over SSL, because most of the
carriers have some proxies in

between that try to optimize
traffic, whatever that means.

And they look web sockets, and
they're like, look, this

doesn't smell like HTTP.

Close.

Or even better, the blind
proxies, which don't even care

what's in there.

They're just substituting
bytes.

And this is why without SSL,
20% of your connections on

desktop will fail randomly.

You have a proxy that doesn't
understand web

sockets, end of story.

On mobile, it just happens to
be the other way around.

80% of your connections
will fail.

So if you want, you
can reliably

deploy web sockets today.

It's HTTPS.

And that's how anybody on mobile
deploys that at scale.

STEVE THAIR: Great.


AUDIENCE: [INAUDIBLE]
with Mozilla again.

Isn't the big reason for library
use that a lot of

browsers still don't support
web sockets, or a lot of

browsers that people use still
don't support web sockets,

which we can't really
get away from?

ILYA GRIGORIK: So we need HTTP
fallbacks for browsers that

don't support it.

Hence the reason for Socket.IO
and all these other

abstractions.

And that's just an unfortunate
reality of not everybody is

able to upgrade to an
evergreen browser.

Some people are just stuck on
an old IE machine that they

can't upgrade.

And I don't know how
to fix that.


AUDIENCE: Hi.

ILYA GRIGORIK: [INAUDIBLE].

STEVE THAIR: Got a question
right there.

AUDIENCE: Yes.

STEVE THAIR: Tell
us your name.

AUDIENCE: Hi, my name
is [INAUDIBLE]

from [INAUDIBLE].

If I use a web socket for
mobile, does it drain the

battery further.

Or as long as it's an idle
connection, it doesn't drain?

ILYA GRIGORIK: Yes and no.

It depends on how you
use your web socket.

If you're sending periodic
messages every five seconds,

you'll keep your radio
active all the time.

I think what a lot
of people confuse

about is you can have--

so your radio can be
off, but the TCP

connection is still alive.

I think a lot of people
confuse this.

They think the moment my radio
turns off, I've lost my

website connection.

That is not the case.

Your actual TCP connection
is still

maintained by the carrier.

And it's just the radio link
that goes missing.

So I guess the best practice
for web socket traffic on

mobile is, send as few requests

or messages as possible.

Or if you do, just
as with regular

traffic, send it in bursts.


STEVE THAIR: There were quite
a few questions on this list

about radio stuff.

I think Ilya covered it
in his introduction.

[INAUDIBLE]

AUDIENCE: Hello, yeah,
so I'm Phil.

STEVE THAIR: Hold
on one second.

So there were a few questions
there about battery use and

this kind of stuff.

I think Ilya covered it in his
introduction, that you've got

to be aware of it.

Just one question from me, as
a rule of thumb, do we have

any idea of how quickly
the radios turn off?

Is it once every five seconds,
once every 10 seconds?

If I want to beacon analytic
stuff back,

what's a rule of thumb?

ANDY DAVIES: It's carrier
dependent.

STEVE THAIR: It's carrier
dependent.

JACKSON GABBARD: [INAUDIBLE].


We got yelled at by some carrier
who was saying that

we-- basically, a time out
from one of our logged in

delivery services was
just underneath

the radio time limit.

We were always just keeping it
awake, over and over again.

You have a lowered [? wait. ?]

The radio [? wait ?] will
stay awake longer than

you think it would.

ILYA GRIGORIK: So its
network configured.

There's a great case study
paper published by AT&T--

STEVE THAIR: Three
minutes left.

ILYA GRIGORIK: Three minutes.

AT&T--

I don't remember
the name of it.

If you just search for AT&T
radio performance, I think

you'll find it.

They have the Pandora
case study.

Pandora app--

you play the song.

They did the right thing.

They downloaded the whole
song up front.

So they streamed the
whole thing.

They turn off the radio.

And then every 60 seconds,
they would send a beacon,

which is just a measurement
beacon.

And they measured it, and they
figured out that those beacons

accounted for 0.2% percent of
the traffic and 40% of the

battery use.

They eliminated that.

They doubled their battery
performance.

AUDIENCE: Just a few points--

I'm Phil Leggetter
from Pusher.

So obviously we use
web sockets.

So I handle most
of our support.

So I just want to back up that
SSL connections when you're

using web sockets, definite.

In terms of the web sockets
dropping, I think that's

because most of the browsers
don't implement ping pong from

the specification.

So we've added that as
our protocol layer.

So we are sending messages
when maybe we

shouldn't have to.

But obviously, there
would be a message

natively from the browser.

So again, if you're using web
sockets in a browser, have a

ping pong time out.

And we haven't had a lot
of problems with that.

We've obviously got HTTP
fallback as well,

because we need it.


AUDIENCE: With regards to a
radio power state, would it be

worth for the developer to
have a means to tell the

browser, here is the request,
and send it only whenever you

have the radio in full power.

If it's an idle state, don't
wake it up just to send this,

because it's not urgent.

This is something I would
like to see, personally.

STEVE THAIR: Military style
microburst, basically.

AUDIENCE: And avoiding excessive
signaling traffic,

which is what happens when
you switch radio states.

It's in the best interest
of everyone not to

clutter mobile networks.


ILYA GRIGORIK: So the
answer is yes.

And this is actually something
that we discussed at the W3C

Performance Group meeting that
we had back in November.

There's this new proposal that
we're going to start working

on in, I think, around
May of this year--

it's our timeline--

called the beacon API.

And the idea being that,
it's exactly that.

I want to send a request, like
an analytics request, that I

don't need to dispatch
right now.

Dispatch it any time you want.

In fact, even if you lose
it, maybe it's not

the end of the world.

But just don't wake
up my battery.

So it's almost like the async
keyword on an XHR to say,

sometime, make this happen.


STEVE THAIR: That's basically
the time up

for the network panel.

So I'd like to thank Jackson,
John, Andy, and Ilya.



AMBER WEINBERG: Hello,
everybody.

Can you hear me?

All right.

Was lunch great?

Lunch was great, huh?

So in this panel we
will be talking

about responsive layout.

And George Crawford
is our opener.

He is the Lead Developer of The
Economist's HTML5 project

and the maintainer of FT
Columnflow, which is this

really cool magazine-like thing
that I hope he will

explain to all of us.

Then we have Razvan.

He works on CSS Regions, CSS
Exclusions, and other ways of

improving digital publishing
on the web.

Then we have Andy over here.

He was formerly the Lead
Engineer on Bing maps and then

worked for the awesome Clearleft
offices in Brighton.

And currently, he does the
client-side work at Guardian.

So George, if you want to come
up and give your presentation.


GEORGE CRAWFORD: So responsive
design is a bit of a buzzword.

I'm sure you're all familiar
with it, but it sort of lacks

definition.


First slide is coming up.

So responsive design,
it lacks definition.

We need some clarity.

I'm sure you've all thought
from time to time about

various considerations we need
to take in mind when thinking

about responsive development.

I liked a quote on
Andy's blog--

"Responsiveness is what a
website does when it's loaded

into an unknown browser on an
unknown device by an unknown

individual." So websites need
to respond to the device and

the environment and to the user
and to many other factors

to offer the best experience.

But dealing with all of these
considerations is far too

broad for this session, so we're
just going to talk about

responsive layout.


So here's a typical example of
a site that really thinks

about responsive layout
that's only really

based on viewport width.

This is something I stole from
Amber's blog posts, the United

Pixelworkers.

Yeah, it's funky, and it's
a really nice sort of

interactive experience.

And that doesn't really answer
all of the questions that we

need to answer.

So we don't need to just
consider the aesthetics of a

layout but also the whole
effect on the reading

experience and the way that
a user will [INAUDIBLE]

the sites.

Like, if we need to do extra
processing to achieve a better

layout, we might need to wait
longer for the network, we

might need to wait for the CPU,
we might decrease the

frame weight.

So following the discussion we
had earlier in the network

panel, we need to consider
things like this.

With the Economist web app that
I've been working on, our

first page load, we just use
real links to real images.

But as the user navigates to
an addition, subsequent

articles, we download
with Ajax requests.

And we actually send the
dimensions of the viewports in

the request, so that images can
be dynamically re-sized on

the server, A64-encoded, added
in line to the HTML.

Now, there are obviously
pros and cons to

that, as we've discussed.

But it has a great advantage in
that we don't need to do so

much work on the client.

And also, once the first type of
device, like the first iPad

or the first PlayBook, has
rendered that article, we can

store it in the cache
for faster

performance in the future.

So my experience is mostly with
the Financial Times and

the Economist, which are very
much reading platforms.

So let's look at some of the
problems that newspapers and

magazines present on the web.

So the FT wanted a column
layout, which is obviously

inspired by their
print edition.

CSS columns is useful, but
it's not enough, even to

create a simple layout
like this.

This headline that spans column
one and two, you can't

do that with CSS columns.

You have the options to span all
of the columns or one of

the columns.

So we need to turn to JavaScript
straightaway.

And our first approach was to
iterate through every single

word in a paragraph, even in
an optimized way, find out

where to cut the paragraph, and
move the contents to the

next column.

You know that dealing with
text is really bad for

performance, so we looked
into other ways of

speeding this up.

And we developed
FT Columnflow.

This is Columnflow in action
on the Economist's app.

And actually, the FT, the page
before, was also running

Columnflow.

And if we look a bit closer at
what's happening here, we can

see the paragraphs highlighted
in red.

And you can see that the
paragraph at the bottom of

column one has been cloned
and moved to the

top of column two.

So yes, we have twice the
weight in the DOM.

But if we hide the overflow,
we get a nice result.

And it's actually much faster
than iterating through each

word in the paragraph.


So Columnflow has some other
features which really help

with responsive layout.

You can add classes on to the
flowed elements to stop

elements wrapping, so by
default, for example, it

doesn't wrap images.

You can also keep headings
attached to the paragraph

which follows them.

And you can position fixed
elements like headlines and

images on a particular page, a
particular column, spanning

any number of columns.

Columnflow will try and avoid
orphaned lines at the ends of

paragraphs.

So it would prefer two lines in
the next column rather than

one line on its own.

And it will try and determine
the vertical grid height and

add padding dynamically to
images and headlines so that

they conform to the grid, so
that you get a nice vertical

grid running through the page.

Columnflow does have
some side effects.

It's not perfect.

And one interesting one is
that fonts must be loaded

before it runs.

If a font loads after Columnflow
has laid out the

absolute position of each
paragraph, then you get into

big problems.

You can see here that there's
clipping at the bottom of

column one and at the
top of column two.

So in the Economist, we
actually use a font

pre-loader, which presents a
whole load of other problems.

Anyone who's looked into
determining precisely when a

font loads, it's a nightmare.

And there's a CSS3 fonts module,
which will hopefully,

in the future, add an
onload event or

something similar for fonts.

But not much browser support
yet, of course.

So taking it further, how
might we improve the

Economist's responsive layout?

I've hacked the code base
a little bit, added some

experimental enhance--

[AUDIO CUTS OUT]

GEORGE CRAWFORD: So this
article layout is

designed for the iPad.

And what that means is that
the number of columns is

hard-coded.

And even the aspect ratio of
the image is determined,

editorially, for the
iPad layout.


So when we launched on hardware
with a different

aspect ratio, the easiest
solution is to add white

gutters on the sides.

It's not a terrible solution,
but it's losing a little

element of that immersive
experience.

So why can't we add some
flexibility to this?

We don't need to hard-code
the number of columns.

We can determine the optimum
number of columns by thinking

about things like the
typographic measure.

So the measure is the number
of characters in a line.

And as the font size changes,
the number of characters you

can fit in a line will
also change.

So if we go for an ideal
typographic measure, then we

can also, based on the viewport,
determine the ideal

number of columns.

We can improve legibility
a bit by

modifying the line height.

So for longer lines of text,
it's a generally-accepted

principle that you want a bit
more space between lines, and

for shorter lines, a bit
less line height.

These are quite well-known print
concepts, but they're

only slowly coming to the web
as our devices provide more

and more immersive reading
experiences.

And also, there's some
technology that we're

waiting for, too.

We can vary the number of
columns that the image spans

based on the total number
of columns--

and also the width and also the
height of the viewport,

because we have to take the
aspect ratio into account.

So this is the first draft.

It's making better use of
the available space.

It's more immersive.

It feels like the app has been
tailor-made for your screen.

And it does increase
the legibility.

I'll just run through a range
of viewport sizes.

You can see some of the things
that we're changing.

So as the line length increases,
it goes too far for

the ideal measure, so we
add in extra columns.

And you can see the line height
changing slightly based

on the length of the lines.

And that image started off
spanning one column, then to

two, then to three.


So the same logic can be applied
to a static viewport,

but when the user is changing
the font size.


So as we increase the font size,
we have fewer characters

per line, so we actually
need fewer columns.


We can go even further,
improving the article's

typesetting.

We can learn from techniques
used to layout newspaper

columns like hyphenation
and justification.

So the default here is a ragged
right edge, which with

a narrow column gets a little
bit difficult to read.

But if you set justification,
it doesn't help [INAUDIBLE].

We get these large areas of
white space, and they can

sometimes form very
ugly rivers.

So we can add in hyphenation.

CSS Hyphenation, again, doesn't
have great browser

support, so I've used a
JavaScript library here.

And performance analysts
might worry about this.

It took 10 milliseconds to
hyphenate this entire article.

So I think it's worth
considering

for text-heavy layouts.

Now, we mentioned in the network
session earlier that

we might be able to do
more with images

and responsive workflows.

So maybe it's worth considering
on the editorial

side that they might even embed
metadata into image

files with a selection
of possible crops.

So you might be able to choose,
on the client side, a

range of aspect ratios.

Some may be a tighter
crop if the image is

going to be very small.

And then you can determine,
based on the size and the

aspect ratio of the space you
have, which would be the best

one of those crops to use.

So we can improve this layout by
maybe having a shorter and

wider image or having a tighter
crop that can just

occupy one column.

So what technology do we have
around for our disposal for

responsive layouts?

And what's coming up?


You've probably all seen grids
like this, the 960 Grid and

Twitter's Bootstrap.

These don't give a perfect
solution for

the responsive layout.

They're either completely fixed
width, or they only

adapt a little bit and then
instantly snap to a single

column on mobile devices.


So we've got some emerging
technologies which

will help us a lot.

In the Economist and the FT,
we're using Flexbox to help

with layouts, it's very powerful
and can be quite

complicated.

And then the CSS Grid Layout
module, which is only

currently in Internet Explorer,
is going to help a

lot with designing responsive
grid layouts.

And then Razvan's team at Adobe
are working on some

really nice proposals for
new CSS modules--

the CSS Regions and Pagination
templates for rich,

magazine-like layouts.

So I've devoted quite a lot of
time to Columnflow, but with

any luck, modules
like this will

eventually make it redundant.

Until we get browser support,
of course, we do need

JavaScript polyfills
to do the same job.

And then the CSS Exclusions,
allowing you to flow text

inside and outside shapes
and even images.


And we've got technology like
seamless iframes, web

components, the shadow DOM,
custom elements-- which, when

they're combined, might lead
to give us context-agnostic

encapsulated modules of HTML
and CSS which can adapt and

respond to their available space
rather than actually

worrying about the viewports
so much.

So we're looking into this
a lot for the FT web app,

creating individually-styled
modules which can be dropped

into any part of any
page without

interfering with other elements.

So hopefully that's given you
some ideas about responsive

layouts for magazines
and newspapers.

But what about the
other problems

that other sites have?

And how else do people deal
with responsive layouts?

I'll hand it back to Amber.

[APPLAUSE]


AMBER WEINBERG: All right.

So our first question is
actually going to be my

question, because it is a
problem that I have been

facing lately and I'm sure
many other devs have.

Kind of with the performance
talk as well, but is it worth

taking the performance hit and
extra time deving to serve up

retina images?

Or should we only pay attention
to retina images

when it's really important--
for things like icons or

photo-heavy websites?

Because a lot of sites don't
really matter as far

as the images go.

So George?

GEORGE CRAWFORD: Well, my
experience with the FT and the

Economist is that first of all,
it is a shock to see your

site on a retina display when
you haven't prepared for it.

It's really interesting, the
difference between a large

JPEG image, like the ones I
was showing, and the tiny

interface icons.

I think because we're so used to
really nice font rendering

and really nice PDF support,
just seeing a PNG, a tiny file

that could easily be doubled
without worrying too much

about the overhead, it really
makes a big difference.

And I think you can get away
with non-retina, large JPEGs.

And I think that's definitely
the first step.

And maybe then look into how
much overhead you're going to

add with large feature images.

But of course, some sites are
not using feature images to

the extent that we do.

ANDY HUME: Yeah, I think it
depends exactly what you're

trying to do on a given
site or a given page.

Clearly, a lot of the stuff
in the newspapers is about

high-resolution imagery, and
we have apps that are

specifically tailored to showing
those in engaging,

beautiful ways.

So those do need to be the
high-resolution stuff.

I think for the more Chrome
interface stuff, I'm sort of

in two minds.

I think as much as you can get
the browser to render this

stuff itself natively and get
away from images with some of

the visual stuff in CSS, making
sure you're using

rounded corners and drop
shadows as much as--

GEORGE CRAWFORD: And then icon
fonts and things like that.

ANDY HUME: Yeah.

And SVG to a degree as well.

And I think it depends.

Some icons, I'm not that
fussed about them

not looking as great.

I think things like the logo
is where you notice it, and

all other people notice
it as well.

GEORGE CRAWFORD: I've worked
with the Economist on getting

the articles to work offline,
and the number of stages you

go through where you add
size to the data.

So if we A64-encode our images
and then store them in Web SQL

or IndexedDB, which tends to be
A16-encoded, every time you

encode the image differently,
you're adding

massively to the overhead.

So if we then double the size
or quadruple the size of the

image file as well, this
is a big issue.

But as I say, I think interface
icons are really

important and other
things not so.

AMBER WEINBERG: OK.

So our own Andrew over here
asked an important question.

Is increased page weight an
inevitable side effect of

responsive web design versus
just a regular

separate mobile site?

RAZVAN CALIMAN: Yeah.

So if you talk about responsive
websites and you

look at images, for example, or
written images, there's no

clear-cut way of getting
around that.

Yes, you will have increased
file size with

the responsive website.

But then again, as Ilya and
other people mentioned

earlier, the overhead you have
afterwards is just some fishy

amount, some CSS.

And we're hoping to have the
extra markup you're using for

responsive layouts fixed in
proposals such as grid layout

or Flexbox.

Because that's mainly where
you're adding extra markup or

extra CSS to handle
various parts of

your responsive layout.

So in terms of adding size,
yes, I think right now

responsive websites do incur a
price penalty in file size if

you want to deal with different
size images, which

you should if you do care
about the performance on

different devices and
different browsers.

ANDY HUME: I think you've got to
be careful about taking it

to extremes, though.

Because you can start going down
a road where you end up

polyfilling things like
media queries in all

the versions of [? IE8, ?]

which there are libraries
to do that, and

they do it very well.

But I think that's kind
of missing the point.

If you have to add more and more
of these pieces of these

JavaScript libraries and
polyfills and the like to make

stuff responsive, I think you
will end up in a situation

where your responsive site's
mobile view, if you like, is

worse than it would have been if
you had just optimized for

mobile in the first place.

RAZVAN CALIMAN: Yeah.

I totally agree on this.

Of course you need to look at
the device, the context, and

where people are going
to use it.

Of course it doesn't make any
sense to polyfill for media

queries and the like.

So yeah, I do agree.

You find your lowest common
denominator, and you build up

from that, but you ensure you
give your users a good

experience.

The point is that I am in
favor of quite a lot of

polyfills right now, because
there's a lot of technology

that hasn't been tested quite
yet, and everybody's waiting

for it to come into browsers.

And polyfills give you a very
good opportunity to build the

technology experiment with it
and learn that some use cases

just don't fit--

like, see the AppCache model.

ANDY HUME: Or the Columnflow
stuff.

GEORGE CRAWFORD: I think at
every stage of the way we need

to bear in mind the good
user interface as well.

As soon as people get on to the
bandwagon of responsive

design and layout and
development, it's so easy to

add bells and whistles that
really aren't necessary or to

change the feature image for
each 50 pixel breakpoint as

the user resizes their browser
window and things like that.

And you have to really consider
how your users are

going to work through the site
and whether some of the

enhancements are really
necessary.

AMBER WEINBERG: Well, kind
of related to polyfills--

the newest CSS3 specs and stuff
are getting really,

really complicated in the
area of responsive

development and stuff.

And a user--

you, George--

asked, is it OK to continue to
push for more and more CSS

modules like Regions, Grid
Layout, et cetera?

Or is it actually
OK to just use

JavaScript solutions instead?

I kind of wonder that myself,
because CSS was known to be a

simple language--

easy to use, easy to learn.

And now it's becoming so
much more complicated.

GEORGE CRAWFORD: That's my point
totally-- that it's not

that I believe that we should do
these things in JavaScript.

Of course there are massive
performance gains to be had

from pushing things to GPUs and
all that kind of stuff.

But just looking at the average
CSS file now, it's

already complicated enough.

A lot of people who have
moved to Sass and other

preprocessors would agree that
we're pushing the limits of

what quite a simple syntax
can include.

And as soon as we get other
modules coming in, it just

gets more and more complex.

And maybe the question is-- is
CSS the right language or the

right technology to
deal with it?

RAZVAN CALIMAN: OK.

So first of all, that's
a very good question.

And I'd like to start
out with Hakim, the

guy that built Reveal.

He sent a tweet recently that
we're asking so much more of

HTML and CSS right now,
considering that it was meant

as a textiling declarative
markup language.

In response to your question,
I do think that we need to

push for more CSS module and
more support in the browser,

specifically on those areas
where JavaScript isn't really

supposed to be working at.

Like in terms of layout,
the browser itself

is doing the layout.

So I would much rather leave it
do the layout and focus my

JavaScript resources, which are
oh-so-scarce, on various

devices, given the complexity
of web applications, not

necessarily the complexity
of web design.

GEORGE CRAWFORD: We realize
that we're sort of almost

wasting time by trying to
optimize things like

Columnflow, because it's really,
as you say, a layout

technology.

And it feels counter-intuitive
to go over and over and over--

why isn't JavaScript perfect
for this job?

It's because it's not designed
for this job.

RAZVAN CALIMAN: It's not
designed for this job, but the

reality is that most CSS modules
don't really give you

the access you need
in JavaScript.

So up until now, there's
been a pretty much

all-or-nothing solution.

Is it all in CSS or
all in JavaScript?

And I really think that stuff
like CSS Regions--

it's intended to be a building
block, so it's not going to

solve your complete
problem in CSS.

But it gives you access via the
CSS object model, so you

can understand how your layout
has been rendered and your

various boxes.

And I think that's really
where CSS and JavaScript

should really work together--
in handing, for example,

layout and event handlers and
content flow differently.

GEORGE CRAWFORD: I was really
excited to hear, when I looked

into Regions, that, yeah, you
start off with CSS, but when

you run out of regions, when you
run out of flowed areas,

JavaScript gets involved,
right?

You have events, and you can
create new elements for

content to flow into.

And there's an

interoperability between the two.

RAZVAN CALIMAN: Yeah.

And at this point, this is
because CSS Regions is

supposed to be a building block,
and it doesn't handle

the complete refill
of the content.

And you go to use JavaScript to
listen to if your content

has fit in all of
those regions.

And that is seen as a limitation
by some people.

And to some extent they're
right, because you need some

sort of a method in CSS.

If you think about layout,
CSS should handle

the complete layout.

So right now the spec is
supposed to work really fine

with other specs like
Grid Layout.

But it's using empty
developments and it's using

the JavaScript just because we
don't have any other spec at

this point that will work.

What I personally would like
to see is some sort of

adoption of multiples to do
elements, so you can actually

define your complete
template in CSS.

Because basically, that's what
I want from my CSS, right?

I want it to easily swap out
templates, easily flow out

content, and leave the markup
to handle just the semantics

and describing my actual
content, right?

ANDY HUME: Do you think part
of the complexity at the

moment is that there are a
number of emerging new CSS

layout modules, and it's not
necessarily clear until we've

started playing around with them
and experimenting which

ones are going to be good for
what type of problems?

So for example, the Regions
stuff is enabling lots of very

new kinds of layouts that
haven't been possible at all

before, really, without things
like Columnflow, too, and

Exclusions in the certain column
and things like that.

Whereas Grid seems to me to be
more about helping us do the

kind of layouts we've been doing
for a while but in a

simpler way, a way that's more
suited to a real layout system

rather than sort of hacking
floats and positionings.

GEORGE CRAWFORD: Sure.

And something the browser can
optimize as well, the

performance of it.

Yeah.

AMBER WEINBERG: All right.

So would it be useful to have
native CSS media queries at

the element component
widget level and

not just the viewport?

And that is related
to our other

question about page weight.

Would that help?

ANDY HUME: From my point of
view, that would be a very

nice thing to be able to do.


That's not something you can
abstract into a system and

have work at the moment
for various reasons.

But it's desirable.

And maybe there's something
around--

George mentioned web components
and being able to

codify behavior for a particular
type of interface

element and deal with those kind
of exceptions that might

arise on a sort of case-by-case
basis.

GEORGE CRAWFORD: I think this
modular idea is really

interesting, where in the
JavaScript world, we're

leaning more and more towards
modularized code, which is

good development practice
anyway.

The work I mentioned that we
were doing is mostly being

done by Wilson over there
on the FT's web app.

And he's sort of almost faking
the shadow DOM and custom

elements before it's arrived
by using media queries to

write before and after
pseudo-elements with content

on individual modules in the
page, and then in JavaScript

reading those tags.

So for example, for a certain
module, you might--

with a before or after
pseudo-element, you might

write the words "column" or
"row." And then the module now

knows that it should behave
as a column or a row.

So that's starting to
fake the media query

on a modular level.

And who knows what's
coming up?

But the problem, of course, is
that we also always need to

wait for the browsers to catch
up with what we need and that

the spec writers need to wait
to hear what we want.

But I think this kind of modular
layout is really

interesting.

AMBER WEINBERG: Do you think
that interrupts the idea that

the content should be exactly
the same on the desktop and

mobile that we're kind of
following right now, if we are

able to swap out different
things

for different viewports?

GEORGE CRAWFORD: So this is
another question that I put in

the Moderator is I think we
probably all come up against

on our mobile devices sites that
are basically truncated

in terms of their usability
until you get to the bottom of

the page and you click
the link that says

View Desktop Site.

And then you can actually
use some functionality.

This gets really,
really boring.

And it's going back to the UI
and the content providers.

Is designing for mobile simply
cutting out 30% of the useful

information on the page?

No, of course it's not.

ANDY HUME: I think at some point
in the past, there's

been a desire to try
and second guess

what people call context.

Why are you using the sites
on a mobile device?

Oh, it's because you're walking
down the street and

you want the phone number
of the restaurant

you're going to.

But whether that was ever true
or not is kind of irrelevant,

because it's certainly
not true now.

And deriving some kind
of context, I don't

know how that works.

I'm not sure that you can.

GEORGE CRAWFORD: It was
immediately interesting for me

to hear a proposal that, on
the server, for the first

request, we might know the
viewport dimensions and not

have to do user agent
sniffing.

But actually, as was pointed
out, you can't tell very much

about a device just from
the viewport dimension.

You certainly can't tell
the conditions in

which it's being viewed.

So you don't know whether they
want a huge word displayed on

the screen with the answer to
their question, or whether

they want a 5,000-word article
to read, because you can't

predict that kind
of information.

So we need to give
them flexibility.

But I think having a View
Desktop Site link at the

bottom of the page is
not the answer.

RAZVAN CALIMAN: Yeah.

In terms of using web
components, I'm actually quite

excited about this.

Because when you think about
your content, it's not

necessarily only to give it to
your users in full in mobile

versus on desktop.

You also have to think
about the context.

And if you swap out and you
don't think about content like

text content, you think about
web application controls,

they're different on the
interaction mode on a mobile

device rather than on
a desktop device.

And to answer the question if
media queries are OK inside of

web components or small,
isolated elements, I think

that's really important and
useful, because it gives you

the flexibility of reusing
most of your elements.

GEORGE CRAWFORD: It's not just
that they're isolated from

each other but also that they
can be dropped into other

projects, right?

ANDY HUME: Isolated from
the layout from

the particular page.

MALE SPEAKER: So this is a great
discussion, but I think

that media queries
on other elements

is the wrong approach--

in part because if you look at
how the browsers today treat

media queries, they don't work
too well when the page is

being constructed.

We don't have access
to the viewport.

We don't evaluate the rules.

Like if you look at your rule
right now, if you look at the

webkit, it says, hey, this looks
complicated in the sense

that it's not [? screened, ?]

which means that we're
just going to

download the resource.

And this is a fundamental
trade off.

We don't know the viewport
information when we're

constructing this page.

So this is not the
right mechanism.

Right now, if you declare a
bunch of CSS [INAUDIBLE],

we'll download them all.

So having this information
on elements is not the

right way to do it.

What we're talking about here
is service-side adaptation.

So I think the premise that we
need some way to exclude

certain chunks of functionality
is right.

I think media queries is
the wrong way to do it.

ANDY HUME: Yeah.

I don't think we're necessarily
saying media

queries is the right
technology.

In fact, media queries at the
moment, they make us fixate on

the viewport.

Because in terms of measuring
the width of something, that's

the only thing we have.

And it's actually not
very interesting

that you can do that.

You can do some interesting
things with it, and that's why

responsive design now has
a name and everyone's

talking about it.

But I think, yeah, it's more
granular than that.

The context which you want to
respond to from a layout point

of view is more granular
than just the viewport.

And yeah, whatever you guys
think is the right way to let

us do these kind of things,
I'll go with that.

AMBER WEINBERG: So are there any
front-end alternatives to

responsive web design that can
fulfill the promise of being

device-agnostic?

Or could there be?

ANDY HUME: Java.

RAZVAN CALIMAN: I don't
know what you mean by

device-agnostic.

If you look at the web as we
see it right now, yes.

HTML, CSS, that fulfills the
job of making something

responsive.

But if you look only just a bit
ahead of what devices are

coming and what device-agnostic
means for

Google Glass, for example--

does responsive web design work
for your contact lens?

I think we need to think
about that technology.

And that's maybe a space where
native will actually win.

Because the web as we see it
right now, it works really OK

for one-dimensional,
two-dimensional layout.

What happens in three
dimensions?

I don't have a clear-cut
answer to that.

So whatever we're doing right
now, it's optimized for touch.

It's optimized for pointing,
different screen sizes.

But whenever you change the
screen sizing, whenever you

change the interaction model
from touching to speaking, for

example, does the web offer
the same flexibility to

building responsive?

What do you guys think?

ANDY HUME: I guess it depends
how you define the

scope of the web.

Is it any client technology
ever?

What defines the web?

Is it the open nature of it?

Or is it the--

GEORGE CRAWFORD: Yeah, I
think you've said it.

RAZVAN CALIMAN: The
answer is no.

There isn't a catch-all
technology right now.

AMBER WEINBERG: Right.

So should the browser be more
chatty about its environment,

which we spoke about
in another session?

Should we know what the
viewport size is, what

connection it is,
their bandwidth?

GEORGE CRAWFORD: From the work
I've been doing, step one is

just, well, give us the right
information and ideally, give

it in a unified way
across browsers.

That would really, really
help, right?

When a device incorrectly just
announces its pixel ratio or

something like that, it
basically means you either

added another seven lines of
hack or you have to not query

that information.

And I find that more
frustrating, I think, than not

knowing some things about
the environment.

I think we've probably covered
network and bandwidth and

things like that.

But I think if what we're trying
to do is to provide as

immersive an experience as
native apps, then yeah, we do

need to know a lot about
the device that is

displaying the app.

But--

ANDY HUME: Do we need to
know about that on

the server as well?

GEORGE CRAWFORD: I think
it would help.

I think if I'm working really
hard to store as many issues

of the Economist offline on
someone's device, I know I've

only got 50 meg and that that's
actually 25, because

it's all A16-encoded.

And I would really like to be
able to optimize my images and

to package things up and
effectively do what a native

iOS app is going to do, which is
sort of prepare everything

in advance and ship it.

And then you can cache the hell
out of that, and you get

a really, really good
experience.

You do run into issues where,
if you're running a

JavaScript-heavy site, you
have to, we've already

mentioned, like Mustache
templates on

the server and client.

You even have to start preparing
articles and

additions using Node on the
server, because you have to

use the same logic that you're
using on the client.

But maybe that's fine.

I do understand that any changes
to HTTP are enormous.

And adding one line to a header
is going to massively

affect web traffic as a whole.

But I think in return, we can
stop wasting bandwidth by

delivering totally
useless images.

ANDY HUME: And people are
still doing user agent

detection on the server to--

GEORGE CRAWFORD: Sure,
as was said in an--

ANDY HUME: [INAUDIBLE] --device
into mobile, tablet,

or desktop or whatever.

GEORGE CRAWFORD: As we said in
an earlier session, we're

doing it already.

So test to see which approach
is fastest.

And please, browser vendors,
either don't declare a

property or declare it correctly
or let us know that

it's buggy.

But it really, really makes our
life a lot harder when you

give the wrong information.


RAZVAN CALIMAN: Just one
point to add to this.

It does actually happen on
server-side right now.

And it's particularly useful for
digital publications when

you want to target a whole
slew of devices.

So even though it's not
responsive in the responsive

sense that it happens on the
client side and it reacts to

anything, there's a lot of
versions of the same

publication rendered
server-side.

And you just go there, and
your device is just the

terminal, and it receives
the end result.

And right now that works
pretty fine because

everything is stored.

Everything is controlled.

Ideally, you would want to give
this to the end user,

because you can't really
simulate all of the user

agent's font rendering--

does it have or doesn't it have

hyphenation, stuff like that.

So it's happening right now,
and I think we should move

away from that.

But we need to wait for browser
vendors to catch up on

the technologies we actually
need like decent layout, grid

template, Flexbox, all of that,
because we're actually

hacking right now with those.

So up until we get these HTML
and CSS improvements, we're

going to see a lot more digital
publications which are

just images at this
point because

they're simple to render.

And yes, that's a 700 megabyte
magazine, but it will work

across all of your devices,
because they're pre-rendered

for each screen size.

GEORGE CRAWFORD: But do you
agree in principle that it's

an advantage if you know at
least a little information

about the viewport dimensions,
for example, on the server,

and that you accept that there's
going to be a bit of

downscaling of images?

But rather than enormous to
very small, you can ship a

medium-sized image at the very
least, because you know

something about the viewport
dimensions on the server?

RAZVAN CALIMAN: Definitely.

I agree we need that kind of
information, but you need to

be responsible in
how you use it.

For example, we had an
example earlier--

knowing the bandwidth and the
bandwidth being wrong, you

might assume something wrong
about the device and give it a

bad user experience or a very
good user experience.

But the device cannot
download it.

So yeah, I do agree you need
that kind of information

server-side.

As a developer, you need to use
it and not make too many

assumptions about the device.

GEORGE CRAWFORD: It's
interesting, then, Ilya's

points on media queries that
that's actually responsible

for so much of what we discuss
when it comes to responsive

layout, right?

And the reason we're obsessed
with viewport dimensions is

because that's the one thing
we have on the client to--

well, one of the chief
things we have in

CSS to control behavior.

So it's got a lot to answer
for in a way.

AMBER WEINBERG: Well,
let's move on to the

flip side of the coin.

With all this new stuff that
we have to take into

consideration, what about the
arguments that responsive web

design isn't worth it at all
and that there is merit to

just having normal
zoom-and-swipe sites?

Considering that's
originally--

when Steve Jobs came on stage,
he touted you could have the

full web on your phone.


ANDY HUME: I guess people want
to create designs that fit

that device.

And if you look at what people
create for the iPhone natively

and the iPad natively, it's not
double-tap to zoom in on a

column and swipe around.

And I think that's what's
driving what we want to do

with web technology, is the
stuff that's happening native,

to try and create more engaging

experiences, to coin a phrase.

GEORGE CRAWFORD: We've struggled
to define what a web

app really is sometimes.

But one possible definition is
to do with how immersive it is

and whether you feel
your app has been

designed for your screen.

And if you see the whole of the
BBC News front page on a

screen that size, it's
fantastically easy to get to

the-- if you know the layout of
the page, you don't need to

read the words.

You know that the link you're
looking for is in the

bottom-right of the page.

It's super quick to get to that
content, but it doesn't

feel so immersive.

But then maybe we go too far the
other way that you get a

beautiful layout with
a full-sized image.

And you know you can swipe
through 12 images, and it's a

satisfying experience.

But where the hell are the
links to find my content?

And we really have to take
both kinds of directions

before we find the answer.

We were talking earlier about
pagination and what the

solution is for presenting
text-heavy sites and visual

media-heavy sites in
terms of pages.

Do we want the content
to scroll?

Do we want it to be
split into pages?

And I think this
kind of thing--

the third option maybe is to
present everything at once and

then to have a tap-to-zoom
kind of paradigm.

It really depends
on the content.

The point I made was, for the FT
and the Economist, I think

pagination's really useful.

Because if you are distracted or
look away for some reason,

everyone knows how
to read a book.

We all know that if you look
away and you look back to the

book, you have a rough idea that
you were halfway down the

right-hand column.

But when you're looking at a
single-scrolling column of

text, it's sometimes
very hard.

And I find that I have to
concentrate more on the

mechanics of what I'm doing
when I'm scrolling.

And just to simply tap
or swipe to go to the

next page is great.

But then you made the point
that this is not at all

appropriate for some
other sites.

RAZVAN CALIMAN: Yeah.

We need to take into
consideration media-rich

digital publications.

And you want to do it in a
paginated responsive view.

You easily find that you're
going to lose context between

the text and illustrations or
pictures the text is referring

to if you want to embrace
responsiveness.

And cutting off an image
at the middle page is

not really an option.

And if you do move the image
or the illustration to a

different page, you end up with
a lot of white space on

your pages, which you can't
really control.

And you have to understand
that a lot of digital

publications are coming
from print.

And that's where designers are
used to having a lot of

control over where content goes,
where text is on the

same page with the
illustration.

And the trade off when you take
on responsive web design

with paginated view is that
you lose a lot of that

fine-grain control over where
your content is heading.

So I am actually keen to
understand even more how

people see pagination as an
advantage on the web when we

are accustomed to the paradigm
of scrolling or tapping.

And where it makes sense, for
example, in text-heavy

articles, like you mentioned,
that's a very valid point.

But does it make sense
for anything else?

AMBER WEINBERG: So should
responsive web design, then,

emulate print?

On a 27-inch screen, is having
six columns go all the way

down and all the way across
going to be easy to read?

RAZVAN CALIMAN: I think
web design should

emulate a bit of print.

And that's something the
Exclusions spec is doing.

And that's something
specifically that should be in

CSS, because JavaScript is not
really meant to do something

like that, flowing text inside
of shapes or around shapes.

GEORGE CRAWFORD: And typography
as well, like the

hyphenation and stuff.

It would be great to have good
support for that, right?

RAZVAN CALIMAN: In terms of
moving the complete idea of

print to digital, I think
that's the wrong idea.

You don't really get anything
with six columns of text.

You don't get more information
out of that page.

You have to understand that
print has evolved like that

into multi-column layout and
having multiple articles on

the same page because of the
physical constraints of the

page, something we don't
have on the web.

You can actually use the device
size to your advantage.

And if you do have a large
screen size, that doesn't mean

you have to put in more columns

because you have space.

There's the point that
George made.

What's the distance between
the user and the device?

Are you reading that on a TV?

Six columns is not
going to help.

You're going to need larger type
and something optimized

for your laying back on the
couch and reading the content.

GEORGE CRAWFORD: Any graphic
designer will draw your

attention to the whole concept
of white space, that that

really helps.

Maybe I was wrong with my slide
going from the white

gutters on the side to filling
all the available space.

Because it's quite an assault,
visually, to deal with that

kind of thing.

And white space is incredibly
important.

So for sure, the answer is no,
we don't want to fill a

27-inch monitor with columns.

But we need to really learn a
lot from print and then adopt

it to our own.

ANDY HUME: Yeah, I think it's
natural that we look at things

like print or what's been in
the past to kind of inform

what we're trying to
do in a new medium.

But the reality is it
is a new medium, and

it's still quite young.

And these things, as we learn
by adopting bits of print--

and some stuff does work,
some stuff doesn't--

we'll learn more about the
medium that we're actually

working in.

That's assuming it doesn't
move so fast that lessons

we've learned one week aren't
relevant the next, when you

consider we're now talking about
TVs and the distance

from the screen and things.

AMBER WEINBERG: OK.

So kind of on the same layout
issue, Oliver asked-- current

responsive web design solutions
to grid systems make

for very complicated
presentational HTML.

Defining the same behaviors with
CSS, on the other hand,

is very tricky.

So what needs to be
the middleman?

Is that still JavaScript?

Or is there going to
be something else?


ANDY HUME: So I'm not sure
that there is a middleman

available at the moment.


I think I understand what he's
saying when he says there's

lots of presentational
class names in HTML.

And I think at the current
point in time, that's the

solution you should
move towards.

As I said, I find being able to
have a layout system that

is abstracted from everything
else, a grid system, and then

implement it in markup easily
is very valuable for all the

reasons we've talked about--

making sure components
are extracted

from layouts and pages.

And at the moment, the easiest
and simplest, most

maintainable way of doing that,
in my view, is with more

presentational class names.

What we have coming in the
future that I think will help

this is the Grid
Layout module.


AMBER WEINBERG: Is that it?

OK.

So we just have a couple
of minutes left.

I have one more question
for you.

Very quickly, if you could have
one thing, anything in

responsive web design approved
by the spec or majorly

implemented in any browsers,
what would your

dream feature be?

RAZVAN CALIMAN: Overnight
grid layout templates.


GEORGE CRAWFORD: I think,
because of my work on

Columnflow, I think Regions.

Maybe I'm not so clear on how
they all interlink, but the

demos I've seen of Regions
just look great.

I've spent a long time flowing
text into areas.

And just to have something
that will do that

for me would be great.

ANDY HUME: I'm inclined to
agree with grids mainly

because I get just as excited
about new stuff that's going

to make my life easier rather
than new, shiny stuff.

And also media queries at a
component level, however that

might be implemented.

And call it media queries.

AMBER WEINBERG: Well, I would
like something for retina,

something easy.

All right.

Well, that is it for the
responsive panel.

And thank you, guys.

[APPLAUSE]


CHRIS HELLMANN: Hello and
welcome to the one before last

session on privileged access.

That's why I brought
the [? Politsi ?]

tee shirt to give you, not
there, not there, we go there.

So it has to be organized.

So we've got a panel of
illustrious people here.

So we got Diana from Vodafone.

We've got Paul Kinlan
from Google.

We've got Petro Soininen--

PETRO SOININEN: [INAUDIBLE].

CHRIS HELLMANN: OK.

Fair enough.

ex Nokia and now at Five.

And as we didn't have enough
blanket statements and

outrageous swearing, we actually
brought Brian Leroux

from PhoneGap with us as well
who is actually going to start

the whole session by
telling us-- for 10

minutes and not longer--

what we are all about here
about privileged access.

So take it away.

Take your closed technology and
show us what you can do.


BRIAN LEROUX: OK.

Can you guys hear
me all right?

AUDIENCE: Yeah.

BRIAN LEROUX: Yeah.

Well except for old man Russell
in the front there.


So I'm going to talk to you guys
today about privileged

applications, packaged
applications, sometimes we

call them installable
web applications.

I've even heard it called
a thick client.

So--

oh come on pointer events.

There we go.

I work on a PhoneGap project
which you may have heard of.

It's for building apps using
HTML, CSS, and JavaScript.

And it's very much like a
packaged application.

You host the assets
on a device and

we load them locally.

They're intrinsically offline.

And it's also a powerful
extensibility layer.

So PhoneGap lets you get
at, basically, anything

the device can do.

And that's what we're
talking about.

So the question that we were
posing was, did the web solve

cross platform?

And I think when it comes to
things like screen sizes and

operating systems, the
web did solve cross

platform really well.

Somebody was talking about Steve
Jobs earlier when he

said, you're going to build
apps and you're going

to build web apps.

And I love that.

I thought that was
a great vision.

But web didn't solve
everything.

Web intrinsically is sandboxed,
and this is

actually not a bug.

This is a feature.

This is how the web works.

But because it has this
capability or this feature

that it's sandboxed, it
also doesn't have

access to device APIs.

And so it's at a disadvantage
when it comes to native

applications.

It's sandboxing.

I guess another disadvantage
of the web is that it can't

participate in app stores
which maybe

we'll talk about later.

I don't think this is exactly
what packaged

applications are all about.

So I don't know if you guys have
noticed but there's this

trend lately towards web
operating systems.

Google's got Chrome OS.

Microsoft has Windows 8, which
uses HTML, CSS, and JavaScript

to build applications.

Some guys called Mozilla
are doing a thing

called Firefox OS.

There's this thing called Tizen,
which is an open source

web operating system by
Samsung and Intel.

And then there's
Web OS from HP.

It kind of makes me sad so
I don't like to talk

about it too much.

But there's all these things.

So if you think about Google,
Microsoft, Mozilla, Samsung,

Intel, and HP are all betting
on the web for their next

operating systems which is a
pretty interesting thing.

And these are all privileged
applications and packaged

applications.

Mobile is not quite so kind, but
luckily, with PhoneGap we

can get to these things
and we can get

inside these app stores.

And this is not a cheap shot--
this is just a statement of

fact and it's kind
of interesting--

all of these app stores
themselves are web

applications.

They're hybrid apps.

You can't install an

application without the network.

And typically when you're
browsing for apps in an app

store, you're going
to the web.

So forgive me if you've heard
this before because packaged

apps are not a new concept.

This has been around
a long time.

It used to be widgets
inside of Vodafone.

There's this thing called
confabulator from Yahoo.

Think it was Yahoo.

PETRO SOININEN: Yeah.

BRIAN LEROUX: It was Yahoo.


Maybe this thing called AIR
from this other company.

I can't remember who they are.

The idea has been around
for a while though and

it's not a new thing.

So apps that are designed for
a particular platform are

incompatible by their nature.

If you build for a particular
operating system, you're not

going to ship it on other
operating system unless you

believe Blackberry 10, you can
put Android apps on it but

that's another thing
all together.

So that's why we
have standards.

That's the point of
web standards.

And there's actually some
emergent standards that are

around this, and there's
some older ones too.

So there's a thing called the
Widget Spec, which kind of

died in a horrible death, but
it's around in its own way.

Bruce is going to cry.

I'm sorry, Bruce.

It's not around anymore.

There's the device API Working
Group at the W3C that thought

we need all these device APIs.

Let's standardize all this
stuff, but they didn't think

about the security model with
enabling things like camera

and contacts and all
these device APIs.

So there's a new group now
called the System Applications

Working Group.

And it's starting with the idea
of the runtime context

and security model.

And I'll talk about that
in a little bit.

So to be really clear, what
we're talking about here is

packaged web applications.

We're not just talking about
packaged applications because

packaged applications
have happened

before and they've failed.

The web is naturally
interoperable.

The web has this DNA where
things are portable, and this

is what we're looking for.

And this is why packaged web
applications are important.

So this is where shit gets
a little bit boring.

Every application, or every
packaged application has to

have a manifest.

And a manifest is going to have
things like your title,

your icon, your license, your
author, the things we need to

know what to display
when we have a

springboard for the app.

But then it starts to get a
little bit more interesting.

It also has to have an origin
because we need to know where

to go to update it, which
kind of comes back

to the offline stuff.

And it also needs to have white
listing for the network

because a packaged application
typically runs local on the

device but it needs to
know where it can

go to go get data.

Packaged applications also have
permissions for features.

We don't want every application
to have access to

your front facing camera, and
so you have to be able to

declare this.

Packaged applications are
also a runtime context.

So in the case of PhoneGap, we
run on the file protocol.

So file://indexHTML is
where we load stuff.

But this means that all these
applications intrinsically can

do cross domain requests, which
is dangerous, which is

why we have to white listing.

The runtime context also has
some weird properties that are

a little bit different than
other types of applications.

So window.open, for example,
might open an in-app browser

instead spawning a new tab.

File system locations can be
different, that kind of thing.

Thank god there's beer.

OK.

So I'm trying to go
quick here, Chris.

Apps live a really
weird lifecycle.

So an application right now in
a browser, you open a tab, it

starts up, you're good to go.

An application running in a
packaged application runs in

kind of these different modes
and so we have online and

offline events.

I'm of the opinion that we
actually need more information

than just online and offline
but we can talk about that

over the beers later.

We also have pause and resume
so there's something called

the page visibility API in the
web but it's a little bit

nascent right now.

And it's the same thing, but
when you're looking at

applications that are running on
a phone, we can put them in

the background.

They may or may not be able
to do anything about that.

Then there's system
notifications.

And so the classic example I
like to give here is a battery

notification event-- if your
battery is about to die, you

might want to back up
your information.

We implemented this in PhoneGap
and unfortunately,

polling the battery drained
the battery.

So we didn't know what
to do to fix that.

This is a property of packaged
applications too.


So there's runtime security
beyond the sandbox and this is

where stuff is most
interesting.

There's things like
network security.

There's encrypted key stores
possibly on some devices where

you can store data on
the phone securely.

And that's where we get
to device APIs.

So I like to put device
APIs into two buckets.

You've got system sensors
and you've got data.

Sensors are things like your
camera, your accelerometer,

your geolocation, and
that kind of stuff.

GPS.

Data is like your file, your
contacts, your media.

That's what we want to get at.

That's what the web
can't do today.

And that's where the web needs
to go if it wants to compete

with the native platforms
that are out there.

And that's why we're seeing
all this work going into

standardization.

So all this stuff is cool and
everybody wants it, but if

we're not careful, we're
going to shoot

ourselves in the face.

And this is why runtime
security

context is super important.


Awesome, right?

I just wanted to use that GIF.

It's all I got.

Thanks.


Do you want to leave that?

CHRIS HELLMANN: It might be a
bit annoying after a while.

Let's just switch to
something nicer.

How do I type Mozilla's hiring?

No.

OK.

It's good when you get the
speakers drunk first because

then they're much faster
than normally.

BRIAN LEROUX: Did
I go too quick?

CHRIS HELLMANN: No.

That's OK.

We've got more time for
questions then.

That's pretty good.

So as you said, it's an
interesting concept because I

spent the last few months now
talking about Firefox OS to

people and talking about
packaged apps to people.

And every time you talk about
web apps and people are like,

what is that?

I don't quite understand it and
it seems to be this hybrid

that people just don't
get around first.

So to start with that, what do
you think is the main thing

that keeps us from having proper
apps that could be, in

terms of privileges,
on par with

native apps at the moment?

Is it an understanding
problem?

Is it that every provider has
a different manifest format?

Is it that people just don't
trust web apps yet?

What do you think is the biggest
barrier that we have

to overcome?

Let's go through
you one by one.

Diana, what do think?

DIANA CHENG: OK.

There are few things.

Application packaging
is an issue.

It's completely fragmented
at the moment.

Yeah.

This is the way I'm supposed
to hold it.

Another issue is security.

So everything that runs
in the browser has to

have limited access.

So as has been mentioned,
[INAUDIBLE] had a different

device APIs.

Working Group had a different
surface [? cope ?] first and

it was called device APIs and
policy working group.

And then the policy bit got
dropped because websites are

intrinsically--

or you have to assume that
they're going to be malicious,

that they can do
a lot of harm.

So they cannot get write
access to a lot

of data on the device.

They need to be sandboxed
and all that.

So we need a different
sort of runtime.

We need a security model.


You know that the new working
group is working on new APIs

that have extended permissions
that will be installable, that

will, hopefully, be certified
by an app

store, will be signed.

And this is one of the
things that is new.

And it's great that we have
implementations like Firefox

OS and they're going to
put this in the wild.

It's not going to
be just specs.

It's going to be an
implementation.

CHRIS HELLMANN: Cool.

PAUL KINLAN: Yeah.

So I think the biggest thing
for me is we haven't got a

unified permissions model.

We don't know.

If you're on the open web and
you're kind of driving past a

URL, we haven't got anything
that's even slightly

considered compatible
across browsers.

And I also think we haven't even
dealt with the fact that

a lot of the things that
we want to do in native

applications we want to do
with things like USB.

And we don't even know how
to like opt the user

into access a device.

In Chrome, we've got the ability
to query some device

ID to see if it's present on the
USB bus and then you can

open it up and read
and write to it.

But we're still trying to make
sure that we've got that

permissions model quite right.

BRIAN LEROUX: And isn't
that like a

fingerprinting issue too?

PAUL KINLAN: Yes.

Well, that's actually why it
changed relatively recently.

Well, not exactly
why it changed.

BRIAN LEROUX: You've
accepted that

fingerprinting is going to happen?

PAUL KINLAN: Well I think
everyone always has to accept

fingerprinting at some point
is going to happen.

You can look at the EFF website
or whatever it is and

they'll show you all the unique
characteristics of your

normal browsing session.

The thing from the USB side of
things is that we're trying to

get to this place where, maybe
in the manifest, you say that

this application can have access
to your Fitbit or those

types of different devices
because you normally have a

vendor ID and a product ID.

And then that might actually put
people off from actually

installing the application,
especially if

they don't have it.

So we're starting to also move
to this idea of a runtime

permissions model for those
types of things.

And I don't think any of the
browser vendors have even got

to any level of consistency.

That's my biggest thing.

CHRIS HELLMANN: Cool.

PETRO SOININEN: I think for me
it's the thing that even if

you actually understand what
the hybrid concept or the

package web app concept is, is
that a lot of the customers

that we work with just say that
they don't have enough

experience or enough examples
of packaged web apps that

actually do deliver the
UX that they're

going to be happy with.

So I think that we still lack
real showcases and real kick

ass applications that
actually deliver.

CHRIS HELLMANN: Which is quite
bizarre because seeing that

even in the native markets,
a lot of them are actually

packaged apps with PhoneGap.

They're just not advertised
as those.

BRIAN LEROUX: That's right.

Yeah.

CHRIS HELLMANN: And some AIR
ones as well, funnily enough.

BRIAN LEROUX: Tons.

CHRIS HELLMANN: Yeah.

So the questions to moderator
are actually all going around

the same topic, which is the
biggest topic that everybody

has to deal with, how do I make
my end users realize that

they're giving permission
right now?

Do we really need to ask for
permission for everything?

And how do we make sure we don't
overload people with a

question every time they
do one action?

Do you want to move
the mouse left?

Are you sure?

BRIAN LEROUX: Yeah.

CHRIS HELLMANN: These
kind of things.

Where do we draw the line?

What is the real problem
with that?

BRIAN LEROUX: This is the key
issue to me because we don't

want to have web Vista where
it's like asking permission

for everything.

Can I access your camera?

Can I access your contacts?

Can I use your file system?

That user experience
would totally suck.

At the same time, we don't want
the user experience to be

website XXX has access to my
front facing camera and my

contacts, and yeah, we don't
have to go any further with

that analogy to know that
that's a bad thing.

CHRIS HELLMANN: Speak
for yourself.

BRIAN LEROUX: So browser vendors
are challenged by this

too because I think Google's
proposing something.

They're trying to come up with
language in the system

applications working group.

How do we have this thing called
like a trust gesture

where you say to the browser,
hey, I trust this thing maybe

one time, or I trust it
for all the time.

We wanted to be able to get back
to those permissions and

look at them and maybe revoke
them possibly in case website

XXX turns a new leaf.

CHRIS HELLMANN: It's also
no timely access.

It always seems like it would
be a black and white thing.

I give access and that's it,
but I could grant, for

example, a guest pass for an
app to access my camera for

the next five minutes and then
I have to revoke that again,

or it revokes automatically.

I mean, Flickr had this for
guest access to your photos,

for example, that you could
send somebody a string and

like within an hour they could
look at your stuff but after

an hour they can't
login anymore.

That would be another
way of dealing with

that, wouldn't it?

That I could say, OK, for the
next five minutes I want to

try that app out but after that,
you don't get access to

the camera anymore.

PAUL KINLAN: I mean, we could,
but that exists anyway, right,

in the sense that if you do a
get-user media it normally

pops up a little bar
across the top.

It's because the hardware
manufacturer actually puts a

little LED at the front so you
know it's on, it's actually

doing stuff.

But once you actually finish
with the stream, then it

closes down.

The next time that you request
it you get the

prompt again normally.

CHRIS HELLMANN: Yeah.

PAUL KINLAN: I don't know.

I look at kind of having to
re-grant storage permissions

and increase storage.

People just press the buttons
normally and we don't know

what's going to happen, right?

BRIAN LEROUX: That's the
Android problem.

It's like, oh, this app wants
to do everything.

Cool.

Install.

That's what happens.

Then, later on, you don't know
what permissions you've

granted this thing because you
can't find it because it's

buried in the system.

CHRIS HELLMANN: One good
question was also when you

look at Facebook, for example,
you can give access to

everything in the world.

Then this app turns out to be
evil and you can actually stop

that access.

So you have a dashboard of all
the apps and what access they

have to which device.

So there's a centralized
way of doing that.

Would that be a solution that
we could think about?

That instead of every app having
to ask these things, I

have a dashboard of this
app has access

to these five things.

So you have one grid on your
system that actually allows

you to control all of that.

PETRO SOININEN: Yeah.

I think I'm in this on
the previous kind of

proposal that you make.

They both make sense.

And there are a lot of
other good ideas on

this front as well.

But I think one of the key
things is also just to make

sure that users actually
understand what are they

accepting and then, again,
the mechanisms--

how they can actually
control it.

So as you said, that they're
probably just going to be

pressing the OK, OK, OK and
not really think about it.

But that's not really
technology.

It's more like psychology and
trying to figure out how

humans think.

BRIAN LEROUX: Paul , you were
talking about this at lunch.

You guys had difficulty with
the messaging or something.

PAUL KINLAN: Yeah.

If you look at the way that we
have our installable kind of

hosted apps and packaged apps
in the next packaged apps,

essentially, we have had kind
of this messaging issue.

If you go to install the
application, and you're on,

say, the detail page, it'll
tell you all the

things that it does.

I don't know how many users
actually look at that.

But when you press install,
there are at least three

different levels of ways that
we prompt the user.

So for some things like
unlimited storage, which is a

permission that you can have,
we don't even tell the user.

It's just kind of assumed.

There is, to your point before,
there's actually a

dashboard inside Chrome where
you can normally access like

the levels of permissions that
your applications have and

revoke them.

But normally, when you revoke
something, it means

uninstalling the application.

So that's a different
part as well.

CHRIS HELLMANN: Is it
an innovation thing?

Because we had app cache, then
we had local storage, then we

have Nxdb, then we got web SQL,
and we put an interface

for each of them in the browser
rather than having one

interface for storage and saying
OK, this app wants to

store stuff offline, wants to
store things in a database,

and wants to store things
only for this session.

Do you want to allow this?

Is it now the time to actually
look at all the browsers again

and find a unified interface
for that?

PAUL KINLAN: I mean, there's
also this idea of quota system

which has been banging around
for a little while.

You can request some storage
or an increase in unlimited

storage, for instance, and
it goes across all of the

different types of persistence
mechanisms that you have

inside the browser.

BRIAN LEROUX: Is that
the Quota API?

PAUL KINLAN: Yeah.

BRIAN LEROUX: Yeah,
yeah, yeah.

PAUL KINLAN: Yeah.

These things exist.

We just don't think we've
got consensus

amongst the vendors yet.

I don't know what we do
other than talk more.

CHRIS HELLMANN: Diana,
you wanted to--

DIANA CHENG: Yeah.

I just wanted to say with
regards to that, it's a

difficult thing to agree on
because there is no place to

agree on that.

So this is not something you
can write on a spec.

Right?

On the spec you write things
that are testable, that are

verifiable, but you don't
test UI stuff.

Even in geolocation there was
only so much we could ask.

You should specify the host of
the site that is requesting

the permission and
you show that.

But it's very, very hard to find
a place where you make

people agree on this.

CHRIS HELLMANN: So during lunch,
we talked about widgets

already and I remember
both Vodaphone--

I worked back then on it-- and
Opera were the first ones to

do W3C widgets to actually
have little apps on your

desktop that can run even
when Opera was closed.

So that didn't take on.

Why do you think?

We needed the app model on
mobile phones for people to go

back to the app idea?

Or is it just that on a desktop
nobody understood the

concept of having an app that
actually is in web standards?


PAUL KINLAN: I don't know what
the official answer is, but

it's like just generally
widget was a

weird word, for one.

It didn't denote anything like
an installable application for

me at least when I was
looking at it.

BRIAN LEROUX: I believe they're
an evangelism team.


AUDIENCE: At the time somebody
begged them to change the

stupid name.

PAUL KINLAN: Yeah.

If you look at the spec, a lot
of this stuff is very similar

across all the manifests that we
have apart from it's an XML

and not in the JavaScript
notation.


It's kind of interesting.

CHRIS HELLMANN: So one question
that people had was,

now that every single app
platform, like packaged app

platform in HTML has a different
manifest file, is

there a way to actually
automate that?

Is there already a script
out there--

PAUL KINLAN: Appmeter.com.

CHRIS HELLMANN: --to generate
all of them?

PAUL KINLAN: Yep.

We made one called Appmeter
which did Chrome apps, that

was very specific to Chrome apps
but Firefox apps aren't

too dissimilar.

I think, Bruce, you had one?

Or you--

AUDIENCE: Scott Wilson from
Apache Project had--

PAUL KINLAN: OK.

AUDIENCE: [INAUDIBLE]
translate Chrome.

PAUL KINLAN: Yeah.

There's been a couple of these
ones where the core

functionality in most
of the browsers is

pretty much the same.

We are diverging now a little
bit where we're starting to

get more hardware access.

But we're still, as an industry,
exploring what that

means and kind of what
that entails.

But yeah, we've had the ability
to kind of convert

between them but I've not seen
a huge appetite for it.

BRIAN LEROUX: We've got a
library called Confetti in the

PhoneGap project that
will spit out all

the different formats.

So instead of trying to push
an agenda on one format, we

just decided we would
support all of them.


CHRIS HELLMANN: It's interesting
because the apps

themselves are they
that different?

It's like, can you just build
one app and just render it on

all the different platforms?

Because if we're not
inter-compatible in HTML5

itself, then we can not really
tell the native clients off

that they're on.

DIANA CHENG: Besides from the
manifest format, I don't know.

I mean, the technologies
are the same.

It's a package directory.

And I think since Alex is at the
front that maybe this is

something that TAG could
address, like the

fragmentation, in terms
of packaging format.

It's a long term problem in the
W3C and it would be good

to find solutions.

BRIAN LEROUX: Save the
internet, Alex.

PAUL KINLAN: Yeah.

Yeah so we've got different APIs
at the moment as well.

Fundamentally, I think Mozilla's
got the web API

system and we've got our
own Chrome name space.

Until that kind of settles down
and we know exactly what

we need from APIs.

A normal web application, like
something that you would

expect to get in your browser
but that's got a little bit of

installability and all this type
of stuff, we've probably

got broadly compatible across
a lot of these platforms.

It's when you get to these new
bits like UDP, TCP, USB,

Bluetooth, these things that
people want from their native

applications, but we don't
have access to

them inside the browser.

We have to work on that
all together.

CHRIS HELLMANN: Shouldn't
they already want to?

Isn't the big problem that I
can't take a photo at the

moment across browsers?

Aren't we already thinking about
the hard projects where

we don't even have parity with
native apps at the moment?

PAUL KINLAN: I mean, the latest
browsers we can take

photos and we can save
them in the gallery.

We can do these things.

We might have not done a greater
job at evangelizing

these bits--

CHRIS HELLMANN: Well then,
do it in the iPhone.

PAUL KINLAN: You can, in the
latest one, I think.

BRIAN LEROUX: You can.

Media capture is there.

PAUL KINLAN: Yeah.

Input type.

BRIAN LEROUX: It's [INAUDIBLE]
user media but it's input type

in the camera.

It declared [INAUDIBLE].

CHRIS HELLMANN: OK.

Question there?

AUDIENCE: Yes.

[? Jonas Sicking ?]

from Mozilla.

I've done a lot of work on that
platform for Firefox OS

including the web
APIs and so on.

One of the reasons we don't have
compatible manifests, is

that we haven't actually
tried.

The device API group went off
and did all the APIs but it's

kind of like they came at it
from the wrong way of not

doing the runtime first which
is why there was no common

ground to sort of build these
things on top of it.

The sys apps working group is
the first real time we're

actually trying to standardize
the packaging format, the

runtime model.

There are proposals a couple
of them including one from

Mozilla for defining a
standardized manifest and

packaging format and so on.

I also wanted, since I
have the microphone--


the app model in Firefox
OS is absolutely not

packaged apps only.

We do a lot to enable web
applications to run just like

a normal website runs today, but
as much as possible enable

it offline, which it's not quite
there yet but we are

hoping to get it there.

BRIAN LEROUX: I honestly don't
think it's an issue either.

It's just a metafile format.

And it's kind of the
most boring bits.

The permissions is going to be
the thing that needs be solved

and the rest of it's like
where's your app icons and

what's the title on the
springboard and that type of

thing which is--

PAUL KINLAN: There's also the
point that [? Jonas ?]

mentioned a second
ago is offline.

That was like the very first
thing that we tried to do in

the next version of Chrome Maps
is make sure the offline

is kind of deep like baked in
completely, which means that

we've gone away on that side of
things from like the hosted

model right now.

But we thought that was the
biggest thing because if you

move into phones and iPad,
iPhone, and Android, it's a

different development model.

You're offline straight away and
then you need [? to put ?]

online functionality
into your app.

And we believe that, at least
for installable apps right

now, that's the way we
should be going.

CHRIS HELLMANN: One question
here is, to go back into the

UX what everybody asked about,
how do we ensure that people

know the impact of what
they're granting?

How do we make sure that people
don't go through the

Android way of like yeah,
yeah, yeah, I give you

everything because I want to
throw these birds at those

pigs or whatever?


Isn't it the problem
that we have?

Like already the press is saying
that HTML5 will never

be secure and native is secure
and when we start actually

advertising like, yeah, there's
things you shouldn't

give grant access to.

Would there be a bad backlash
towards the platform?

BRIAN LEROUX: It's an education
issue absolutely.

We have to teach people what
these things mean.

And I think we're going to have
to teach people how to

use their devices in
a responsible way.

And that's probably going to,
unfortunately, take a massive

privacy fail before we can truly
appreciate how important

these things are.

DIANA CHENG: One thing that many
people claim, and that I

actually agree for
certain APIs is

through keeping the locality.

So the relationship between the
permission and the action

that needs this permission makes
it clearer to the user.

So having an API that allows you
to specify up front for a

website or web app what are all
of the permissions and for

the user to approve them in a
batch might not be the best

for all applications.

It could work in many cases.

If I just want your
location, then why

would I ask this upfront?

I want to be asked for this when
I actually want to see my

location with relation to
my car in a map, right?

So that helps the
user, I think.

CHRIS HELLMANN: Well,
that's the power of

the web, isn't it?

The immediacy and the on demand
delivery of content and

on demand delivery
of functionality.

Whereas, with packaged
apps and native apps,

we don't have that.

It's like one app per thing
that does it perfectly.

That's fine but I have to
install an app to convert

Celsius and Fahrenheit where I
could enter that in Google in

the search bar as well and
get the same result.

So the question is, how do we
make people aware that the web

apps can't do more than that?

With packaged apps, don't we
just simulate what the other

apps are doing but we don't
have the same access to

hardware and we can't give
the same experience?

BRIAN LEROUX: Well, with the
PhoneGap hack we're just

utilizing what the operating
system does.

So in the case of Apple,
the security

model is to be reviewed.

In the case of Android, the
security model is to have a

permissions manifest.

And then that's all we can do.

Chrome apps, Windows 8 apps,
all these new web operating

systems, Firefox OS, this is the
opportunity to define this

and teach people.

So basically what I'm saying is,
that's your guys' problem.

CHRIS HELLMANN: Because the
issue is I scare a lot of

users off when I just show
them like I want to have

access to 20 things.

This app can do this
and that and that.

Whereas, if the usage of the app
is basic and later on they

go to other levels and
need more access.

And then, the question
should come.

But that's again, a UX
problem, isn't it?

PAUL KINLAN: I don't know.

You have to work it out.

It's actually a really complex
problem because you've got

different times that you might
want elevated access, like the

unlimited storage one is we can
let you know at install

time that this application's
got unlimited storage.

I don't think we do at the
moment for that one, but there

are other ones like when you can
do cross domain requests

without breaking out the normal
site, like the sandbox,

like the domain isolation
at least.

We let you know at install time
that this application can

do that, but it all depends
on the message that we do.

If you put one or two sites
in, we'll tell you you can

access Twitter.com, it
can access Facebook.

But if you put 10 different
like domain sources in, we

basically say this application
can access the

content of your sites.

Because you can't list all 20.

And especially when it's like
a weird regular expression

which is *.Facebook.com/*.

Like normal users aren't going
to even know what that means.

They're just going to see some
weird stuff when they install

it which increases the
likelihood that they'll just

click OK without understanding
the ramifications.

AUDIENCE: I believe greatly in
the belief you should give

control to users.

This is a question regarding
to the permission system.

So I'm wondering about the
problem with education

regarding the user.

The problem I see is that
there's no control to use

actually at the moment.

Users giving a question
regarding giving access to all

of these permissions without
[INAUDIBLE] actually giving

updates set on the specific
permissions.

They don't wan to give access
to contacts, for example.

I think that should
be possible.

CHRIS HELLMANN: Yeah.

The question is you have to give
all permissions and if

you don't give one of them, you
just don't get the app,

rather than it should be up to
you which ones to give and the

app should apply to that or
the app should change

accordingly?

BRIAN LEROUX: I think Chrome
got this [INAUDIBLE].

PAUL KINLAN: We're exploring
that at the moment where you

can request access.

Basically, it's an optional
permission where you can

request access.

You have it in the manifest so
you know the application's at

least going to ask for
it at some point.

And then when you come to ask
for it, you can ask the user

are they sure they want
to do this action.

I think the problem it comes
down to is, one, it's

relatively awkward to tell
developers to go and do this

and the easier one is just to
put the non-optional optional

permissions in.

It all depends on the
functionality

of the app as well.

If the app can live with
it, then it's fine.

If it can't live with it, what's
the point of installing

the app if you need access to
the camera and then every so

often you don't give access
to the camera.

I don't quite know.

CHRIS HELLMANN: In Firefox
OS, we've got

three different levels.

We've got an app that you host
yourself which only has access

to the things that the browser
has in there now as well like

local storage and geolocation.

And then we have an app that
has to go through the

marketplace and we have an app
that only Mozilla and partners

can do that get access to like
telephony and sending text

messages and things.

Is that a good idea or is it
maybe something other people

should mimic?

Because the one size fits all,
that app can access everything

or nothing, is not getting us
anywhere at the moment.

People want to host things on
their own server but they also

want to get access
to the hardware.

BRIAN LEROUX: I like
that model too.

I think these things
are compatible.

If people happen to be running
Chrome right now, you could

click on the favicon icon, and
you can get this contacts menu

in your desktop browser that
shows you all these different

permissions.

And I think this is the early
manifestation of these ideas,

but it is an all or nothing.

You don't have this idea of
different levels of privilege,

the system apps, user apps, wild
west apps, I guess, would

be the third part.

And then there's like the idea
of federation in app stores.

So right now app stores are all
walled gardens per vendor,

essentially, but it
makes no sense.

Why is EA getting permission
from Apple to ship a game?

It's crazy, right?

EA should have its own store.

I trust EA.

I want to play games.

CHRIS HELLMANN: Well if only we
had an open marketplace API

but I'm not going to talk about
that now, but you can

ask me later.

What is interesting about this
is that you said like I trust

EA, but you can't trust
any server.

It doesn't really matter
who it is.

It's like larger companies
can get their

service hacked as well.

It's just a matter of
how do you do it

unless you host it yourself?

And that, to me, is the main
crux of the matter.

I just got an update on an
Android app that asked me for

1.81 gig update.

And you're like, you haven't
understood mobile devices, did

you because I only got 8 gig
on this machine anyway.

So how could we do an app that
are already granted access to

allow it to update
automatically, to only get

parts, to load a new level, to
load to new extra in a game

rather than replace the whole
packaging system?

I think that is failing
on the web.

I don't want to download
an app every

time there is a change.

But the change should be in
an extra API somehow.

BRIAN LEROUX: That's an
imperative API for the cache

manifest would do that.

So you could do delta updating
which I think is the stuff

that Alex and Jake have
been proposing.

Yeah.

It's a big issue.

So PhoneGap apps have this
one all the time.

We have a game and that game
could be gigabytes.

They only want to load the first
level because you want

to be available over the network
and if the user gets

to level two in whatever game
they're playing, then download

those assets then.

It's a huge issue for sure.


AUDIENCE: I think when we were
talking on the permission

stuff, I can give a very short
run down on what we're doing

in Firefox OS, which is we
essentially have two types of

privileges for APIs.

We have APIs where the user gets
asked the question very

similar to GPS and
geolocation.

But there's a lot of APIs where
we just can't ask the

user, like asking the user do
you want to allow this app to

use TCP socket?

It doesn't mean anything.

So for those types of APIs where
we didn't feel we could

ask the user, we have to do it
through a review process which

is very unfortunate.

Because it does mean that it's
much more similar to the iOS

model where it has to be someone
that is a trusted

party that has actually
done code reviews.

Code reviews doesn't really work
but it's kind of the only

thing we have right now.

We sort of have a third model
where it has to go both

through code review and we ask
the user where the code review

sort of covers the security
aspect and the asking the user

covers the privacy aspect.

But these are sort of
the models we have.

The code review part does mean
that it has to be a packaged

app because that's the only
way to ensure that the

reviewed code is what's actually
being executed.

But that's something we'd like
to figure out but this is the

first iteration.

CHRIS HELLMANN: One question
also on moderator was an

interesting one that says, I
trust the cam app from Google.

Why don't we have apps that are
trusted for the access and

go through those rather
than having

the app itself contacted?

I don't want to put the dagger
in but Web Intents did

something like that,
didn't it?

Because I already knew I had
stuff on my mobile phone that

I could take pictures with.

Why can't I get the picture
from that app rather than

having to ask for permission
to access the camera?

Web activities do that, and in
the browser, input type camera

does the same thing.

But an app cannot access it
the same way as far as I

understand it.

Wouldn't that be a way around
that every operating system

comes with apps that are trusted
for different access

to different parts and
it goes through a

security level that way?

BRIAN LEROUX: Do it, Paul.

Go.

PAUL KINLAN: I actually
don't know the answer.

People want natively integrated
experiences like

inside their app.

They would like the camera to
be there so that they can

apply a little fish-eye effect
to it and make their face look

big and all these types of
things in real time.

And we could go down the Intent
model of you delegate

the functionality to a
trusted application.

That's fine, but people want
to integrate it into their

experience, and I don't
know how you delegate

between both scenarios.

Maybe have an activity
Intent-like system at

the same time as--

I don't know.

I think people get confused by
having to switch between apps

all the time.

If you're having all
this functionality.


I don't know.

You've got to get broad
consensus across every single

different type of platform
about well

how do I access contacts?

Do I go to the contact kind
of like contact manager?

Well, obviously if we have 10
different types of contact

managers, it's a desktop
machine and all

this type of stuff.

I don't know.

CHRIS HELLMANN: Especially
with contacts it's an

interesting one because the
interface is optimized for

doing contacts so why should
any app build their own

contact manager on
top of that?

PAUL KINLAN: Well it's not
necessarily contact manager.

It's like people want to share
invites to their friends on

different networks and all
this type of stuff.

There's loads of different use
cases where you want to

integrate it directly into the
experience and that's why you

don't delegate out.

CHRIS HELLMANN: We had
a twitch over there.

Munir, did you want
to say something?

MUNIR: Yeah.

[INAUDIBLE].


CHRIS HELLMANN: As you see in
the Firefox tee shirt, he

actually works on the
web APIs as well.

MUNIR: [INAUDIBLE].

So I'd actually [INAUDIBLE]
exactly solving the issue you

are mentioning.

If an app can't do something,
[INAUDIBLE] are doing

something, permissions or
something, like sending an SMS

in Firefox OS, only the
system can do that.

You can just call that web
[INAUDIBLE] and system app

already has some behavior that
is secure like showing the

[INAUDIBLE].

So all activity should
resolve [INAUDIBLE]

where not want to
do some issue.

Web Intent has [INAUDIBLE]

or Intent on Android.


CHRIS HELLMANN: Another
question we had, what

granularity should permissions
be at?

Obviously having separate
permissions for app cache and

local storage is overkill,
but do we need any

granularity at all?

Would a single privilege status
be enough, like can

take photos, can't take live
video, for example?


Shall we complicate this more
than it is already?

DIANA CHENG: I was going to say
granularity makes UI very

complicated.

And that's something we want
to avoid because developers

don't like presenting
prompts to the user.

That has been proven.

They want to avoid it.

So the more complicated the UI,
the least developers are

going to want to use
any APIs really.

PETRO SOININEN: Yeah.

I think it comes down to what
Paul said earlier that if you

start having gazillion lines
in your prompt asking about

cryptic things no one is
going to understand

what it actually means.

So there has to be a way to
try to keep it simple and

actually understandable
for the user.

CHRIS HELLMANN: It's an
interesting task for the UX

people out there, isn't it?

It's like how to explain
something that complex in very

simple words and then translate
it into foreign

languages as well.

PETRO SOININEN: Yeah.

Plus when you take into account
potential kind of

different legislation
in some areas.

For example, in China you might
have totally different

requirements on what kind of
privacy things you actually

need to ask from the user.

And for example, if you
use the same service

in Germany or whatever.

CHRIS HELLMANN: Yeah.

PETRO SOININEN: Quite
a complex issue.

CHRIS HELLMANN: You can't ask
for gender in Germany, for

example, these kinds
of things.

Yeah.

DIANA CHENG: When it should
arise is also what happens

when the application changes.

When the application gets
changed, if it needs a higher

level or a more specific
level of granularity.

For example, for your location,
we thought OK,

asking for the exact location
all the time when only the

city is relevant.

It's too much.

Why shouldn't we ask for just
city, country, whatever?

Then what happens when the
app actually needs more

information?

They need to prompt
the user again.

Or for a different action in the
same app, 15 minutes later

then you are prompting the user
again for a more specific

permission and that's
not good.

CHRIS HELLMANN: It's
tricky, isn't it?

It all [INAUDIBLE]

to me it seems like we're not
going to solve this one here,

but I love the idea of any app
having access to a permissions

controller that actually would
control all the permissions

possible and actually allow you
to unset, set them, get

new permissions in, and
basically separate that from

your main app.

Because right now, we have to
bake it in somehow and that

just feels like it
doesn't scale and

it's not future proof.

Has anybody thought of that?

BRIAN LEROUX: Yeah and it's also
really closely tied to a

capability model.

So this is another problem that
we're running into pretty

often where we'll have devices
that don't have a camera and

someone will ship an app in an
app store and that app will

utilize camera functionality.

And right now our answer
is that we just fail.

CHRIS HELLMANN: Trying to detect
a camera that isn't

there unless you ship
it with the app.

BRIAN LEROUX: Right.

Yeah.

Buy this app, get
a free camera.

AUDIENCE: Just an observation
about granularity

permissions, really.

It seems that there's no
value in asking a user

can I use index TB?

Can I use local storage?

Can I use app cache?

Because they don't care.

But then something we thought
about in Opera was with like

geolocation.

So we could imagine, for
example, that somebody like a

woman living on her own might
wish to say yeah my tweets can

have my location between 10:00
AM and 6:00 PM but I don't

want my tweets to have my
location after 6:00 PM because

I'm probably at my house.

CHRIS HELLMANN: So Geo-Fencing
that Flickr has?

AUDIENCE: Yeah.

Yeah.

And one of the things that we
looked at as well about a

console where you
can look at the

permissions you've granted.

You very rarely want to see what
permissions did I give to

Mr. Spanky dot DE,
for example.

But you might very well--

sorry, Brian--

you might very well want
to say what things

can look at my camera?

So the question of which way
around the grid goes.

You probably care.

Oh, shit!

What can look at my camera much
more than what have I

given every individual URL
or app, for example.

And there's also with a camera,
of course, there's an

argument for having a big
kill switch so nothing

can look at my camera.

Because obviously you cover the
camera on your phone or

your laptop, but there's no
guarantee that it isn't

actually a camera that's out of
reach that's plugged into

your laptop and you might want
to have a kill thing.

PAUL KINLAN: So one of the
interesting things about that

is I don't know whether we're
assuming that these

applications run inside the
browser, but a lot of the

stuff that especially we're
doing with Chrome applications

is that you don't know they're
actually even slightly tied to

Chrome in the slightest.

So if you're going to have a
permissions model, you're not

going to put it inside your
browser for someone to go in

there and disable it.

And I don't know what type of
operating system level.

We don't control
Windows, right?

So we couldn't put that in.

So we have to go and add a
settings app, for instance, if

we're going to do that type
of thing it's hard.

Yeah, just hard.

CHRIS HELLMANN: Which brings
us to this one here.

What do packaged apps with their
close ties to particular

browsers and web app stores mean
for cross browser as a

platform support?

As I said before, it's like we
always say in HTML5 you write

it once and it works everywhere
and then like

actually that app store doesn't
allow you to do that,

that one doesn't allow
you to do that.

So can't we all just
get along?


When PhoneGap came out,
it said clearly

this is a gap solution.

We want to be redundant sooner
or later and it's been now

four years?

BRIAN LEROUX: Yeah.


Yep.

PAUL KINLAN: But what's
it mean for

across browser support?

That's the question I've got.

If you've package this thing
up to be a deliverable--

it's like Adobe AIR, right?

When you could package a
[INAUDIBLE] on JavaScript it

would run with a really
old version of WebKit.

Does the user know?

Does the user care?

Would they know it's Firefox and
not Firefox that's ruling

the renderer?

If you've got installable apps,
there are installable

apps which are technically
isolated from the browser.

I don't know.

And if you talk about things
inside the browser, then

that's a different
question again.

BRIAN LEROUX: I think with
renderer things have gotten

pretty clean at this point
because of one of the, I

think, biggest triumphs of HTML5
was defining the parser.

So now all browsers have the
same bugs and we don't need to

worry about cross browser
compatibility.

This is just the new
part that's going

to be tough to do.

And there's probably going to be
a jQuery of device APIs at

some point I would assume.

And we're going to have
something that's going to

polyfill all this garbage
and then eventually

standardize that too.

PAUL KINLAN: Yeah.

People are doing it
with Node, right?

So people are building these
Node-based servers which can

talk to AR drones and then go
well I want that to work on,

like a Chrome app.

I want it to work on
the Firefox app.

Well, we'll just port the Node
APIs back across rather than

go and try and learn
the default--

BRIAN LEROUX: Browser find.

PAUL KINLAN: Yeah.

Actually, we use browser find
in our project so it's cool.

CHRIS HELLMANN: One question
we also had is why can't I

trust Open Full Screen without
the user having to give me

permission and the keyboard
access in Full Screen and all

the things we had?

That also ties into why can't I
have a video playing in the

background on iOS?

Why it is click to activate?


Education-wise, we probably know
why all of these things

are necessary.

But it is a valid question
for end users.

Why do I get this ugly window
saying this app is now full

screen because yeah, it's an
app, I want it full screen.

PAUL KINLAN: Yeah.

It's all based on usage and
use cases and developers

actually wanting these
things, right?

And we didn't prioritize
that originally.

We've added it in so that you
can request a window goes full

screen without any kind
of interstitial.

But it's an installed app.

It's a different thing.

And I don't know whether the
access model from the web

translates to installed apps the
same way, where we have to

have an explicit user gesture
for activities such as across

a site and it just going

automatically to a full screen.

You don't want that on
the drive by web.

But as an installed app,
you're probably fine.

You want your game
full screen.

BRIAN LEROUX: Yeah.

It's to avoid fishing.

Essentially because that screen
app could then fake

your Chrome.

It could say, hey, you forget
to put in your bank path.

CHRIS HELLMANN: I think the
best I've ever seen was a

banner that said has your credit
card being stolen?

Please enter your credit
card details here.

That was amazing.

I totally loved that.

So what do you think about
a model that allows you a

certain amount, like you can
store five photos without

asking for permission.

Is that a possibility that we
have tried to buy permissions

and then when they like it, it
seems like you want to store

bigger photos.

Please give us access to the
rest of the hardware.

BRIAN LEROUX: Super
case by case.

But yeah, I like it.

I think it's good.

And this is, for me, also one
of the fundamental issues is

offline storage.

Right now we've got 2 to 5
megs depending on who you

believe which isn't enough
space to do anything

significant.

And so yeah, I think we do
need these piecemeal

permissions to ease people
into the hot tub of it.

Right?

We got to get the
stuff into the

browser as soon as possible.

CHRIS HELLMANN: How
about storage?

I mean, I don't want to go into
index DB versus web SQL.

I'd tell people to
use Lawnchair.

But it's still an issue that
people don't go into web app

development because they
basically say, I don't want to

write for 10 different things.

Why can't your browser
vendors get along?

So what could be an
answer to that?

Use Lawnchair.

Yeah, I know.


BRIAN LEROUX: Yeah.

Use Lawnchair-- no, I don't know
what the answer is there.

I think the browser vendors now
work together more than

they ever have.

The new browser war is
essentially consensus.

That's the new battle that's
happening and it's

speed and dev tools.

Those are the things that the
browsers are fighting about.

So we're winning as devs but
there's just all these things

and storage is one of
them that the native

world kicks our ass.

We need to fix that.


CHRIS HELLMANN: OK.

Any last words?

We're almost out of time.


Give us a timeline.

When can we finally have
packaged apps that work

everywhere?

When can you close PhoneGap?

BRIAN LEROUX: I have
no idea, man.

I don't know.

I thought we'd be done
all this by now.

CHRIS HELLMANN: Do you get a
lot of stuff in Adobe that

people from AIR look at you
like we've done this.

Why do you have to reinvent
it right now?

BRIAN LEROUX: Actually, no.

They're awesome.

You could say that the road was
paved pretty easy and we

have a good roadmap to
look forward to.

Stuff that had been done
in the Flash Player and

with AIR for sure.

Yeah, they're cool.

CHRIS HELLMANN: Good.

What do you think will be
the next thing for you

like Chrome app store?

Will there be Chrome packaged
apps for mobile as well?

PAUL KINLAN: Yeah.

If you look on GitHub,
there's a public

repo and it uses Cordova.

It's our easiest avenue to get
a consistent API stuck across

those devices.

The biggest thing for me is like
the API access whether

it's cross browser or not.

It's like the developer doesn't,
in theory, want to

have to care.

We're supposed to be trying to
solve that problem for them

with HTML in general.

But we are at the stage where
everything is brand new and

we've not really done this
device access thing before,

and we're all trying out
slightly different things.

And at some point, we'll get
consensus and we'll have a

nice model.

But we need to prove that
built-in native apps is a

thing that actually is going to
be cool and works, and we

deliver great user experiences
with it.

CHRIS HELLMANN: Do you see a
slight competition between

apps and asking for permissions
and browsers

having things like WebRTC
and things inside?

A lot of people come to me and
saw something on HTML Rocks

like look in the latest
[? cannery ?]

I can also take pictures so why
do you even complain about

this anymore?

It's like desktop browsers seem
to have some things that

mobile browsers just
cannot get.

And as developers, we try to
show off to each other but

don't understand
the difference.


BRIAN LEROUX: I wasn't
even aware.

Is WebRTC really there?

I mean, I know Firefox
and Chrome are

talking to each other.

AUDIENCE: Yeah.

It's coming to--

BRIAN LEROUX: There's
that other browser.

I'm trying to remember,
Internet Explorer.

CHRIS HELLMANN: Or the
Erickson thing.

Yeah.

DIANA CHENG: I tried WebRTC
on Opera mobile.

So [INAUDIBLE] media and it
prompts for permission but it

didn't really work.

It didn't really show
me my stream.

So I don't know why.

Maybe it's implementing a
previous version of the spec

and I'm just asking it.

BRIAN LEROUX: In many ways, all
this is not [INAUDIBLE]

like the world of technology and
the web is advancing to a

point where it is kind of all
hybrid and the differences

between the native stack and
the web stack are getting

blurrier by the second.

I think that it's not going to
be like web versus native,

it's just going to
be development.

Software development
will be of the web.

CHRIS HELLMANN: Web GL is a
good point there as well.

It gives you like full access to
the graphics hardware which

you cannot do from anything else
which CSS shaders will

have the same thing, which
another company it has a

different 3D engine basically
said it's a security problem.

So we're not quite there yet
but we have a lot of

technologies that try to do the
same thing but we don't

seem to be there to
come up with a

standard around that stuff.

So where do you think
we should go next?

Where do you think people
should push us

to actually do things?

I like people complaining and
filing bugs to browsers.

I think they should much, much
more, but they should have a

good ammunition to say this is
the first thing we need.

PAUL KINLAN: I think they've
been saying that

for a while, right?

They want offline
apps to work.

If it's an app, for instance,
they want that to work pretty

much wherever they are
regardless of connection

status and they want
it installed.

They don't want to have to
launch a browser to go and

launch an app to go and do
something that they would

expect to just find on their
desktop and click and open.

I think if we get those two
sorted, we're on a good path

to working the rest out.

And then it's use case
lead from there.

BRIAN LEROUX: Yeah, I agree.

Totally.

Those are the biggest

challenges for sure is offline.

Discovery may be another one
too, figuring out this app

store thing.

CHRIS HELLMANN: Yeah.

Because we need a search engine
for app stores by now.

There's far too many
out there already.

It's tricky to actually--

when promoting your app means to
have to go through like 40

different app stores, then
something went very wrong

along the way because we had
the internet already to put

your content out there and get
it found by people like Google

and others.

Well thanks very much.

So next we have tooling.

Cheers!



MATT DELANEY: Hi, everyone.

So to start off this performance
talk, welcome to

potentially the juiciest
talk of the day.

You have people who are nice and
hangry before lunch here.

So just to be clear, there were
some kind of questions in

our moderation tool for this
panel that were kind of

overlapping with some
previous talks.

Because performance is
everywhere, right?

So if you look at some of the
questions relating to strictly

kind of network performance
things, those are mostly

covered in previous talks.

We'll mostly skip over those.

So now is your moment to put in
any juicier questions for

front end things, especially
graphics, and all the kind of

client side related performance

concerns you guys have.

So very quickly, I'm going
to run through.

We've got our opening speaker
here, Shane O'Sullivan.

So he's from Facebook,
a UI engineer.

He'll introduce himself
a little bit more.

We have Pavel Feldman
from Google.

He has worked on Chrome
dev tools.

And we have Rowan Beesje?

ROWAN BEENJE: Beenje.

MATT DELANEY: OK.

Knew I was going to
mess that one up.

So he works at FT Labs
with Andrew, and is

known for FT Scroller.

And then we have Chris Lord
from Mozilla, who is a

platform engineer for
Firefox mobile, so

primarily on Android.

So to start, Shane has a little
opening talk for us to

give us a bit of the
lay of the land of

performance at the moment.


SHANE O'SULLIVAN:
So hi, everyone.

I'm Shane O'Sullivan.

I work as a UI engineer
at Facebook.

I spent a couple of years
on the mobile site.

And now I work on our
business interfaces.

As he said, I'm here with
Ron, Chris, and Pavel.

And we're going to talk a bit
about some of the potholes

that are in the road to actually
having a performant

and fast and non-stuttery
website.

The two main things I'm really
going to talk about are

scrolling performance of complex
content, which is more

or less a stress test
for all rendering

platforms, not just web.

People also have a problem
with this on iOS.

God knows they have a problem
with it on Android.

And it more or less
forces us to solve

all the other problems.

And second one is memory
management,

which is quite related.

So to start off, let's
say what the goal is.

The goal is 60 frames per
second animation with no

dropped frames.

This is kind of the panacea.

Everybody wants to get here.


But it's not always possible.

So let's have a fallback goal.

And say, if we can get to 30
frames per second animations.

Make this reliable.

Make it have no stuttering.

This often is achievable.

And in a lot of user tests that
we've done, this tends to

perform a lot better than having
something that runs at

60 frames per second some of the
time, and even 40 frames

per second some of the time.

So if it goes from some 60 down
to 40, back up to 60,

people often see that as being
worse than just having a

steady 30 frames per
second animation.


So nice to have 60.

If we can get a steady 30,
you're generally in a fairly

good place.

So what's stopping
us getting there?

There's a whole bunch
of things.

To start of with is the
large DOM size.

If you want to take something
like Facebook newsfeed, you

have variable height rows made
up of large images, small

images, no images, variable
length text, everything

changes size, and you don't
know what size it is until

you're trying to show
it to somebody.


And also, if you have thousands
of these, which you

technically could, the browser
just starts running into

serious memory problems.

So you have to decide things.

When do you create it?

Do you create it up front
and take an upfront hit?

Do you create it lazily, and
take a hit as people are using

your application?

That often depends on what
you're trying to build.

For example, Gmail takes
a hit up front.

Because they expect you to leave
the tab open for weeks.

Facebook goes the other way,
because it's more of a random

browsing experience.

And they try to make the upfront
hit very small, and

render later.


OK.

So one of the main problems we
have is, if you want to keep

the DOM small, that basically
means you've got to change it

on the fly.

If you have a lot of data to
show, and you don't want to

have a big tree, you've got
to change it on the fly.

And that basically is great.

You've got a nice, small DOM.

But that introduces a whole
bunch of other problems, which

we're going to get into.

One solution people come up
with is have a pool of

reusable DOM elements.

Say you have 20 different
types of

rows you want to show.

Have a pool of each of
them, and reuse them.

So that way you don't go from a
small image to a big image,

back to a small image.

Something with no images,
something with text only.

So this can help.

But you still end up with
kicking off page reflows if

you're not careful.


Also, when you do start changing
things, say you go

from a small bit of text to a
long bit of text, even inside

of something that you haven't
technically changed the

structure of, you can change
the height of it, you can

change the width of it.

And often, you need
to know this.

If you haven't measured
everything ahead of time, then

you need to know how
big something is.

For example, if you want to show
somebody a scroll bar,

they have to know
what size it is.

But the main problem with this
is that touching the

DOM makes Ryan sad.

It makes him very, very sad.

And you don't want
to make Ryan sad.

So measuring the size of a DOM
load, it basically stops

everything.

Makes the browser flush all its
pending operations, and

slows everything down.

So what do we do?

We'd like to keep it
off the UI thread.

This is possible in native.

For example, the Facebook for
iOS app has a completely

separate thread that more or
less does everything the UI

thread does, but does it
off the UI thread.

Measures everything, renders
everything, and then just

passes it over.

That would be lovely.

We can't do that.

One reason is we don't
always have workers

on the latest iOS.

We do on Android.

But we don't always.

Also workers on a single
CPU are slow.

If you're trying to run a worker
on iPhone 4, which only

has a single core, you're not
really getting any gain.

I mean yes, it's different
thread.

But it runs on the same CPU.

And anyway, workers
can't be DOM.

So this doesn't really
help you.


So what can we do?

Hide the scroll bar.

Don't tell people how
much stuff's there.

It's a dirty hack,
but it works.

You don't have to measure a
thousand rows, because just

don't tell them.

Just tell them keep scrolling.

But some people like
scroll bars.

So another thing you can do
is measure when not busy.

This can be fairly tricky.

Because when are you not busy?

You're not touching it now.

What if you start measuring,
you say, I'm going to spend

100 milliseconds measuring
the next X things.

Then in the middle of that 100
milliseconds, someone touches

a page and you miss it because
your JavaScript is running.

You can try and measure in the
middle of a frame, which we've

done before, where we figured,
I spent five milliseconds out

of the 16 or 32 millisecond
frame.

And I'm going to use the
rest to render ahead.

That can work.

But it's really tricky to do.

Something that we're starting to
play with now a bit as well

is measuring on the server,
which is just something we're

only prototyping
at the moment.

But we figure in our use case,
we have at max a few thousand

different ways to arrange all
the individual types of things

on the newsfeed.

And if you have an app like
that, then you can technically

the DOM ahead of time.

Figure out what you fit into.

And just never measure
the DOM at all.

I'm hopeful this might help.

But it doesn't fit
every use case.

But if it does, then measure
things once, and then never

measure them again.


Another annoying thing
is repaints.

Most of this comes in because
images are unpredictable.

They load when you don't want
them to load, like when you're

in the middle of an animation.

They load the wrong size, so
you end up clipping them,

which has its own cost.

Or you end up resizing them,
and it has a massive cost,

which some of the people were
talking about earlier.

Not just network costs, but
obviously performance cost.

And finally, they have
to be decoded.

As we just heard, WebP takes
longer to decode than JPEG,

and JPEG is bad enough
as it is.

So if you're decoding things in
the middle of an animation,

then you're going to
have a bad time.

So what do you do?

Some people defer all
image loading until

you finish an animation.

This is for new images.

That can work.

But it looks bad.

You have a big, empty thing
scrolling by with a little bit

of black text and a
couple of links.

And when you stop, everything
pops in.

It works.

You get nice animation.

And as a start, it's good.

Other people use low res images,
which have a lower

decode cost.

But it still costs paint.

And what we're doing now, or
trying to do, is figure out

how much time each particular
operation, including text

changes and image changes,
take per animation frame.

And we figure we have a 16
millisecond animation frame.

We have used 10 milliseconds.

It normally takes 6
milliseconds to

draw a small image.

So we still have time.

And if we don't, then
we defer it.

And you do get a blank image.

And that gives you the nice
effect of, sometimes you'll

see images scrolling past or
images popping in in the

middle of a scroll.

Sometimes, you don't get to
it, but it tends to look

better than the first one.

That's very hard.

You've got to write
that yourself.

You've got to write
it in JavaScript.

Would be nice if browsers did
these things for you.

But hopefully, we might get
there at some point.

And another one is resizing.

A lot of people think that
resizing images, like just

don't resize.

Don't do it, just clip them.

Often, you can't, as people were
talking about earlier.

Like Jackson was mentioning
at Facebook, we have four

different sizes of images
that we use.

And if you clip them too much,
then it just looks terrible.

You cut off people's heads,
and that kind of thing.

And saying OK, just ship
the right size.

Shipping the right
size is hard.

You've got massive
server costs.

It helps you to be a large
corporation, where you can

tell like Akamai, we really,
really need a solution here.

And they will help you.

If you're not a large
corporation,

you can't do that.

It's very hard to say that if
say I want a 57 by 57 pixel

image, you must serve
it to me.

So one thing you can do is get
designers to calm down a

little bit.

And just tell them, don't try
loading images in subtly

different pixel sizes.

Do you really need a 50
and a 52 pixel image?

Maybe you don't.

Then just have a single 50 pixel
image and you're done.

Designers like to have a free
hand in everything.

But reality has to come into
play at some point.


So one of the final things
is decoding JPEGs.

A lot of people don't
think about this.

A lot of people, they look at
the timeline on Chrome.

And you see a lot of paints
and that kind of thing.

But decoding JPEGs can be a very
large hit, almost as much

as painting sometimes.

One thing we're playing
with is doing

it in a worker thread.

Doing XHR to the server, get
down the data for a JPEG.

Decode it in JavaScript on a
worker thread, ship the data

UI off to the image
on the UI thread.

And then you're only paying
for the paint.

In some cases, that works.

In some cases, it doesn't.

We've only rolled out a test.

But for large images,
it seems to work.

For small images, it doesn't.

It's horrible.

And I wish we could have off
thread JPEG decoding.

But such as it is, it still
slows down our scrolling.

Alex looks thoughtful.


Obviously, there are other
good solutions to this.

But hopefully, the guys will
know some of them.

And the last one that we're
probably going to end up

mentioning is GC, which
everybody knows stands for

Gremlin Carnage.

OK, it really stands for
garbage collection.

But it might as well stand
for Gremlin Carnage.

Because it's just this random
little monster that runs

around, and makes
you very sad.

Unless when he looks really
cute like that, and then

everything's good.

So with garbage collection, you
put all this effort into

having a fantastically good,
smooth animation.

And then something random comes
in and takes up 100

milliseconds and kills
everything.

V8 has, in the last
year or so--

year, 18 months-- come up with
incremental GC, which spreads

the load a bit.

But you still get hit by these
large mark sweep things that

can still take a large
amount of time.

One thing you can do is just
go through your whole code,

and micro-optimize absolutely
every tiny little piece to not

use memory, to reuse events, to
reuse all sorts of things.

It's painstaking.

It takes forever.

And I don't know of
a silver bullet.

But we will be discussing this,
and hopefully somebody

has a silver bullet,
because I want one.

All right.

And with that, let's get
on with the questions.

MATT DELANEY: Thanks, Shane.


So I'm not sure exactly where,
but somewhere out there

there's another mic.

So just keep in mind for this
panel, we have a roving mic

that will magically appear
as you need it.

So we're hoping for even more
people talking in this talk

from the audience, because
everyone deals with

performance.

OK.

So the first question here.


So from our very own Andrew
Betts, we have the first

question which is, with longer
and longer lived pages, will

web developers start having
to spend time on memory

management?

And is that a good thing?

And I'd like to start off Rowan
with this question.

ROWAN BEENJE: Well, I
think Shane, you've

covered some of it there.

I think Shane did cover
some of it there.

We are going to have to worry
a lot more about memory,

especially on memory constraint

stuff like mobile devices.

And the tooling has
got better.

Garbage collection
has got better.

I don't know how much--

AUDIENCE: You had the
mic [INAUDIBLE].

ROWAN BEENJE: I don't know how
much everyone knows about--


I don't know how much everyone
knows about the current memory

implementations.

But it's no longer retain
release stuff.

It's all very nice.

Is anything still attached
to the documents?

So no longer cycles
to worry about.

But you do still have to keep
very careful track of objects,

and make sure you don't have
to attach DOM trees.

Massive memory loss there.

And Chrome tools have got
a lot better in this.

You can do heap snapshots.

You can dip your
heap snapshots.

You can work out where you're
leaking objects in your

application life cycle.

But we are going to have to
worry about a lot more.

As Shane said, reuse isn't
silver bullet.

But it's what we have to work
with for the time being.


MATT DELANEY: Anyone else?

PAVEL FELDMAN: It's a bad thing
that we need to care

about memory.

But it's inevitable.

We'll need to take
care of memory.

And we need to make it a
standard part of our

development practice.

And not only we should care
about the present state, but

about the regressions as well.

Because you don't want to fix
everything, and then lose it

all with some regression bug.

And on the tools front, we are
working on exposing better and

better pictures.

We're currently working on
native memory instrumentation,

so that you saw how much DOM and
strings and resources and

images and decoded images
are taking.

But what we can see is
that apps [? model ?]

is most likely a source of the
memory leak and involved with

memory growth.

So you should be using heap
profiler for that.

And yes, it's complex.

And yes, heap profiling and
memory leak hunting is kind of

a last resort.

You don't want to do that.

But you end up doing it.

And you end up doing it not
only for web, but in any

development platform.

So just make it a standard
practice.


SHANE O'SULLIVAN: One thing that
we've run into is that

often, you know when your app
is not doing anything.

And you know that, for example,
right after someone

finishes scrolling, they're
going to stop and read

something for at least 100
milliseconds before they start

doing interactions again.

And one of the things that would
be fantastic is if you

could just say, I know my app
state Now clean it up.

But don't do it in two
seconds time when

they're scrolling again.

Clean up now.

And I know this has been
brought up before, too.

Everybody who ever built a
garbage collector, and they

always say, it's always best
guess, or maybe that isn't the

best time to do it, and all
that kind of stuff.

But being someone who doesn't
actually know how the

internals work, why is that?

PAVEL FELDMAN: I'm not
commenting on the GC,

controlling GC questions.

It's a tough area.

And you should be really
talking to the

virtual machine engineers.

And they have the
official story.

Paul, what is our
official story?

PAUL: I have no idea.

PAVEL FELDMAN: So the answer
that you get from the

[? vendors ?] is always, we are
going to do best for you.

You don't want to control it.

Or otherwise, you will
lead us into trouble.

But you really need to go into
the details, and talk to the

actual engineers.

SHANE O'SULLIVAN: Do we have
any of them in the room?


MATT DELANEY: This relates
directly to the

next question, it's--

SHANE O'SULLIVAN: Or a dozen of
next questions like that.

MATT DELANEY: What's that?

SHANE O'SULLIVAN: Or a dozen
of next questions on this.

MATT DELANEY: Right.

So this is kind of an
interesting thing from a

standpoint of perhaps getting
the answer from them.

But the next person asks, which
is Shapir from Israel,

is, should JavaScript be allowed
to explicitly trigger

garbage collection when you
the app is idling, say?

Or if the app knows when
it's OK to do so?

Or should it be allowed to
prevent GC when actually

performing time critical
operations?

So this is currently something
that people don't really have

control over.

But, hear your take on it.


ROWAN BEENJE: I think the only
other thing to bear in mind is

that there are occasions when
the browser is going to have

to garbage collect if it's
running out of memory.

So there's always going
to be points where you

can't control it.

But perhaps we could hint,
I'd like the next 16

milliseconds, perhaps.

Please don't garbage collect
during that time.

AUDIENCE: So do you see
observability as a

major issue at TC39?

So one of the things that I
wind up doing is one of

Google's representatives to
the standards body for

JavaScript.

And so being able to know
exactly when garbage

collection happens has
potentially very serious side

effects for cross-document and
cross-origin communication,

which are not friendly.

There's also the concern that
exposing GC will bake into the

web heuristics which are likely
to be proven wrong

anytime now.

So in the history of V8, we've
gone from having a

generational GC to having
many, many, many other

variance of generational GC.

And if you bake in invariants
in your code based on V8,

they'll be wrong under Nitro.

And they'll be wrong under
IonMonkey, or whatever the

next thing is out of
the next vendor.

And so the optimizations you'll
employ are likely to

get you into a place where not
only will you be wrong in the

future version of the VM that
you're currently attempting to

tickle in the right way, you'll
certainly be wrong on

the other VMs, too.

So it's a nasty place to
end your code base up.


CHRIS LORD: I don't have
anything to add to that.

MATT DELANEY: Have you guys run
into any situations where

you felt like it would be a much
better thing to be able

have control over these?

Because in a lot of native
platforms, you have, of

course, different controls over
the VMs, like say in JVM

and whatnot.

Are there any other times in
your experience where you've

dealt with wanting something
like this?


SHANE O'SULLIVAN: Yeah.

It's more from an extremely
high level, rather than be

able to observe specific things,
or even know when it's

going to run.

More from a point of view of
telling it, like you said, I'm

starting to do something
really complicated now.

Just calm down.

And if my memory grows by
another 20 megabytes while

you're waiting to GC, please
wait until I'm finished.

And then feel free to hit
me with a big thing.

I know, it may not
be possible.

But--

AUDIENCE: It can't
be that simple.

Because we're trying to balance
the interests of the

user, who may have triggered
your page to allocate those 20

megabytes, versus, should
they go to swap now?

What else should they be doing
here in order to--

what's the most valuable thing
to do with those 20 megabytes?

And the answer may
not be your app.

You may think it is.

But you may not have a global
view on what the user agent is

doing for the user.

CHRIS LORD: And I think to some
extent here, we're kind

of trying to have our
cake and eat it.

You kind of do have some
control over GC to some

extent, in that you can just not
write things in a way that

will end up with objects
to collect.

It sounds kind of silly.

But that's how like in Java on
Firefox mobile for Android, we

have these problems in a lot
of our codes, like while

you're panning and so
on is Java code.

And if we create a load of
objects during those frames,

then at some point, GC will
comes along at a completely

random time and take more
than a frame's worth of

time to do its work.

And the way we work around
that is just

by not doing that.

We can't change the
garbage collector.

And we probably wouldn't
want to anyway, really.

Because then other things are
going to break, and other

assumptions we've made
are going to break.

You can just write your code
in such a way that it won't

cause a lot of GC.


SHANE O'SULLIVAN:
No, that's true.

Yeah, that's true.

And you should be doing
that anyway.

But it does just get to the
point at some point.

I mean, if you're trying to do
things like I was saying

there, or keep your DOM small,
and have some sort of complex

controller that does all these
things and recycles views and

all that kind of stuff.


You're doing all this to get
around the problem of large

DOM and to avoid repaint, and
get as much reuse as you can.

That inevitably leads to
large memory usage.

If you have static content, like
buttons and icons, and

you're swiping through those.

Absolutely.

But if you simply have megabytes
of data that, as a

person scrolls through, you've
got to show them a piece at a

time, it gets fairly difficult
to start avoiding things.

Even when you cut it down
as much as possible.

CHRIS LORD: I guess you kind
of want to balance the two.


MATT DELANEY: I'm moving on.

So we've got a third question
here, from Jonno

from London, or Yonno?

Is that a person in here?

Yonno?

Anyway.

So we've got a very talked about
topic here, but with

respect to tooling this time.

So when you're using CSS to
manually trigger hardware

acceleration of DOM elements for
animations, for example,

the hack of using translateZ(0),
is there a tool

or any way to measure how this
impacts the users and GPU?

They ask.

Let's start with Feldman.

PAVEL FELDMAN: Yeah.

So you measure it
using timeline.

And I won't comment on whether
it's a good practice or not to

force the hardware

acceleration using that technique.

And Paul can cover that one.

But once you've done that, you
can, in Chrome, and it covers

good part of WebKit, you can use
timeline to measure both

paints times, and just
compare those.

That will obviously depend
on whether you are using

[? retna ?]

or not, size of the screen,
[? whatever, ?]

accelerator.

But you can do that.

You'll need to have an
inventory for that.

Because equipment differs.

And do you want to comment
on the translating?


[? PAUL: ?]

Just one thing about the
translate zed for me is that

the way, certainly in Chrome,
it's handled is that it

creates you a new layer,
but also a layer

with a backing surface.

So that effectively really maps
down to a texture that

needs to be uploaded
to the GPU.

So the net result of this is
that if you've got a translate

zed or across a lot of
elements, on desktop

you might be fine.

Because you've got a lot
more VRAM to play with.

But on mobile, you're going
to get punished.

Because now you've got a lot of
textures that needs to be

uploaded to your GPU.

And the upload time might be
quite slow to get those

textures from the CPU up to
the GPU, depending on the

actual hardware you're
running on.

So it's one of these things
that it's sort

of used with caution.

And it may be that in your
specific implementation it

speeds things up, because you've
got enough VRAM to kind

of cover that debt that you're
kind of creating for yourself.

And it also is good because,
again, in Chrome, if it's

possible, switch the rendering
mode over to thread

compositing, which is often a
good thing, especially if

you've got a lot
of animations.

But you might just see, as
again, a mobile, you might see

it crush your performance
if you do it too much.

CHRIS LORD: Yeah, this is the
same case in Firefox, as well,

where if you add any kind of
transformation, then it will

end up not optimizing it, but
sort of making it appear on

its own layer.

There are other things to
consider, as well, when you're

forcing layers and elements
and that.

If you force something to become
a new layer, you're

also forcing layers to be
underneath it and over it,

depending on the structure
of the document.

And again, depending on the
structure of the document,

you'd also be forcing things
like alpha blending to happen.

You're forcing things like
increased overdraw to happen,

all of these.

And you'd have memory
hit, you'd have

GPU time hit as well.

And at some point, like
translateZ(0) might end up

just being a null op anyway.

ROWAN BEENJE: It is
already on WebKit.

It's been kind of deprecated
[INAUDIBLE].

PAUL: Yeah, they may be like--

there are other ways to trigger
the same behavior so

that the warning [? shot ?]

is, this one might
become null.

But developers might gravitate
towards an alternative way of

triggering the same effect.

It is exactly what
you're saying.

It depends on the context of
when you're using it as to

whether it's actually a suitable
thing to do, really.

MATT DELANEY: So there's really
a lot of knowledge

here, and a lot of gotchas,
depending upon the platform

and what they fall down into
doing, what actual rendering

paths, right?

But I guess for this question,
it'd be really interesting to

point out maybe, especially
with people in the more

constrained environments on
mobile, what do you guys see

out there for tooling to measure
the impact of their

apps usage of this hack upon
what they're doing?

CHRIS LORD: This is quite
a difficult thing.

Because GPU behavior is wildly
different, depending on what

vendor you have.

So Firefox does have a profiling
tool built in, which

will profile at the native level
where time is spent.

And it goes into JavaScript,
as well.

So if you run your page or
your web GL app, and you

scroll around with the profiler
enabled and you stop,

you can see where time
is being spent.

But in terms of getting really
granular results,

that's quite hard.

Like GL drivers quite often,
they'll defer work to the

latest point possible.

So you might find that although
you're doing a load

of vertex upload or something,
you're uploading a load of

data to the GPU, or you're
uploading a load of things,

you might find that actually all
of that takes zero time.

And swap takes all
of your time.

Or clear takes all of your time,
or flush, or some other

command where the GPU's like,
right, OK, we can't defer

things any longer.

We have to flush out
all the work.

And we can't really counteract
that without doing, I guess,

other clever things like having
a shim for the GL

functions and the JavaScript,
so that we can log what

commands you are using, and use
some kind of context to

say, well, maybe you shouldn't
be doing all of this.

Maybe you shouldn't be uploading
all of this data

here, or maybe you should think
of using more VPOs and

batching your drawing, rather
than doing lots of separate

drawing and things like this.

But I think it's going to be
quite difficult, nigh on

impossible, to have a really
granular general profiler when

it comes to GPU use.

But yeah, Firefox has
a built in profiler.

If it's not in the current
release, it's probably in 19

or 20, I forget.

And also for the record,
we have incremental GC

also in 19 or 20.

PAVEL FELDMAN: So before
it gets to Firefox,

we have it in Chrome.

And the way you look at it-- so
there is no GPU profiling.

But there are interesting cases
on the timeline where

you see your CPU time spent
for just JavaScript

[? layer ?] painting.

And it all adds up to some
reasonable amount.

And then there is this
transparent bar.

And you don't know why your
frame has been skipped.

And the reason for that is the
browser was waiting for GPU.

We don't really see that
happening a lot in practice,

on non-heavy 3D apps
whatsoever.

So in most cases, first thing
you check is timeline.

And you're most likely OK.

And the detailed GPU profiling
is still ahead

for Chrome, as well.

CHRIS LORD: Yeah.

It's much better on desktop
than it is on mobile.

And most of my experience is
mobile, so I'm probably going

to be speaking from
that perspective.

You worry less.

I guess everything is
better on desktop.

The state of mobile GPUs, at
least certainly on Android,

although it's getting better,
is like Android-based system

tends to use GPUs more.

Like, drivers have some pretty
awful and incorrect behavior,

and just flat out bugs that will
cause things like this.

You'll have hitches that will
be very hard to trace.

And it will come down to
something like, you've

triggered something
which might do--

like it might update
part of a texture.

And that GPU driver subimage
uploads are

actually just terrible.

And you should never do them.

We try and work around these
things, but I don't know.

It's on mobile it's hard.

But on desktop, it's less
of a concern, I guess.

MATT DELANEY: Also we
have a question from

the audience here.

What's your name?

AUDIENCE: Hi, I'm
DJ Fazzyfist.

No, I'm kidding.

[INAUDIBLE]

from Google.

It's also worth noting that for
those of you daring souls

in here who compile Chromium,
that there is access to the

Skia debugger, which is actually
sort of the hardware

GPU compositor.

It's actually amazing
the insight you can

get from Skia debugger.

You can actually see the GPU
performance for each CSS

element on your page.

You can actually see what your
DOM is doing, and what each

button and how long that's
taking on the GPU.

It's amazing insight if you're
seeing problems in this area,

and definitely worth checking
out if you're willing to

compile Chromium.

AUDIENCE: How do you spell it?

AUDIENCE: Skia?

S-K-I-A. Skia debugger,
check it out.

Hi.

MATT DELANEY: Sounds
pretty good.

PAVEL FELDMAN: Does it already
provide traceability from DOM

and CSS literally?

Because it was bound
to instructions.

And you couldn't really trace
it into particular

[? selector ?]

and/or CSS property.

I don't believe you can now.

AUDIENCE: [INAUDIBLE].

PETE: Mic?

AUDIENCE: Thanks, Pete.

The latest one that I was
playing with had some

abilities there.

Obviously, the tooling needs to
get better across the board

for getting GPU insight for
these sorts of things.

Since kind of the future of web
compositing performance is

on the GPU anyway.

So for those of you who want
to kind of try out and give

feedback for this early stuff,
definitely check out Skia

debugger and kind of get a
chance to chart where these

tools are going in the future.

PAVEL FELDMAN: So the way it
works pretty much, if I

remember it correctly,
is it logs

everything that is happening.

And then it replays it.

And while replaying, you can
assess the performance of the

instructions that were made.

So basic idea.

CHRIS LORD: I think we do
actually, I remember now, on

the [INAUDIBLE]

last year, we have a similar
tool for recording GPU

behavior and then
playing it back.

But I can't tell you
anything about it.

I've just forgotten, and
it's not finished.

So I think that sounds
really cool.

You're definitely well
ahead there.

ROWAN BEENJE: And I think the
Chrome dev tools are just

starting to expose the
amounts of GP memory

used, is that correct?

That's coming up?

PAVEL FELDMAN: Not yet.

ROWAN BEENJE: But it's coming?

PAVEL FELDMAN: It's
coming, yes.

ROWAN BEENJE: Very soon.

PAVEL FELDMAN: So native memory
instrumentation started

with the renderer.

And the GPU for us is outside
of the renderer.

CHRIS LORD: I'm not sure if--

like, we have, if you go to
About Memory in Firefox,

you'll see lots of details
about where your memory's

being used.

I'm not sure if that goes
to GPU memory, though.

That also works--

I think it works, it should
work-- on mobile.


MATT DELANEY: Great.

So that's quite a bit
about the tooling.

So how about we move over to
the next question, which is

related and kind of touched on a
bit in the beginning of this

one, was, how do you guys feel
about frame developers and

their understanding of which
performance metrics they

should actually be looking
at these days?

Say both, of course on a
desktop, but more importantly

mobile, the more constrained
environment.

Should they be looking,
rendering,

compositing, layout?

How should they be used
in the tools?


CHRIS LORD: I guess there
aren't too many.

We've not done as good a job
as we should have, in that

there aren't tools to measure
certain things that you'd

really want to know.

Or at least, the tools are
things like, oh, just use an

HDMI video capture unit and do
frame analysis, which is

obviously not feasible for
most people, I would say.


PAVEL FELDMAN: Can we turn that
to the audience, and may

I ask, how many of you have
experienced issues,

challenges, profiling, fighting
for rendering

performance?

If you could raise your hand.

Rendering performance?

OK.

And how many of you were
using timeline to

capture what's happening?

OK, so it's pretty much
half of [? us. ?]

So that's your answer.

So half of us realize what needs
to be done tooling wise.


AUDIENCE: [INAUDIBLE].


So how would it help me
in a web view iOS?

It's great that we have all
these tools in our browsers,

but a lot of performance
of HTML5 is

in the closed platforms.

So what can we do to get those
closed platforms to get the

cool tools that we're
building?

PAVEL FELDMAN: So those
platforms diverge, especially

on the rendering front.

It is truth.

On the CPU front, though, they
are very much alike.

So you have a good clue on
what's happening in iOS web

view when looking at Chrome,
unless you enable threaded

compositing or something
like that.

And it often gives
you a good clue.

And image decode time will
be proportional.

Because what you're assessing
is basically the CPU and the

architecture of what
you're running on.

So you have some clue.

You have some good
clue on that.

But it is not precise.

SHANE O'SULLIVAN: But also what
you should care about, I

don't think should be what any
one tool gives you, or any one

performance metric--

I mean, performance is
not a goal in itself.

Performance should be there to
get you to increase whatever

metric matters to you.

So for example, in Facebook,
the reason we care so much

about scrolling is that we did
a test where we artificially

introduced for some small
number of people, 20, 30

million or something, where
we said, we'll have your

scrolling framework on Android
and iOS, just artificially.

We know you can do 60
FPS on an iPhone 5.

We will give you 30 FPS.

And engagement collapsed.

You would still get--

we didn't introduce jerking,
we just slowed

down the frame rate.

And engagement dropped.

So we said, OK, therefore,
scrolling matters to

engagement.

And engagement is
what matters.

So if what you care about--

test all the different
things for your app

that actually matter.

If speed, time to interaction
is what's important to you,

emphasize for that.

If scrolling is important to
you, and you do stuff like

newsfeed, or any kind of image
heavy thing, then optimize for

not resizing images.

Optimize for not doing paint
reflows on complex content.

If you really care about
TTI, do server render.

It's faster.

So try out 10 different
things.

I know it's time consuming.

But the metric you should
be looking at is

what matters to you.

Do you care that people look
at 50 photos in an hour?

You're a photo app, fine,
optimize for that.

So yeah, I don't think there's
any one sole [? rebuttal ?]

for this stuff.

PAVEL FELDMAN: So the same
happened to Chrome.

We consider scrolling
very important.

And there is actually a tooling
to detect regressions

on that front.

So there is a telemetry, the
remote control for Chrome.

And the rendering team
is using it in

the following matter.

This tool can connect to remote
devices such as Android

phones and Chrome OS and
desktops, different builds,

different versions of builds.

So it connects to those, runs
regression testing, uses

timeline to get raw data back,
and builds the graphs.

And any degrade in that graph
is a show stopper, and we

change that.

[? Regressions ?]

gets rolled out [? of them. ?]

So the same thing that happens
on the vendor front should be

happening on that app front.

And I'm sure it does.

So the metric is scrolling
matches here.

CHRIS LORD: I think, on a slight
tangent, there are some

practical things that are worth

knowing before you even--

MATT DELANEY: 30 seconds.

CHRIS LORD: While you're
making a site.

You should take these things
into consideration.

So it's worth knowing to some
extent what things cause new

stacking context to be
created, for example.

Because if you create a new
stacking context, likelihood

is you're going to create
a new layer, as well.

Not necessarily, but it's a
reasonable kind of rule of

thumb to go by.

Try and reduce the amount
of stacking context.

Try to reduce the amount of, for
example, if you have text,

not having it on a solid
background means that you're

going to force alpha blending,
and you're going to force that

text to be rendered twice.

First optics or anti-aliasing,
maybe not on mobile.

We'd probably just
use grayscale.

But there are lots of little
things like this.

Like if you're going to have
gradients in your backgrounds,

CSS gradients, don't change
them all the time.

Don't resize them if
you can help it.

Try and avoid fixed
backgrounds.

Because again, you're going to
force the foreground layers to

have an alpha channel and force
blending and so on.

Just sort of small tips that--

MATT DELANEY: Lots of good
strategic advice there.

Move on to the next
one here, sorry.

So we've got a pretty
interesting question, I think,

from James Ford.

Kind of an age old question,
perhaps, but does using SVGs

and font icons for graphics over
GIFs and PINGs have an

impact on the performance
of a web page?

How about more from your actual

experience of using such?

CHRIS LORD: I was going to say
recently, we switched SVG to

rather than going from like a
single node in our display

list to using all of our
display list nodes.

So if you have an SVG that's
got like 1,000 different

render nodes in it, then that
will be represented in our

display list.

And we have open bugs.

This did cause performance
issues.

Because as you scroll through
the page and you expose new

areas of SVG, we have to iterate
that whole list, and

render it and sort it into
layers, decide which bits have

changed and which haven't
and so on.

So yeah, SVGs are
going to be--

you can cache them.

But assuming that you're
using them for a reason

and you're not just--

I mean, if you weren't going
to plan on showing them at

different sizes or a site.


Assuming that you are using
SVG for a reason and you

couldn't have just used a static
image kind of thing,

they are more expensive to use
than just static images.

And the same with
fonts, as well.

Fonts are quite expensive
to render.

So the answer is
yeah, I guess.

They're more expensive.

AUDIENCE: So maybe one example
that I found recently,

actually the Apple site uses
SVGs quite well and badly.

Well in the sense that they
use them everywhere, for

example for the logo
and all the rest.

But I think what a lot of people
miss is a complex SVG

with a lot of paths is actually
very expensive, even

in network bytes.

If you look at the complexity of
the SVGs that they use, you

can get like a 5x improvement if
you just save it as a PNG.

So it's retina friendly, which
is what Apple wants.

But it's actually worse off for
like render time of your

page and network performance.

CHRIS LORD: Yeah.

ROWAN BEENJE: Does anyone have
any comparative information

about icon fonts versus SVG?

PAVEL FELDMAN: We
need to measure.

And if we can't measure
it, we need to

make sure we can measure.

MATT DELANEY: [INAUDIBLE]

in the back?


Never mind.


No experience from
Facebook on this?


SHANE O'SULLIVAN: No experience
by me at Facebook

at the very least, no.

MATT DELANEY: All right, so
let's move on to the next

question then.

A little bit of time
here left.

How much on the clock?

15?

So kind of a bit of a loaded
question, but how can I find

which CSS rules and properties
are expensive to render on a

particular page?

Is a next question, a little
bit of clarification.

PAVEL FELDMAN: We are
working on that.

But it's a hard one.

You need to trace it all the way
from the CSS property to

the GL instruction or paint
instruction, Skia instruction.

And it's a long way to go.

There is a permanent solution,
though, that we've introduced

recently as an experiment.

We can now put browser into the
continuous repaint mode,

where it continuously repaints,
even if it doesn't

need to, and it shows you the
frame rate it can do it at.

And if you're not touching a
page, you can see that OK,

where it says number
of milliseconds,

it's paints per frame.

So it says, 3 milliseconds
per frame.

That's a good frame.

You'll achieve 60
FPS with that.

If it shows you 60, or 100
milliseconds, then you can go

and bisect your DOM.

So that's the best we can
offer at the moment.

You go through DOM,
you hide things.

It toggles visibility
to [INAUDIBLE].

And the number of milliseconds
reduce.

And then you figure out what
is the part that was

statically positioned, or had
a complex background, or had

some gradient whatsoever.

It's a manual process.

But it is already way
better than nothing.

SHANE O'SULLIVAN: Will this help
in the case where you're

showing and hiding things, but
let's say I modify something

that will trigger both a
repaint and a reflow.

Does this capture it
in that second?

PAVEL FELDMAN: So this one
is only about paint.

And paint meaning layout
does not change.

DOM does not change.

So it's only about CSS
and DOM that you have

presented on the screen.

For the rest of the
information,

you go to the timeline.

There are similar techniques
on figuring out the recalc

style or layout performance.

They often end up
with bisecting,

unfortunately, as well.

And we're working on
improving that.


SHANE O'SULLIVAN: Anything cool
coming up in Firefox?

CHRIS LORD: Not much
to add, really.

On mobile, I guess, it's worth
considering that certain pages

and complex pages, and on
certain mobile devices, it's

really not feasible to expect
the page to render very

quickly, as in within a
reasonable 60 hertz or 30

hertz time frame.

But we have asynchronous
compositing to counter that.

And what your goal then really
is to kind of do your work at

clever times, and partition it
in clever ways so that you

don't interrupt the asynchronous
compositing at

inopportune times,
or for too long.


MATT DELANEY: We're on to
the next question here.

So this is perhaps a little
bit redundant, but it's

interesting to get the
perspective real quick from

both the Chrome and
Firefox person.

So we use translateZ(0) to
trigger hardware rendering, as

people think.

Should we have an API to
explicitly do this?

So this is obviously
a bit tough.

And I think we can get some
audience input to this.

But should there be, perhaps in
general, any feedback from

the app side to get a little
bit of hopeful kick into

acceleration?

Because if people are using
this, and they're finding it

to good effect, is it something
that maybe we want

to make more real?

PAVEL FELDMAN: So I think Paul
and Alex have already covered

this one from the platform
perspective.

When you were talking to GC,
many things applied to this

thing as well.


CHRIS LORD: Yeah.

This has come up a few times,
really, like do we want apps

to be able to hint to
GC when to collect?

And do we want--

it's like every bit of control
that you add is kind of--

MATT DELANEY: From your work
on Android, have you found

times where it would've been
more useful for the app

developer to give you a hint
that they need that?

CHRIS LORD: Not really,
I guess.

I think really, we should
just be cleverer

about doing these things.

I think if you put that kind of
control into users' hands,

things are going to change too
much pretty quickly, to the

point where it would
just force bad

behavior in future versions.


SHANE O'SULLIVAN: From the point
of view of people who

write apps, yes, it
would be lovely.

I don't know if it's
feasible or not.

It's just that on the web, as
everybody knows, one of the

reasons we're sitting here right
now is that performance

is a problem.

And on some of the platforms,
you do have the option of

dropping down to a lower level
if you need to, and if you

have people who are
sufficiently good

enough to do so.

And I don't know if that's
feasible on the web.

It would be nice if it was.

I admit, things change
all the time.

We're constantly updating our
browsers, or even updating

them in the background now.

So things do change
all the time.

And even on iOS, things
change once a year.

So yes, it would probably
break everything.

But when you try to do smart
things in general, often

you're going to be missing
an edge case.

And an edge case could be 25%
of all implementations.

So I don't know.

If there was a way to drop down
lower and just say look,

I know what I'm doing, trust
me, it would be great.

Like I said, you can do it
on native platforms.

CHRIS LORD: I guess you've
got Canvas and WebGL.

You can do it like that.

SHANE O'SULLIVAN: True.


MATT DELANEY: Is there
maybe time for one

more question here?

So the question from Christina
Auckland, from Hampshire, is

there an overhead to using
media queries, especially

bubbling media queries in
your experience, guys?


PAVEL FELDMAN: I don't know.

CHRIS LORD: No idea.

SHANE O'SULLIVAN: Not a clue.

MATT DELANEY: Then one
more question.


Oh man.

Nope.


We talked about this question
for about five hours last

night, off and on, like
beating a dead horse.

Would it be possible to
accelerate reflows, hardware

accelerate?

So I think this question's a
bit confused into what it's

asking, perhaps.

But it did bring up some
interesting things last night.

So give you a moment to just
talk about what reflows are,

perhaps from you guys, and how
that may possibly be hardware

accelerated.

PAVEL FELDMAN: I think Google
is definitely hiring.

So if someone has some bright
ideas on that, they'd be

definitely interested.

CHRIS LORD: Ditto.

I guess, yeah, I think
the question

might be slightly confused.

So to kind of go to semi-fast
principles, I'm going to

assume that DOM tree is
something that we all know.

But browsers tend to, after you
get a DOM tree, it will

get passed into a frame tree,
which is a better

representation of how
it will get drawn.

And then the frame tree will get
processed, where it will

calculate where the position
and size of things are.

And that bit is the reflow.

So when you change something
that causes a size to change,

then reflow needs to happen.

Because the size of certain
elements will be dependent on

the other elements.

I say elements, that's
not quite true.

Because we're in the
frame tree now, but

for the most part.

So that's not something
you could put on--

I mean, you could put it
on the GPU, I guess.

But it'd be pretty pointless.

All of that is in
system memory.

So you'd be shoving that over
to GP memory, and writing a

really complex set of shaders,
I guess, to work on it.

And then shovel it back.

Basically, the answer is no.

But maybe there are some other
things that we're not

accelerating right now that we
could, which might be an

interesting question.

So from the frame tree, Firefox,
or Gecko rather, will

make a display list which
represents how it

would draw the page.

And then it processes the
display list to create the

layer tree.

And I think a similar process
happens in WebKit, possibly

minus display list or depending
on what fork you're

using, judging from the
conversation last night.

Are there other things that
we could accelerate, maybe

between those things or like
during that thing?

So for Firefox, most of
the rendering will

happen on your CPU.

Certain things will be hardware
accelerated, like

drawing a big image.

That might end up being uploaded
to the GPU and

scaled, for example,
in the GPU.

Or transforms happen on GPU.

Blending happens on the GPU.

But maybe there are other
things that could

happen on the GPU.

Like we don't draw gradients
on the GPU at the moment.

And gradients are a huge hit.

That's something we
could do, maybe.

And other elements as well.

There might be other element
types that would be able to

take advantage of hardware
accelerated rendering.

PAVEL FELDMAN: Another hint is
that if you're experiencing

really slowly, most likely you
are doing a total reflow.

And in WebKit, you are doing
total reflow if your layout

root is root of the document.

Which means in this very
message, you mutated two ports

of non-intersecting DOMs.

And they ended up being
the root layout.

So you figure out what
your layout root is.

There are simple rules to follow
to make your element

layout root.

And make sure you
don't screw it.


CHRIS LORD: I think we've kind
of mentioned this already.

But just in case, a lot of the
optimizations that happen on

the kind of rendering process
are to do with delaying tasks

and splitting them up.

So things like, if you can make
everything like a set

width and height, and never move
it, that would be great.

But if you do have need to
change something, like if you

change the width of something,
that is going to trigger a

reflow probably at some point.

But that point could be any time
between the time you do

it and the time that
the frame comes.

And stuff might happen
in between.

And if possible, we'll coalesce
these reflows.

On the other hand, if you change
a width, and then you

immediately read back the
width of an element that

depended on that width, you're
forcing that reflow to happen

immediately.

And then if you change something
after that, then

you've got a double
reflow situation.

So I guess an attempt to maybe
batch stuff is a sort of

general tip to avoid that.

PAVEL FELDMAN: Yeah, so to add
to that, we've often seen five

total reflows happen
within a frame.

So it's not that the
reflow is slow.

It's that it's continuously
happening

within the same message.

And we have good
tools for that.

We will show you all the
layouts, and we will show you

[INAUDIBLE] stacks that
invalidated re-layout, and

that forced it.

And you can see a continuous
invocation of

like five of them.

And you cut it into a single
one, and all of a sudden your

performance is OK again.

MATT DELANEY: So actually, real
final question here from

the audience is from Paul
Kinlan, he says, yes, does

scrolling performance in
client-side performance affect

the time on the site, balance
rate, et cetera?

And Shane was actually talking
about something pretty

interesting last night about
what he's seen from Facebook's

perspective.

SHANE O'SULLIVAN: Yeah, I kind
of mentioned it a bit earlier.

But yeah, it absolutely does.

What we find on Facebook is that
regardless of what you

do, people have kind of assigned
a certain amount of

time every day to spend
on the site.

And the more things that you can
get them to do within say,

they only spend 20
minutes a day.

And if you can show them twice
as many pages during that day,

then it will do twice
as many things.

The same goes for if people tend
to scroll down, we found

that when they scroll more,
they see more stories.

They click like more, they
comment on more things.

They see people's faces,
and the site

sends them more messages.

And when we did add friction
to scrolling, when we added

varying scroll rates, or when
we added consistently slow

scroll rates, as soon as we made
anything non-optimal when

it comes to scrolling, then
people often might stay on the

site as long.

So it didn't really affect
bounce rates.

But they would do far fewer
things, which is why we spend

so much time obsessing
about scroll rates.

So scroll rates directly affect
user engagement on

native, on wave,
on everything.

Which means our basic site,
which only serves HTML and

goes on to Nokia phones, gets
fantastic engagement if you

put it on an iPhone.

It's extremely fast.

It's tiny.

It looks ugly.

And people engage with it
really, really quickly.

And you know what?

It scrolls at 60 frames
per second.

Because there's no JavaScript.


Yeah, who knew?

MATT DELANEY: Any
last thoughts?


CHRIS LORD: Not really.

Maybe it'd be nice, like
we're talking a lot

about scrolling here.

It's obviously very important.

And scroll behavior differs
between basically every mobile

browser in quite big ways.

Maybe this is something we
should be, or should have been

collaborating on before.

Maybe there should be an API
for that, like some kind of

meta tag or something.

SHANE O'SULLIVAN: I heard Chrome
team were going to

start looking at scroll
performance as something to

instrument, or something
like that.

PAVEL FELDMAN: Yeah, so that
telemeter that I was talking

about is the regression testing
for the scrolling

performance.

And there is a huge scrolling
effort that, among other

things, moved the painting to
the impulse side, including

the image decode and resize.

And that's already available
on Chrome for Android now.

Yeah, it's already enabled
for Chrome for Android.

It's in the About Flags
on the desktop Chrome.

So you can take a
look at that.

CHRIS LORD: Sorry, and
one last thing I just

remembered as well.

In the Firefox built in profile,
we have a mode that

we call junk mode, the
like ticker box.

And then when you start the
profiler and you do some

stuff, and you stop it, it
will basically show you--

it will highlight on
the profile exactly

any hitches in panning.

So any frame that took longer
than 16 milliseconds or

whatever to draw.

You can drill down into just the
operations that were going

on during that frame.

And I think, no yeah,
I'm sure, that

profiler works over ADB.

So you can run it on your phone
and profile it on the

desktop, which is
pretty handy.

So just letting you know.


MATT DELANEY: So thanks.

That was Performance Channel.



PETE LEPAGE: I'm going to do a
quick intro of our panelists,

and then I will hand it over.

Sitting right here
we have Mairead--


MAIREAD BUCHAN: Buchan.

PETE LEPAGE: Buchan.

So I've messed her name up
probably five times already,

and I've known her for
about four minutes.

So I apologize.

Boris Smus from Google.

We've got Francois Daoust, and
then Matt Caruana, who is

going to come and do
our first intro.


MATT CARUANA GALIZIA: So I'm
going to start by talking

about something really simple.

It's just text input, which is
probably one of the most

fundamental kinds of
input on the web.

I just think that there are a
lot of lessons to be learned

here because obviously, we've
been using this kind of input

for a long time, longer than
we've had touch or

anything like that.

So we've gone quite far toward
standardizing it.

And in the beginning, there
were really only low-level

events like keydown, keypress,
keyup, that are very tied to

the hardware.

In a way, because of that,
they're really good.

They allow us to attach special
functionality to key

combinations in web apps that
should support where users

need to be able to do
things quickly.

The problem is that they're not
really suited to form- and

text-based inputs.

They're too hardware specific.

For a start, they have a lot of
problems, for example, with

non-Latin keyboards.

Like the Chinese keyboard,
pressing the character key for

man, for example, results in
a keydown event with one

character, which is an accented
a and the keyup event

with the actual character
itself.

So it's difficult to
tell what the user

actually wanted to input.

Key events aren't just really
difficult to use.

There are many kinds of text
input that they just aren't

designed to handle.

And really, it's a mistake
to assume that text input

involves a keyboard.

Speech dictation and drag
and drop can also be

used to input text.

The keyboard on Android has a
microphone button on the side,

for example, which you can just
press to dictate text

into an input fields.


Thankfully, no one has attempted
to write a speech

dictation to keypress
event polyfill.

Instead, there's another event
that we can use, which is the

input events.

It's been recently standardized
in HTML5, and

it's now supported by
all major browsers.


So this makes it really easy to
detect input in a hardware

agnostic way.

Key events are just a bit too
low level for most kinds of

text input.

We don't really want to listen
for physical key presses.

Really, we just want
to grab input.

And the input event is a whole
different way of about

thinking about this.

We stop thinking in terms of
hardware and start thinking in

terms of intent.

We just don't really care about
the hardware at all.

That really, I think, makes much
more sense than listening

for key events.


So why didn't we take the
lessons from text input and

apply them to other forms
of input, like

pointing and touching?

So take the anchor
tag, for example.

It can be clicked,
touched, tabbed.


Do we really want to know
if the user clicked

it or touched it?

Most of the time we don't.

We just want to know if
the user wanted to

navigate to that link.

There are fundamental problems
with listening only for click

events on anchor tags.

What if the user tabbed
to the link and then

pressed the Enter key?

Or what if the user issued a
voice command intending to

navigate to that link?

Perhaps we can just have an
activate event that we can

just use to listen for
the intent itself.

This can apply to command
elements, buttons, as well as

anchor tags.

But at the same time,
pointer events are

still really useful.

They're ideal in 2D drawing
applications, and developers

will rely on them to define
custom gestures for their

applications.

So those gestures can come from
a trackpad, a touchscreen

device, a Kinect, or a
Leap Motion device

used in a 2D context.

To ask a common question, can
touch events coexist with

pointer events?

Yes.

Should they?

Perhaps not.

It's unlikely that a developer
would want to capture touch

events as a subset of
pointer events.

If you have access to pointer
events, it's probably best

just to use those.

Besides, the pointer-type
attributes of a pointer event

gives you access to the input
device type, whether it's a

mouse, pen, or touch.

The same point on coexistence
goes for click events.

Sorry, I've gone too far.


In fact, developers will
eventually get to abandon

click events completely, and
they'll be replaced by more

semantically correct and
hardware-agnostic events in

the cases that they're now most
frequently used, like

anchor tags and buttons.

Libraries, like pointer.js for
example, already make it

possible to move away from click
events and move towards

pointers, which are
more abstract.


The trouble is that almost
all forms of inputs we've

discussed so far involve
input in a 2D space.

Take Leap Motion's JavaScript
API for example.


You can receive input as
an array of hands.

And they can be anything from
zero to infinity, really,

because it depends--

if you have multiple Leap Motion
devices, you can just

have an infinite amount
of hands.

And each hand has coordinates
on x, y, and z.

And how do we turn these
into pointers?

Pointers don't really give us
a z-axis, but it shouldn't

really be that difficult to
add it to the standard.


Hands from Leap Motion can fit
into the pointer event spec.


But at the same time--

sorry.

Just a second.


So another big issue is
standardizing gestures.


There isn't really much going on
in this respect with specs.

The closest we've come, really,
toward standardizing

gestures is in the UI event
spec, which gives us a way to

separate the actual method of
input or the physical action

that the user made
from the intent.

So, for example, we can take a
physical push action and turn

it into an activate intent for
a link, which gives us a more

abstract way of dealing
with input.


Taking a swipe gesture, for
example, on a trackpad, in the

UI event spec gives us a way to
turn this into a pan event.

So it doesn't matter whether
the user provided the input

using the speech API, say, as
go left command, as a verbal

command, or by swiping their
hand on a touchscreen or by

just moving your hand in the air
to mimic a swipe action.

The spec gives us a way to
translate this into a pan

event, which we can then use
to move a page around.


Really in conclusion, we want
developers to produce more

adaptive web apps.

To do that, we need to
standardize input methods.

We need browsers to
support pointers.

And it would also help if
we standardize gestures.

But at the same time, a probably
more future-proof way

is by providing developers with
more abstract ways of

dealing with the actions that
the user intends, like

activate actions for links, say,
or panning actions for

moving a page around.

And that will just make our
life a whole lot easier.

Instead of requiring every
developer to listen for all

these different kinds of events,
for all different

kinds of input methods, we can
just listen for one event,

which is the intent,
and support that.

That's it.

Thanks.

[APPLAUSE]

PETE LEPAGE: All right.

So while I'm unlocking my
computer so I can have a look

at the questions,
I know the first

question that's on there.

And it's by far the most popular
question, is what are

the new input types that really,
as developers, we need

to start thinking about today?

And what are the implications
of using those?

So I'd like to hear from all of
you guys what you sort of

think is the biggest and most
important one and what

developers need to think.

So, Mairead, do you
want to go ahead?

MAIREAD BUCHAN: Well, in terms
of the biggest at the moment,

I think in terms of something
that's not just keyboard or

mouse, is touch.

That the majority of your users
are going to have that.

If you're talking about things
that you haven't really

thought of that are coming in,
maybe motion sensing, so maybe

Leap Motion because that's
coming next.

It should be released at the end
of this month allegedly.

But also like [INAUDIBLE] did
loads of work into how many

children are actually using
games consoles, so anything

that you can interact with a
games console with, and also

hybrid mobiles that are games
console devices and mobiles.

So they have joysticks and

touchscreens and maybe keyboards.

So you've got to think about
what application you're making

and what that your users
are likely to be using.

PETE LEPAGE: Cool.

Boris?

BORIS SMUS: Yeah, I would
basically agree with that.

Touch is, realistically
speaking, the only interesting

new mode, at least from the
perspective of what we need to

do as web developers.

But there's a whole slew of
emerging technology that--

I don't think Leap is
at all like the

extent of what's coming.

There's a whole number of--
pretty much every large

corporation has some finger in
this pie of camera-based or

something like this input
technologies, whether it's

tracking fingers,
hands, bodies,

faces, irises, et cetera.

So there's a whole number of
primitives in the real world

that are going to start
to be tracked.

And this is obviously a little
further out, but still

interesting.

FRANCOIS DAOUST: So just to
maybe add something more on

top of the huge list you
already mentioned.

Maybe at the intent level that
Pete mentioned, I would

perhaps add presence or user
attention as a possible way

for a more immersive
experience.

For instance, if you have a
screen that is displayed on a

wall, a mirror, or something,
something that is connected,

you might just want to know
whether the user is in front

of it or whether it's not.

And the thing that you're
going to display, the

interaction with the user, will
change based on that.

Again, it's at the intent level,
so you don't need to

know how the system knows
that the user is there.

They already have some
mechanisms to do that with the

RFID, with NFC, with, actually,
the user manually

entering his status on Skype
or whatever saying, I'm

available, I'm busy,
I'm not there.

So it has [? fallback, ?]

and that could be a new kind of
a user input coming in the

near future.

MATT CARUANA GALIZIA: I think
that one of the most

interesting developments in
input is speech, because it

forces us to think of input
in a whole new way.

We suddenly have to deal with a
method of input that doesn't

involve fingers, doesn't
involve hands, doesn't

touching, moving, or
anything like that.

So we just have to completely
change the way that we think

about input and write
applications

in different ways.

The first step is to probably
change standards or develop

new standards to allow
developers to more easily

support this new form of inputs

without relying on polyfills.


I tend to think that providing
polyfills is probably a good

way of getting started.

We can produce the polyfill, get
developers to start using

it, and then eventually the
standard will come later.

PETE LEPAGE: Actually, that's
a great sort of segue to the

next question that Andrew
had put in.

And his question was, if
we use a mechanism for

abstracting all directional
input into pointer events,

will we ultimately regret
that decision?

I believe there's a pointer
event polyfill library you can

start playing with today.

But are we regret that decision
in 6 months, 12

months, maybe in 60 months?

BORIS SMUS: I'll take
a stab at this.

So I think that there's some
kinds of directional input

that makes sense to try to
abstract as a pointer and

other things it totally
does not.

Things that are screen based is
an obvious fit, where you

have a natural mapping to
screen coordinates.

This includes mouse and touch.

But when you're talking about
things like Leap or any sort

of sensing in the real world, I
think you quickly fall into

this weird place where
it's unclear what the

client x is, really.

And at that point, you're
dealing with physical units if

you have some z-coordinates,
and you're just

polluting the space.

I feel like it's a
perilous path.

So I guess the short
answer, depends.

PETE LEPAGE: All right.

Anybody--

MAIREAD BUCHAN: Your only other
choice is coding every

single aspect from scratch.

And is your project going
to be profitable?

Have you really got the
development time to do

pointers and touch and click and
keyboard, which I reckon

probably most web developers
are failing at already.

Like we're not even doing
keyboard and click that well.

So are you going to add another
interaction paradigm

into your development
lifecycle?

PETE LEPAGE: But isn't the point
of pointer events that

you can sort of reduce the touch
and the mouse and all

that kind of stuff to
one simple place?

MAIREAD BUCHAN: Yeah.

Absolutely.

I think it's a great idea,
and I agree with Matt.

You've got to abstract it.

Otherwise, we're entering
a world of pain.

You've got to.

BORIS SMUS: Yeah.

I think abstracting is
important, but you still need

to retain the ability of
distinguishing between these

different types of input.

Like for example, you often do
want to have a touch-specific

thing, which pointer events do
let you do because you can

distinguish between [INAUDIBLE]
and touch.

But that's an important thing
to carry over so that we're

still able to do these sorts
of customizations.

FRANCOIS DAOUST: Yeah.

So just to complete, again,
there are different layers or

different levels.

And you want both of them--

maybe there's more than two,
but you want actually the

intent level for generic
interaction, and you want the

more precise level, the pointer
level, being one, the

touch level being a
deeper one, maybe.

All of them have some use cases

that need to be fulfilled.

So the difficulty is teaching
the developer what to use and

how not to misuse, because if
you mix the levels, you're

going to end up breaking your
app pretty quickly, I suppose.

PETE LEPAGE: Yeah.

And I think we've all seen lots
of apps that have gotten

a little bit broken with touch
and that kind of thing.

Well, let's go--

all right.

Go ahead.

BORIS SMUS: A question for
people in the audience.

How many of you actually know
what pointer events are?

Just curious.

PETE LEPAGE: Awesome.

BORIS SMUS: OK.

So we actually are talking about
something that half the

people don't seem to
know what it is.

OK.

Cool.

So maybe just a quick intro
to pointer events.

Basically--

PETE LEPAGE: 30 seconds.

BORIS SMUS: Pointer events is a
way to consolidate mouse and

touch input into one type
of event system.

The reason for this is touch
events and mouse events are

basically two completely
separate systems.

There's this weird synthetic
event concept where mouse

events are generated for touch
on mobile devices.

So if you don't have a
touch handler, you

still get mouse events.

But this leads to a whole
bunch of problems.

So, anyway, now that we're
on the same page,

another quick question.

How many of you actually have
touch-specific handlers in

your applications?


OK.

So maybe about half.

Sounds good.

Thanks.

PETE LEPAGE: Cool.

Mairead, I wanted to go
to your question next.

Do you think that devices lying
about the event they are

sending, ie, touch devices
sending fake clicks, motion

sensors that likely motion
faking a touch event, is

unhelpful and somewhat
reminiscent of browsers lying

about their user agent?

MAIREAD BUCHAN: So to kind of
clarify this, well, I was

looking at the Leap Motion.

And what it does is
it projects a 2D

plane in front of you.

And when you touch that
plane, it sends

that as a touch event.

So anything you've built to be
touch related, Leap Motion can

do in 3D by pretending
it has a 2D surface.

If you look at how a touchscreen
pretends that it's

had a click, and that doesn't
really work, is the Leap

Motion touch really going
to be the same as

you touching a surface?

It's not, is it?

So the more we end up
down this dark path.

And also, if you're doing
feature detection, are you a

touch device?

Yes, I am.

No, it's not.

It's something else lying that
it's a touch device.

So that's dangerous ground, I
think, because, what, are you

going to go back to user agent
sniffing because your feature

detection is not working?

I don't know what's the
answer to that.

MATT CARUANA GALIZIA: One of
the problems that we have

right now, in fact, is devices
that support multiple input

types, like laptops with screens
which you can touch,

for example, but which also
have a mouse connected.


In the FD web app, we use a
library called FT Scroller.

But the issue that we have with
scrolling right now is

that we feature detect first
if the browser supports

pointers, then if it supports
touches, and then obviously

will fall back to
mouse events.

The problem with that is that
we sacrifice usability.


After we successfully feature
detect touch events, it means

that user won't be able to use
the mouse, for example, to

scroll a layer.


We should really be able to just
use pointer events, and

it should work for all the
different inputs, for the

mouse or for the touchscreen
itself.

BORIS SMUS: Yeah.

So on that point, I think for
the case of a touch laptop,

it's important not to
just ignore mouse.

Maybe the best practice is to
prevent default on such events

as opposed to not listening to
mouse events at all, since you

can no longer assume that
touch implies not mouse.


And on the question of reducing
different kinds of

input to different other kinds
of input, I agree with you.

It's a dangerous path.

Just like reducing touch to
mouse didn't work, reducing a

Leap, which actually tracks--

it's a sausage tracker,
essentially, tracks sausages

in the air--

reducing that into a touchscreen
also doesn't work.

And it's an insult to what
Leap can do, just like

reducing a touchscreen to a
mouse basically eliminates any

possibility of multitouch.

We have completely unexplored
territory in the 3D tracking

space that we would just
lose entirely.

PETE LEPAGE: I want to dive a
little bit deeper into the

interactions when using both
touch and mouse because,

Boris, you showed me a couple
of demos yesterday where

having an object on screen, you
can put your finger on it,

and then use the touchpad or
your mouse to make it move.

I think there are a lot
of really interesting

opportunities there that
haven't been explored.

Let's talk about some of
those different ones

for a minute or so.


BORIS SMUS: OK.

So I guess there's a
couple things that

are interesting here.

So the first one is just the
transition between the two

modes, in like a Windows 8
touch laptop, seems like

there's some opportunity
to have some--

almost like a responsive
input-type approach, where

instead of adapting to
screen size, you're

adapting to input method.

Just kind of throwing
this idea out there.

I haven't seen anyone do it
well, but it's interesting.

The other angle is multiple
inputs simultaneously.

So like what Pete was
describing, with a trackpad

and a simultaneous touchscreen
interaction.

Again, I've built some
prototypes around this stuff,

but it's pretty early.

And I think it'd be cool to see
more of them from other

people and have a discussion
about them, but it's a little

too early, I think,
to really go into.

PETE LEPAGE: All right.

Fair answer.

Anybody else have any
thoughts on that?

All right.

So the next question we have,
tapping links on a page incurs

a 300 millisecond delay to work
out if the user is doing

a double tap to zoom.

Can we get rid of this
delay somehow

without losing the zoom?


MATT CARUANA GALIZIA: In
maintaining FastClick, which

is a polyfill that we developed
at the FT to get rid

of the delay, we've dealt
with a lot of issues.

[? You will ?]

constantly bring up the issue
that we've effectively

disabled zooming by firing a
click event as soon as the

finger leaves the screen,
as soon as the touch

end event is fired.


The issue seems to be that
really, we can't have the best

of both worlds at the moment
without an API that we can use

to zoom the page when we
detect a second tap.

But even in that case, really,
because once the finger has

left the screen, then you've
already fired the click event.

So we haven't figured out a
way yet to get the both of

both worlds.

FRANCOIS DAOUST: I guess,
unfortunately, the double tap

thing is really at the operating
system level.

It's something that
the device brings.

And you cannot just prevent it
from happening within a web

app, within a web browser,
within this device, without--

we can't even imagine, I guess,
an API that would allow

the web app to prevent the
double tap, because it's a

usability feature.

It has also accessibility
implications.


I guess the answer for me is,
no, you cannot right now.

New devices will probably
improve the touch interaction

and maybe remove
the double tap.

I don't know.

MATT CARUANA GALIZIA: Do you
that if we're building

responsive layouts, then the
users shouldn't really have to

zoom in the first place?

FRANCOIS DAOUST: Well, no,
but I know that the--

I believe that they should be
able to zoom in, but I know

that it can trigger a lot
analyst discussions on who's

right and who's wrong.

So I'm more--

it's the same thing with
the meta viewport

when you disable scaling.

It's the same discussion
somehow.

And in my view, it's supposed
to be the user choosing

whether he wants to
zoom in o or.

He may have good reasons
to do that.

But on mobile devices or tablet
devices, it's hard to

find another interaction that
could be used to zoom in.

So you're kind of stuck.

So when you develop web apps for
customers, for instance,

you will have to make
some workarounds.

And you will disable zoom in,
even if you don't want to,

just because otherwise,
the web app is

not responsive enough.

BORIS SMUS: So we've had lots
of discussions about this

particular thing.

And I think this is an
optimization that's either in

the Chrome beta for Android
or coming soon.

Basically, if you have a
non-user-scalable page,

there's no reason to have this
click delay, so we just

disable it.

Basically, I think this is the
way that things should be, and

FastClick is a giant hack that
should never have existed.

I'm not saying it's
like a bad thing.

Clearly, there was a--

MATT CARUANA GALIZIA:
I agree completely.

BORIS SMUS: There was a
need for it when there

was a need for it.

But it's time to get past that
and fix our browsers.

MATT CARUANA GALIZIA: I agree.


MAIREAD BUCHAN: I don't know.

Why would you loading a page?

Or can you guarantee that when
a pages is loaded that it's

going to be zoom disabled?

Do you see what I mean?

Like even if you've made a
responsive mobile site, a user

still might want to zoom
in on something.

Can you ever really make
a web page that's--

BORIS SMUS: I would argue that
yes, because if you look at

native apps, basically--

if we look at the extreme of
adapting content to your

device, then in the ideal case,
we should be doing this.

I don't think it's

unreasonable for special cases.

I'm not saying disable pinch
zooming in general or double

tap to zoom, but I
think there are

cases where it's justified.

MATT CARUANA GALIZIA: If we
have a pinch event, then

really, we could just listen for
that and zoom when we get

that event, rather than
using double tap or

anything like that.

And pinch makes sense because
you can theoretically pinch

with your hands if you're using
a Leap Motion device.

So it makes sense as an
abstract gesture.


PETE LEPAGE: Cool.

So as you guys were talking
about that, I wrote down one

off-the-cuff idea is, why can't
we just put an attribute

on elements and say, this
element, if the user double

taps on it, anything in here,
we don't get a zoom.

And then you can just say,
all right, great.

Everything in here, if the user
touches on it, that's an

immediate click.

BORIS SMUS: Great idea.

Microsoft implemented it in
IE 10, or maybe IE 9.

There's a CSS property called
ms-touch-action, I think, and

you can configure exactly what
happens when you touch this

particular element
to the extent of

disabling particular gestures.

So you can say no scrolling
on this thing, or no pinch

zooming on it.

And I think it would be great
to standardize this sort of

thing, just because declarative
things are kind of

better from many perspectives.

So, yeah, that's
my perspective.

PETE LEPAGE: Do you know
where it is in the

standardization process?

Or is it even there?

BORIS SMUS: As far as I know,
it's not anywhere.

PETE LEPAGE: OK.

All right.

BORIS SMUS: But I
could be wrong.

Rick?


RICK BYERS: I'm Rick Byers.

I'm the Google person on the
Pointer Events Working Group.

And so the question was the
ability to disable double tap

to zoom with touch
action, right?

So touch action, as we
standardize it right now, has

pan, none, and auto-- pan-x,
pan-y, none, and auto.

And double tap isn't in there,
in particular because to talk

about zooming individual
elements only makes sense in

IE's concept of content zoomable
where you can have an

element that's independently
zoomable from

the rest of the page.

And so we debated adding some
notion of zoom-to-touch

action, but without a notion
of content zoomable, it

doesn't make any sense.

All that really makes sense
is the page itself

being zoomable or not.

So far, in Chrome desktop, for
example, we don't have any

zooming at all.

We're not going to add double
tap, because there's no way in

hell we want to add that
300 millisecond

delay in Chrome desktop.

And in Android, it's
the viewport tag to

disable double tap.

That's where we are right now.

But I think we'll--

we've got to figure out how
can we not delay the click

while still permitting some--

certainly pinch, we should still
permit without disabling

double tap.

So I think maybe adding
something to touch action is

appropriate or some
other mechanism.


PETE LEPAGE: Anybody?

MAIREAD BUCHAN: I kind of feel
like, why don't we just ditch

double tap?

Like, is it really that
much of a win?

If you can pitch to zoom, do
you need two ways to zoom?

Not really.

Let's just filter that
out, fix that.


PETE LEPAGE: All right.

Anybody have anything else they
want to add on that one?

MATT CARUANA GALIZIA:
Just that I agree.

PETE LEPAGE: All right.

What do you guys think?

Should just everybody take
away double tap to zoom?

AUDIENCE: No.

PETE LEPAGE: No.

All right.

Well, there we go.

So it seems that the panelists
disagree with you.

Jake?

Can we get a mic?


AUDIENCE: So it's quite often
if I load a page on my phone

that's not optimized for the
screen size-- it doesn't have

a viewport metatag--

I'll quite often do the double
tap thing, right, to bring the

paragraph to full width
so I can read it.

But there's probably some way
that we can do around that.

If it does have a viewport tag,
but it isn't fixed zoom,

when the user starts the
interaction we know that

double tap's going to have no
effect because the paragraph

is already full width.

And then we could take
the shortcut there.

We would assume that
one tap is click.

We don't wait 300 milliseconds,
because double

tap is probably not what
they're going to do.


AUDIENCE: And there are also
some touch devices that it

doesn't implement multitouch.

So with the single input, the
double tap solves the problem.

FRANCOIS DAOUST: That's
one point I

wanted to raise as well.

When we talk about input, we
are actually entering a

wonderful world of patents
and that kind of stuff.

And it makes it hard, actually,
to be able to do

whatever you want.

And so indeed, the pinch
couldn't be done in previous

version, at least of other
mobile devices, because of

obvious patents--

or maybe not obvious, actually--
but anyway, because

of patents.

So there's always this side of
the story that we don't like

to talk about and that we don't
like as developers but

that still exists
in this world.

BORIS SMUS: Right.

But I think that's--

hello.

Test.

Test.

FRANCOIS DAOUST: [INAUDIBLE].

BORIS SMUS: Sure.

That said, I think as
developers, there's nothing

that prevents us from
implementing.

[LAUGHTER]

PETE LEPAGE: So obviously,
the audio gods don't

want Boris to speak.

There we go.

All right.

Let's try this again.

BORIS SMUS: So I think the
patents don't affect insomuch

as web developers as
we can implement

our own gesture handlers.

They're just not going to
be available natively in

platforms for any foreseeable
future.

But we can still make our own
gesture libraries, and there's

many of them out there.

So that shouldn't
be stopping any

development in this direction.


FRANCOIS DAOUST: What it stops
usually is standardization.

It's where things stop.

And gestures have been stopped
for that precise reason, at

W3C, at least.

There are other examples.

PETE LEPAGE: All right.

Anything else?

All right.

Let's pop down to the
next question.

This is one that I added because
I think it's a really

important question that
gets addressed.

As web developers, how can we
test our sites if we don't own

a touch PC or a touch
laptop, right?

How can we be testing our sites
to see how they're going

to interact on some
of these things?

Obviously, going down to the
local computer store and

testing your web app on there
and then going home isn't

going to work.


MAIREAD BUCHAN: Well, in my
experience, the only way to

develop, to test on a device
is to have in your hand.

And if you really can't afford
to that, then I think you need

to get testing labs or these
kind of browser shop places

where you've got someone
else doing it

with an actual device.

I haven't found any emulator or
simulator that was really

that useful.

And even if you're looking at
something on a screen, and

you've got an iPad-shaped thing,
like our designers were

designing things.

And then when the QA actually
had an iPad in his hand, his

thumb, the way he was holding
the device, actually obscured

part of the design, which you
can't mimic unless you're

really holding an
actual thing.

I think if you can't afford
every device, and if you're a

sole trader, there's no
way you could do that.

You're going to have to
put an extra line

item in your budget.

FRANCOIS DAOUST: Yeah.

Well, I'm afraid there's not
many other solutions.

We do a lot of development on
connected TVs, for instance.

And you try the emulators.

They just don't work as the
actual TV, so you really have

no other choice than to have the
set-top box, the TV, the

whatever in your room
and try it.

You can just delay the time at
which you start to try to test

the app on a natural device,
but it has to be done,

unfortunately.

MATT CARUANA GALIZIA: At the FT
we use a testing framework

called eggPlant to test using
the iOS simulator, and it

seems to work quite well.

It's just very difficult to get
using, because you have to

learn their scripting language,
script the device.

It's very labor intensive.


BORIS SMUS: I think it's worth
mentioning that the simplest

thing you can do, if you're
especially a content-oriented

site, is you can enable
touch events in the

Chrome Developer Tools.

So it's just a tick box
in the settings.

And if your site doesn't work
with that enabled-- basically,

what it does is it creates a
touch-equivalent event for

each mouse event.

And if your site doesn't work
there, then it's not

guaranteed--

or basically, if it doesn't work
there, it's guaranteed

not to work on a
mobile device.

So you don't have the opposite
guarantee, but

it's at least something.

The other thing is I would--

pardon my shameless plug, but
basically, there's a GitHub

repo that lets you take your
multitouch trackpad on your

Mac device and just essentially
pass those events

into the browser, synthesizing
multitouch events.

If you want to check it out,
it's called MagicTouch, and

it'll work on your Mac.

End of plug.


BORIS SMUS: Rick.

PETE LEPAGE: Mic coming
up behind you.

MATT CARUANA GALIZIA:
Behind you.

RICK BYERS: There's just one
more really important piece I

think I just wanted to mention,
that for this common

case that Matt was discussing
about a site that when you run

it on a computer with
touch and mouse,

the mouse stops working.

That's the case we see all
the time in Chrome on

touch-enabled laptops.

That's actually really
easy to test.

You can run Chrome with the
flag, dash, dash, touch

events, colon, enable.

From about:flags, you
can turn that on.

We really would like to
have Chrome always

support touch events.

The problem is, people conflate
the idea "does the

browser support touch events"
with "is there a touchscreen

attached?"

And in theory, we want the
browser to always support

touch events, because you
could plug in a USB

touchscreen any time.

And we can't just suddenly start
have [? window down ?]

on touch.

We can't change whether or not
the browser supports touch

events during the lifetime
of a renderer process.

We can only do it on startup.

It would confuse the page,
even if we could do.

So we'd love to be able
to just say-- in

fact, we've done it.

I think for Chrome 22
for a while, we

supported touch events.

Everyone complained that
sites were broken.

I'm like, yeah, it's because
they assume that supporting

touch events means that there's
touchscreen attached

when it doesn't.

So please, turn that flag on.

Run with it on all the time.

It doesn't hurt anything except
it might break your

site because you've got
bugs in your site.


BORIS SMUS: So actually
on that, it's sort

of interesting when--

I think we're getting to a place
where there's a lot of

possible permutations of
input that's available.

And there's no real
way to know what's

actually hooked up.

I don't know.

Maybe I'm the only one that's
kind of hit this, but it seems

like sort of a bigger issue
for the web platform.

Just--

yeah, no real point here.

PETE LEPAGE: All right.

Anything else we want
to add to this?

All right.

Let's pop down to the
next question.

And I think it's actually going
back to the sort of

standardization comments we've
had a couple of times.

But should we started working
on this standardizing of

spatial and gestural input from
the upcoming wave of 3D

motion sensing devices
like Leap Motion?

MAIREAD BUCHAN: And so I was
talking to a research

department at Kingston
University, and they deal with

human-computer interaction.

So they've been working with
multimillion pound software

and hardware to do human pose
and gesture detection.

And they've written a couple
of EU standards for gesture

and also human body pose.

So that kind of research has
already existed, not in the

web development world but
in the HCI world, for

quite a long time.

If I was going to see a standard
for us to work with

Leap and Kinect, I would like
it to be following in the

paths of other people's
research.

I don't want to reinvent the
wheel for that kind of thing.


MATT CARUANA GALIZIA:
I agree with that.

For most use cases, developers
will just want to listen to

the intent.

For example, in the few use
cases right now where a Leap

Motion device is attached, we
just want our website to

continue working if we're
listening for

events on links, say.

But for applications that
specifically target--

meant to be used with Leap
Motion devices or the Kinect,

say, then really need a standard
way of dealing with

input from these devices.

The market is probably
going to grow.

There are going to be
many new devices.

We can't just ship all the
different JavaScript libraries

for every single device
with our application.

It's just not scalable.

BORIS SMUS: Yeah.

I would sort of agree
in spirit with the

standardization idea, but I
really do think it's early

days for these kinds
of inputs.

And I think before standardizing
it, it's

worthwhile just to let a million
flowers bloom and just

to see what the commonalities
are and what the useful things

are for standardization before
we move in that path, because

it's going to slow us down.


PETE LEPAGE: Matt, I want to
go back on the same path of

something that you said that
kind of jogged my mind and I

thought was kind
of interesting.

Should we maybe think about with
the PointerEvents spec

just adding a z-coordinate
to it?

MATT CARUANA GALIZIA: Yeah.

I think that make sense.

Why not, really?

PETE LEPAGE: Would something
like that work for Leap and

all of these other things,
potentially?

MATT CARUANA GALIZIA: It would
work in a limited sense.

It wouldn't allow you to make
the best use of the Leap

Motion device.

But for doing basic things, like
manipulating something,

let's say a graphic within a
3D plane, then that works.

For more complex gestures, then
of course, it will be a

bit more difficult to use
pointers in that sense.

You'd need something a bit
more sophisticated.


MAIREAD BUCHAN: I think the way
I see it, there's a couple

of different kinds of
applications that you might

want to use, a 3D motion-sensor

device and the internet.

So one kind of use case is that
you're building a website

that someone's going
to browse.

So they're swiping carousels,
and they're

scrolling the page.

And that's quite traditional
web development.

Or there's another aspect
where you might be doing

something more in a 3D
environment, so gaming and

things where you need inertia
and speed and like also, 3D

motion does kind of tilt,
and rotation of a point.

So it's not just x, y, z.

There's actually a lot of other
information, and that's

relevant to a 3D world.

But it's not really relevant to
someone browsing a web page

or reading a magazine
on their television.

So what kind of application
you're developing, it depends

how much information you need.

So pointer is really good for
websites, and there's other

things that would be relevant
for other kinds.

BORIS SMUS: I agree.

And I would actually be wary
of adding a z-coordinate to

pointer events, partly just
because it's unclear what the

units would be for
all this stuff.

You're breaking the connection
of a mapping-to-a-screen

coordinate.

As soon as you're dealing with
tracking real world stuff,

it's in some different
coordinate systems that's

basically--

if you can bring it back to
screen space, you're doing it

with some weird transform.

But there's some other
set of coordinates.

Typically for a depth cam, it's
x, y, z, in millimeters,

which would be very confusing to
suddenly change your units

to millimeters in
pointer spec.

So my vote for keeping
pointers clean.


PETE LEPAGE: Francois, do you
want to weigh in on that one?

FRANCOIS DAOUST: [INAUDIBLE].

PETE LEPAGE: All right.

All right.

FRANCOIS DAOUST: [INAUDIBLE].

PETE LEPAGE: All right.

So pop down to our
next question.

What will be the equivalent
event for hover mouseover for

touch devices?

Should we abandon the
hover event when

considering touch devices?


FRANCOIS DAOUST: I guess that
could happen in the future.

You can already do that, some
kind of presence detection of

the finger, with several
systems, infrared or--

what's it's called?

Ultrasound.

There are some systems that
allow you to detect the

presence of a finger without
actually touching the screen.

But it has more limited use than
hover, and it's supposed

that the user is not shaking and
is actually pointing his

finger correctly.


We should not close the door
to that possibility, but I

don't think that's a main
use case right now.

BORIS SMUS: I think it's
important that we don't rely

on hover for just the general
web, again, because of mixed

modalities, possibly of input.

If you rely on hover, generally
touch devices are

not going to be able to
see whatever's there.

It's a very clunky interaction
to have this.

You can activate the hover
state, the CSS hover state, by

doing this weird action.

You press down on the link, and
then you move away from it

before it long presses, or
something like that.

And then you get the
hover state.

But obviously this is not
something that we want to do

or have people do.

So I do think that
it's important.

Though there's technology coming
to make this happen,

it's not going to
happen tomorrow.

You should be very aware of
hover states in touch and

don't do it.

PETE LEPAGE: There
a comment back--

AUDIENCE: Actually, I
ask a question, yes.

And the reason I ask is, so my
wife has a Samsung Note, which

comes with a pen.

Because it comes with pen, pen
can do the kind of hover

equivalent.

When it comes too close to the
surface, it mimics hover.

And also, when you do a drawing
in something like

Wacom they also have
the hover.

And it's very critical,
especially when you start

doing [? data ?] visualization
or something, you don't want

to touch everything, because
you just want to glance the

information.

Then you need a [INAUDIBLE]

information, which I don't
want to touch everything.

So I think hover is kind of
getting neglected, especially

in the touch.

You think a touch panel
enhances the input--

PETE LEPAGE: Yeah.

AUDIENCE: --but it's actually
one [? other ?]

thing.

It's decreasing.

PETE LEPAGE: Yeah.

Yeah.

I think that's a really
valid point.

MAIREAD BUCHAN: I think it's
kind of highlighting the

problem of like a kind of--

I don't want to use the word
"semantics," but I can't think

of anything better--

like a hover with a mouse on
a 2D screen is not really a

hover at all.

That's a mouse entering
a bounded area.

It's not hovering just above it
because you've only got two

dimensions.

What's a hover in a 3D world
is different to a

hover in a 2D world.

And actually, it should be
pointer Enter before pointer

is activated.

And your active is your click,
and your Enter is your hover.

But we need to move away from
that kind of terminology,

because it is confusing.

It's a mixed metaphor.


I like hover, but I tell my
designers they're not allowed

to use it anymore.

PETE LEPAGE: We've
got time for, I

think, one more question.


So we'll go for this last one.

Smooth scrolling is critical
for a good touchscreen

experience.

What are some of the common
pitfalls for introducing

scroll jank to touch input?


BORIS SMUS: So one of the common
things people tend to

do is do a bunch of stuff
in their input handlers.

So this breaks down really
quickly with multitouch,

because you're having your
touch move events firing

basically at a rate proportional
to the number of

fingers on your screen.

So you end up having
a flood of--

I don't know-- something
like--

I've seen it go up to, like,
200 fps touch input events.

So if you're trying to render
at 200 fps, you're obviously

going to be throttling your
rendering engine.

The workaround to this is use
RequestAnimationFrame, set

state in your input handler, and
then render on render as

opposed to on input.


PETE LEPAGE: Anybody else
got anything they

want to add to that?

Who's there?

RICK BYERS: Rick.

PETE LEPAGE: All right.

Can we get a mic over
there real quick.


RICK BYERS: I'm sorry.

This is such a big problem I
can't help not speak up again.

I think people often don't
realize the implication of

putting a touch handler
on your page.

So if you're using touch events,
the model is that the

browser can't decide whether
or not to scroll until it's

dispatched the touch
starter-touch move event to

you and waited to see if
you're going to call

preventDefault.

And if you preventDefault on the
touch starter-touch move,

that means you're canceling
the scroll.

You might even be in the middle
of the scroll, and you

preventDefault to move, and it
means we have to cancel the

scroll, which means in modern
browsers, we try to do as much

scrolling as possible
on the GPU thread.

Which means we've got to block
the GPU thread, synchronize

with the main thread that might
be in the middle of

JavaScript or loading a page to
wait to see what your touch

handler is going to do
before we can go

back and undo scrolling.

And it's a huge problem.

So the key guidance
I would give is--

what we've done in the recent
versions of Chrome and what

iOS does is it's got region
tracking so that the GPU

thread knows which regions
of the page have a

touch handler on it.

So if you confine your touch
handlers to just the elements

that really need to have touch
handlers, then we can only

introduce the jank when
you touch those.

If you put a touch-move handler
on your document, it

means that every single scroll
has got a block on the main

thread, and it's going to be
almost impossible to have

smooth scrolling.

This is one of the things I
think is a problem with the

touch event model.

Pointer event solves this.

PETE LEPAGE: There's a
comment back there.

AUDIENCE: Hi.

It was just related to
what you were saying.

How does that translate
through to clicks?

Is it just touch, or what
happens when you've got the

simulated clicks from the touch
events with scrolling?


PETE LEPAGE: Sorry.

Just to make sure
I understand.

What happens when you have
simulated clicks?

AUDIENCE: So if you've got a
click handler element that

you're using to scroll, does
exactly the same thing apply,

or it just--

RICK BYERS: It's just touch
handlers, because click is

triggered by a tap gesture, and
so there's no ambiguity

between scrolling and tapping.

So you can have a tap handler,
you can have

a mouse-down handler.

In theory, mouse wheel
has the same problem.

In theory, mouse wheels are
blocked on JavaScript.

If there's a JavaScript
handler, we have to.

But--

AUDIENCE: [INAUDIBLE]--

RICK BYERS: --all browser
implementations

today always block.

They don't do the region
tracking for mouse wheel,

because there's a psychological
effect.

Scrolling with your finger, you
really notice the jank.

Scrolling with your mouse wheel
or the trackpad, you

don't notice it so much
because you're

not physically connected.

So in theory, the problem exists
for mouse wheel, and we

said we're probably going to
apply the same region tracking

we've done for touch to
mouse wheel in Chrome.

We just haven't done it yet,
because it's not as important

because of that psychological
effect.


FRANCOIS DAOUST: I know the
discussion has focused on

touch, and the question
mentioned touch explicitly,

which I just wanted to open it
to another dimension, which is

just a regular nav-down,
nav-right, nav-left, nav-up

events, which are the ones that
you'll receive when the

user is using a TV remote,
for instance, on a TV.

And it makes scrolling,
actually, a bit of a pain

because you have to handle it
yourself in the web app with

the nav-down.

And you have to, well, scroll
the viewport, obviously, and

then also handle links
in the good old days.

But the TV is kind of huge
screen, as opposed to the

mobile of 2000, where you had
the keypad, but you had the

small screen, so it was kind
of easy to make the

navigation.

So anyway, I just wanted
to raise the point.

Do not forget that there's more
than touch and mouse.

PETE LEPAGE: I think that's a
great point, and I think the

performance tip there of really
making sure that you're

being aware of where you're
putting your touch events,

listeners, and all that stuff
is a really great

point to end on.

I want to thank the panelists
for joining us up on stage.

I hope you guys learned
something, and it was quite

interesting for you.

And go build cool.


